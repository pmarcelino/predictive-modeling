<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Lecture 09: Programming Example - Predictive Modeling MOOC</title>

    <style>
      body {
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "Roboto",
          "Helvetica", "Arial", sans-serif;
        line-height: 1.6;
        max-width: 1200px;
        margin: 0 auto;
        padding: 20px;
        background-color: #f8f9fa;
      }

      .container {
        background-color: white;
        border-radius: 8px;
        padding: 30px;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
      }

      .nav-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 20px 30px;
        border-radius: 8px 8px 0 0;
        margin: -30px -30px 30px -30px;
        display: flex;
        justify-content: space-between;
        align-items: center;
        flex-wrap: wrap;
        gap: 15px;
      }

      .nav-header h1 {
        margin: 0;
        font-size: 1.5rem;
        font-weight: 600;
      }

      .nav-buttons {
        display: flex;
        gap: 10px;
        flex-wrap: wrap;
      }

      .btn {
        display: inline-block;
        padding: 10px 20px;
        text-decoration: none;
        font-weight: 600;
        border-radius: 6px;
        transition: all 0.3s ease;
        font-size: 0.9rem;
      }

      .btn-colab {
        background-color: #f9ab00;
        color: #1a1a1a;
        border: 2px solid #f9ab00;
      }

      .btn-colab:hover {
        background-color: #ff9900;
        border-color: #ff9900;
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(249, 171, 0, 0.3);
      }

      .btn-github {
        background-color: transparent;
        color: white;
        border: 2px solid white;
      }

      .btn-github:hover {
        background-color: white;
        color: #667eea;
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(255, 255, 255, 0.3);
      }

      .jupyter-content {
        margin-top: 20px;
      }

      /* Notebook cell styling */
      div.cell {
        margin-bottom: 1.5rem;
      }

      div.input_area {
        border-left: 3px solid #667eea;
        background-color: #f8f9fa;
        padding: 10px;
        border-radius: 4px;
      }

      div.output_area {
        padding: 10px;
        border-left: 3px solid #28a745;
        background-color: #f8f9fa;
        border-radius: 4px;
        margin-top: 10px;
      }

      /* Code highlighting */
      .highlight {
        background-color: #f8f9fa;
        border-radius: 4px;
      }

      /* Responsive design */
      @media (max-width: 768px) {
        body {
          padding: 10px;
        }

        .container {
          padding: 15px;
        }

        .nav-header {
          padding: 15px;
          margin: -15px -15px 15px -15px;
        }

        .nav-header h1 {
          font-size: 1.2rem;
        }

        .nav-buttons {
          width: 100%;
          justify-content: center;
        }
      }
    </style>
  </head>
  <body>
    <div class="container">
      <div class="nav-header">
        <h1>Lecture 09: Programming Example</h1>
        <div class="nav-buttons">
          <a
            href="https://colab.research.google.com/github/pmarcelino/predictive-modeling/blob/main/module-04/lecture-09-programming-example.ipynb"
            target="_blank"
            rel="noopener"
            class="btn btn-colab"
          >
            â–¶ Open in Colab
          </a>
          <a
            href="https://github.com/pmarcelino/predictive-modeling/blob/main/module-04/lecture-09-programming-example.ipynb"
            target="_blank"
            rel="noopener"
            class="btn btn-github"
          >
            ðŸ“‚ View on GitHub
          </a>
        </div>
      </div>
      <div class="jupyter-content">
        <main>
          <div class="border-box-sizing" id="notebook" tabindex="-1">
            <div class="container" id="notebook-container">
              <div
                class="cell border-box-sizing text_cell rendered"
                id="cell-id=77035d7b"
                ><div class="prompt input_prompt"> </div
                ><div class="inner_cell">
                  <div class="text_cell_render border-box-sizing rendered_html">
                    <h1 id="Lecture-9:-Tree-Based-Models---Programming-Example"
                      >Lecture 9: Tree-Based Models - Programming Example<a
                        class="anchor-link"
                        href="#Lecture-9:-Tree-Based-Models---Programming-Example"
                      ></a
                    ></h1>
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing text_cell rendered"
                id="cell-id=9ff6ef4f"
                ><div class="prompt input_prompt"> </div
                ><div class="inner_cell">
                  <div class="text_cell_render border-box-sizing rendered_html">
                    <h2
                      id="Introduction:-Advancing-Beyond-Linear-Constraints-with-Tree-Based-Intelligence"
                      >Introduction: Advancing Beyond Linear Constraints with
                      Tree-Based Intelligence<a
                        class="anchor-link"
                        href="#Introduction:-Advancing-Beyond-Linear-Constraints-with-Tree-Based-Intelligence"
                      ></a></h2
                    ><p
                      >Welcome back to your Capital City Bikes consulting
                      engagement! Eight months after deploying your linear
                      regression models, the board has approached you with
                      competitive intelligence that demands immediate action.
                      Three rival bike-sharing companies have entered your
                      market with sophisticated ML systems achieving
                      demonstrably better predictions during complex scenarios
                      like weather transitions and seasonal shifts.</p
                    >
                    <p
                      >The CEO's message is direct: "Our linear models served us
                      well for Series A funding, but competitors are now
                      outperforming us with advanced ensemble methods. The
                      Series B investors expect state-of-the-art predictive
                      capabilities. We need you to implement tree-based models
                      that capture the non-linear patterns and feature
                      interactions our linear approach is missing."</p
                    >
                    <p
                      >Your task: engineer sophisticated features that expose
                      non-linear patterns, implement decision trees to
                      understand their interpretable rule-based logic, deploy
                      Random Forest ensembles that achieve production-grade
                      accuracy, and analyze feature importance to guide
                      strategic investments. Every technique must demonstrate
                      measurable improvements over your linear baseline to
                      justify the algorithmic complexity to stakeholders.</p
                    >
                    <blockquote>
                      <p><strong>ðŸš€ Interactive Learning Alert</strong></p>
                      <p
                        >This is an advanced hands-on tutorial with
                        production-grade ensemble modeling challenges. For the
                        best experience:</p
                      >
                      <ul>
                        <li
                          ><strong>Click "Open in Colab"</strong> at the bottom
                          to run code interactively</li
                        >
                        <li
                          ><strong>Execute each code cell</strong> by pressing
                          <strong>Shift + Enter</strong></li
                        >
                        <li
                          ><strong>Complete the challenges</strong> to practice
                          your tree-based modeling skills</li
                        >
                        <li
                          ><strong>Think like a senior consultant</strong> -
                          algorithm choice impacts funding discussions and
                          competitive positioning</li
                        >
                      </ul>
                    </blockquote>
                    <hr />
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing text_cell rendered"
                id="cell-id=1e6b603c"
                ><div class="prompt input_prompt"> </div
                ><div class="inner_cell">
                  <div class="text_cell_render border-box-sizing rendered_html">
                    <h2
                      id="Step-1:-Feature-Engineering-for-Non-Linear-Pattern-Discovery"
                      >Step 1: Feature Engineering for Non-Linear Pattern
                      Discovery<a
                        class="anchor-link"
                        href="#Step-1:-Feature-Engineering-for-Non-Linear-Pattern-Discovery"
                      ></a></h2
                    ><p
                      >Let's begin with feature engineering to enhance the
                      quality of our feature set, followed by a preliminary
                      analysis to better understand the data.</p
                    >
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing code_cell rendered"
                id="cell-id=f373e0f6"
              >
                <div class="input">
                  <div class="prompt input_prompt">InÂ [Â ]:</div>
                  <div class="inner_cell">
                    <div class="input_area">
                      <div class="highlight hl-ipython3">
                        <pre><span></span><span class="c1"># Import essential libraries for data manipulation, modeling, and visualization</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>

<span class="c1"># Load Washington D.C. bike-sharing dataset</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">"https://raw.githubusercontent.com/pmarcelino/predictive-modeling/main/datasets/dataset.csv"</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'datetime'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'datetime'</span><span class="p">])</span>

<span class="c1"># Sort chronologically to maintain temporal integrity for time series modeling</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">'datetime'</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"=== FEATURE ENGINEERING FOR TREE-BASED MODELS ==="</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Dataset: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> hourly observations"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Time range: </span><span class="si">{</span><span class="n">df</span><span class="p">[</span><span class="s1">'datetime'</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">}</span><span class="s2"> to </span><span class="si">{</span><span class="n">df</span><span class="p">[</span><span class="s1">'datetime'</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Existing features in dataset</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Original features:"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
<span class="nb">print</span><span class="p">()</span>

<span class="c1"># Extract temporal features that capture demand cycles</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'datetime'</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">hour</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'dayofweek'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'datetime'</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">dayofweek</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'month'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'datetime'</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">month</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'year'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'datetime'</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">year</span>

<span class="c1"># Create binary features for operational planning segments</span>
<span class="c1"># Binary encoding converts categorical conditions into 0/1 indicators that</span>
<span class="c1"># trees can use for clean threshold-based splitting decisions</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'is_rush_hour'</span><span class="p">]</span> <span class="o">=</span> <span class="p">((</span><span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">7</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">9</span><span class="p">)</span> <span class="o">|</span>
                        <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">17</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">19</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="c1"># Rush hours (7-9am, 5-7pm) represent peak commuter demand periods</span>

<span class="n">df</span><span class="p">[</span><span class="s1">'is_weekend'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'dayofweek'</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="c1"># Weekend indicator captures leisure vs. commuter demand patterns</span>

<span class="n">df</span><span class="p">[</span><span class="s1">'is_night'</span><span class="p">]</span> <span class="o">=</span> <span class="p">((</span><span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">22</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">5</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="c1"># Night hours (10pm-5am) represent low-demand maintenance windows</span>

<span class="c1"># Weather condition severity encoding</span>
<span class="c1"># Map weather codes to interpretable severity levels for better business understanding</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'weather_severity'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'weather'</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">({</span><span class="mi">1</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">:</span> <span class="mi">3</span><span class="p">})</span>
<span class="c1"># 0=clear, 1=cloudy, 2=light_rain, 3=heavy_rain/snow</span>

<span class="c1"># Temperature-based categorical features for threshold effects</span>
<span class="c1"># Cut temperature into bins representing operational planning segments:</span>
<span class="c1"># Cold (&lt;10Â°C), Cool (10-20Â°C), Warm (20-30Â°C), Hot (&gt;30Â°C)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'temp_category'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'temp'</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">],</span>
                               <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">'cold'</span><span class="p">,</span> <span class="s1">'cool'</span><span class="p">,</span> <span class="s1">'warm'</span><span class="p">,</span> <span class="s1">'hot'</span><span class="p">])</span>

<span class="c1"># Humidity-based categorical features</span>
<span class="c1"># High humidity (&gt;70%) significantly reduces cycling comfort</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'humidity_category'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'humidity'</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">],</span>
                                   <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">'dry'</span><span class="p">,</span> <span class="s1">'moderate'</span><span class="p">,</span> <span class="s1">'humid'</span><span class="p">])</span>

<span class="c1"># Interaction features that capture combined effects</span>
<span class="c1"># Temperature Ã— Hour interaction: warm mornings differ from warm evenings in demand patterns</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'temp_hour_interaction'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'temp'</span><span class="p">]</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span>

<span class="c1"># Working day Ã— Hour: commuter patterns differ dramatically between working days and weekends</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'workingday_hour'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'workingday'</span><span class="p">]</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span>

<span class="c1"># Season-Weather interaction: rain in summer affects demand differently than rain in winter</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'season_weather'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'season'</span><span class="p">]</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="s1">'weather_severity'</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"=== ENGINEERED FEATURES ==="</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Temporal features: hour, dayofweek, month, year"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Binary indicators: is_rush_hour, is_weekend, is_night"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Categorical encodings: weather_severity, temp_category, humidity_category"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Interaction features: temp_hour_interaction, workingday_hour, season_weather"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="c1"># Prepare feature matrix for tree-based modeling</span>
<span class="c1"># Note: Tree-based models can handle categorical variables, but we'll use</span>
<span class="c1"># numerical encoding for consistency with scikit-learn's requirements</span>
<span class="n">feature_columns</span> <span class="o">=</span> <span class="p">[</span>
    <span class="c1"># Weather features</span>
    <span class="s1">'temp'</span><span class="p">,</span> <span class="s1">'atemp'</span><span class="p">,</span> <span class="s1">'humidity'</span><span class="p">,</span> <span class="s1">'windspeed'</span><span class="p">,</span> <span class="s1">'weather_severity'</span><span class="p">,</span>
    <span class="c1"># Temporal features</span>
    <span class="s1">'hour'</span><span class="p">,</span> <span class="s1">'dayofweek'</span><span class="p">,</span> <span class="s1">'month'</span><span class="p">,</span> <span class="s1">'season'</span><span class="p">,</span>
    <span class="c1"># Binary indicators</span>
    <span class="s1">'workingday'</span><span class="p">,</span> <span class="s1">'holiday'</span><span class="p">,</span> <span class="s1">'is_rush_hour'</span><span class="p">,</span> <span class="s1">'is_weekend'</span><span class="p">,</span> <span class="s1">'is_night'</span><span class="p">,</span>
    <span class="c1"># Interaction features</span>
    <span class="s1">'temp_hour_interaction'</span><span class="p">,</span> <span class="s1">'workingday_hour'</span><span class="p">,</span> <span class="s1">'season_weather'</span>
<span class="p">]</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">feature_columns</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'count'</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Feature matrix: </span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> observations Ã— </span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2"> features"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Target variable: count (hourly bike rentals)"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="c1"># Display feature statistics for business understanding</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"=== FEATURE STATISTICS (Business Intelligence) ==="</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Rush hour observations: </span><span class="si">{</span><span class="n">df</span><span class="p">[</span><span class="s1">'is_rush_hour'</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">df</span><span class="p">[</span><span class="s1">'is_rush_hour'</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%)"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Weekend observations: </span><span class="si">{</span><span class="n">df</span><span class="p">[</span><span class="s1">'is_weekend'</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">df</span><span class="p">[</span><span class="s1">'is_weekend'</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%)"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Night observations: </span><span class="si">{</span><span class="n">df</span><span class="p">[</span><span class="s1">'is_night'</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">df</span><span class="p">[</span><span class="s1">'is_night'</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%)"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="c1"># Show demand differences across key segments for operational insights</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"=== DEMAND PATTERNS BY SEGMENT ==="</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Rush hour demand: </span><span class="si">{</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">'is_rush_hour'</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">][</span><span class="s1">'count'</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.0f</span><span class="si">}</span><span class="s2"> bikes/hour"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Non-rush hour demand: </span><span class="si">{</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">'is_rush_hour'</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">][</span><span class="s1">'count'</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.0f</span><span class="si">}</span><span class="s2"> bikes/hour"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Weekend demand: </span><span class="si">{</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">'is_weekend'</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">][</span><span class="s1">'count'</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.0f</span><span class="si">}</span><span class="s2"> bikes/hour"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Weekday demand: </span><span class="si">{</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">'is_weekend'</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">][</span><span class="s1">'count'</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.0f</span><span class="si">}</span><span class="s2"> bikes/hour"</span><span class="p">)</span>
</pre>
                      </div>
                    </div>
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing text_cell rendered"
                id="cell-id=b9daf3b8"
                ><div class="prompt input_prompt"> </div
                ><div class="inner_cell">
                  <div class="text_cell_render border-box-sizing rendered_html">
                    <p><strong>What this does:</strong></p>
                    <ul>
                      <li
                        >Loads Washington D.C. bike-sharing data and sorts
                        chronologically for time series integrity</li
                      >
                      <li
                        >Engineers temporal features (hour, dayofweek, month)
                        that capture cyclical demand patterns</li
                      >
                      <li
                        >Creates binary indicators (is_rush_hour, is_weekend,
                        is_night) for operational segments</li
                      >
                      <li
                        >Builds interaction features (tempÃ—hour,
                        workingdayÃ—hour) that expose non-linear effects</li
                      >
                      <li
                        >Categorizes continuous variables (temp_category,
                        humidity_category) for threshold discovery</li
                      >
                    </ul>
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing text_cell rendered"
                id="cell-id=85a2ae2f"
                ><div class="prompt input_prompt"> </div
                ><div class="inner_cell">
                  <div class="text_cell_render border-box-sizing rendered_html">
                    <h3
                      id="Challenge-1:-Analyze-Feature-Distributions-and-Relationships"
                      >Challenge 1: Analyze Feature Distributions and
                      Relationships<a
                        class="anchor-link"
                        href="#Challenge-1:-Analyze-Feature-Distributions-and-Relationships"
                      ></a></h3
                    ><p
                      >Your client asks: "Can you create a visual report showing
                      how different features impact demand? I need to see which
                      factors drive ridership so we can understand the data
                      better." Explore feature interactions and segment analysis
                      through visualizations.</p
                    >
                    <p
                      ><strong>Your Task:</strong> Create visualizations showing
                      demand patterns across different feature combinations
                      (e.g., rush_hour + working_day, temperature + weather
                      severity).</p
                    >
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing code_cell rendered"
                id="cell-id=6e089e75"
              >
                <div class="input">
                  <div class="prompt input_prompt">InÂ [Â ]:</div>
                  <div class="inner_cell">
                    <div class="input_area">
                      <div class="highlight hl-ipython3">
                        <pre><span></span><span class="c1"># Your code here - analyze feature distributions and demand patterns</span>

<span class="c1"># Example 1: Rush hour + working day combination</span>
<span class="n">segment_analysis</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">'is_rush_hour'</span><span class="p">,</span> <span class="s1">'workingday'</span><span class="p">])[</span><span class="s1">'count'</span><span class="p">]</span><span class="o">.</span><span class="n">agg</span><span class="p">([</span><span class="s1">'mean'</span><span class="p">,</span> <span class="s1">'count'</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"=== RUSH HOUR Ã— WORKING DAY ANALYSIS ==="</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">segment_analysis</span><span class="p">)</span>

<span class="c1"># Example 2: Create a heatmap showing demand by hour and day of week</span>
<span class="n">hourly_daily</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">pivot_table</span><span class="p">(</span><span class="n">values</span><span class="o">=</span><span class="s1">'count'</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="s1">'___'</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="s1">'___'</span><span class="p">,</span> <span class="n">aggfunc</span><span class="o">=</span><span class="s1">'mean'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">hourly_daily</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'YlOrRd'</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">'.0f'</span><span class="p">,</span> <span class="n">cbar_kws</span><span class="o">=</span><span class="p">{</span><span class="s1">'label'</span><span class="p">:</span> <span class="s1">'Average Demand'</span><span class="p">})</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'___'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'___'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'___'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Example 3: Visualize temperature Ã— weather severity interaction</span>
<span class="c1"># Create scatter plot or box plots showing how demand varies</span>
</pre>
                      </div>
                    </div>
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing text_cell rendered"
                id="cell-id=ce6c5d71"
                ><div class="prompt input_prompt"> </div
                ><div class="inner_cell">
                  <div class="text_cell_render border-box-sizing rendered_html">
                    <details>
                      <summary
                        >ðŸ’¡ <strong>Tip</strong> (click to expand)</summary
                      >
                      <p
                        >Start with
                        <code
                          >.groupby(['is_rush_hour',
                          'workingday'])['count'].agg(['mean', 'count',
                          'std'])</code
                        >
                        to see how demand varies across combinations. For the
                        heatmap, use
                        <code
                          >df.pivot_table(values='count', index='hour',
                          columns='dayofweek', aggfunc='mean')</code
                        >
                        which creates a matrix showing average demand for each
                        hour-day combination. Set <code>cmap='YlOrRd'</code> for
                        a heat-based color scheme that makes patterns visually
                        obvious. For temperature Ã— weather interactions,
                        consider using
                        <code
                          >sns.boxplot(x='temp_category', y='count',
                          hue='weather_severity', data=df)</code
                        >
                        to show distributions. Look for segments with 2-3x
                        demand differences - these represent high-value
                        operational optimization opportunities. The heatmap will
                        clearly show morning/evening rush hour peaks on weekdays
                        versus flatter weekend patterns. Business insight: rush
                        hour + working day combinations might show 300+
                        bikes/hour while night + weekend shows &lt;50
                        bikes/hour, revealing where fleet positioning matters
                        most.</p
                      >
                    </details>
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing text_cell rendered"
                id="cell-id=9b1f7c31"
                ><div class="prompt input_prompt"> </div
                ><div class="inner_cell">
                  <div class="text_cell_render border-box-sizing rendered_html">
                    <details>
                      <summary
                        >ðŸ¤« <strong>Solution</strong> (click to expand)</summary
                      >
                      <div class="highlight">
                        <pre><span></span><span class="c1"># Example 1: Rush hour + working day combination</span>
<span class="n">segment_analysis</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">'is_rush_hour'</span><span class="p">,</span> <span class="s1">'workingday'</span><span class="p">])[</span><span class="s1">'count'</span><span class="p">]</span><span class="o">.</span><span class="n">agg</span><span class="p">([</span><span class="s1">'mean'</span><span class="p">,</span> <span class="s1">'count'</span><span class="p">,</span> <span class="s1">'std'</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"=== RUSH HOUR Ã— WORKING DAY ANALYSIS ==="</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">segment_analysis</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="nb">print</span><span class="p">()</span>

<span class="c1"># Example 2: Heatmap showing demand by hour and day of week</span>
<span class="n">hourly_daily</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">pivot_table</span><span class="p">(</span><span class="n">values</span><span class="o">=</span><span class="s1">'count'</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="s1">'hour'</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="s1">'dayofweek'</span><span class="p">,</span> <span class="n">aggfunc</span><span class="o">=</span><span class="s1">'mean'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">hourly_daily</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'YlOrRd'</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">'.0f'</span><span class="p">,</span> <span class="n">cbar_kws</span><span class="o">=</span><span class="p">{</span><span class="s1">'label'</span><span class="p">:</span> <span class="s1">'Average Demand (bikes/hour)'</span><span class="p">})</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Demand Heatmap: Hour Ã— Day of Week'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">'bold'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Day of Week (0=Mon, 6=Sun)'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Hour of Day'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Example 3: Temperature Ã— Weather severity interaction</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">'temp_category'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">'count'</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s1">'weather_severity'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Demand by Temperature Category and Weather Severity'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">'bold'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Temperature Category'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Hourly Demand (bikes)'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="c1"># Get current legend handles and create labels only for weather severities present in data</span>
<span class="n">handles</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">get_legend_handles_labels</span><span class="p">()</span>
<span class="n">severity_labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Clear'</span><span class="p">,</span> <span class="s1">'Cloudy'</span><span class="p">,</span> <span class="s1">'Light Rain'</span><span class="p">,</span> <span class="s1">'Heavy Rain'</span><span class="p">]</span>
<span class="c1"># Map only the severities that actually exist in the data</span>
<span class="n">present_severities</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'weather_severity'</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
<span class="n">legend_labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">severity_labels</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">s</span><span class="p">)]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">present_severities</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">handles</span><span class="p">,</span> <span class="n">legend_labels</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">'Weather Severity'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"=== KEY INSIGHTS FOR CAPITAL CITY BIKES ==="</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"âœ“ Rush hour + working day: Highest demand segment (optimize fleet positioning)"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"âœ“ Heatmap reveals: Strong morning (7-9am) and evening (5-7pm) peaks on weekdays"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"âœ“ Temperature Ã— Weather: Warm+clear weather shows 3x demand vs. cold+rainy conditions"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"âœ“ Operational priority: Focus dynamic repositioning on weekday rush hours"</span><span class="p">)</span>
</pre>
                      </div>
                    </details>
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing text_cell rendered"
                id="cell-id=7a7c74a9"
                ><div class="prompt input_prompt"> </div
                ><div class="inner_cell">
                  <div class="text_cell_render border-box-sizing rendered_html">
                    <hr />
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing text_cell rendered"
                id="cell-id=2a354045"
                ><div class="prompt input_prompt"> </div
                ><div class="inner_cell">
                  <div class="text_cell_render border-box-sizing rendered_html">
                    <h2 id="Step-2:-Implement-Decision-Tree-Regressor"
                      >Step 2: Implement Decision Tree Regressor<a
                        class="anchor-link"
                        href="#Step-2:-Implement-Decision-Tree-Regressor"
                      ></a></h2
                    ><p
                      >Now that we've seen how our engineered features impact
                      demand, let's try our first decision tree model. Decision
                      trees can capture non-linear patterns through
                      interpretable if-then rules that linear regression cannot
                      represent.</p
                    >
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing code_cell rendered"
                id="cell-id=9bc3c6cd"
              >
                <div class="input">
                  <div class="prompt input_prompt">InÂ [Â ]:</div>
                  <div class="inner_cell">
                    <div class="input_area">
                      <div class="highlight hl-ipython3">
                        <pre><span></span><span class="c1"># Import tree-based modeling tools from scikit-learn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.tree</span><span class="w"> </span><span class="kn">import</span> <span class="n">DecisionTreeRegressor</span><span class="p">,</span> <span class="n">plot_tree</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">r2_score</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">mean_absolute_error</span>

<span class="c1"># Already have X and y from Step 1 feature engineering</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"=== DECISION TREE IMPLEMENTATION ===</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Create chronological train-test split (80/20) for honest evaluation</span>
<span class="c1"># Time series data requires chronological splitting to prevent temporal leakage</span>
<span class="n">split_index</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.8</span><span class="p">)</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="n">split_index</span><span class="p">]</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">split_index</span><span class="p">:]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="n">split_index</span><span class="p">]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">split_index</span><span class="p">:]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Training set: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> observations (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%)"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Testing set:  </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> observations (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%)"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Training period: </span><span class="si">{</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="n">split_index</span><span class="p">][</span><span class="s1">'datetime'</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">}</span><span class="s2"> to </span><span class="si">{</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="n">split_index</span><span class="p">][</span><span class="s1">'datetime'</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Testing period:  </span><span class="si">{</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">split_index</span><span class="p">:][</span><span class="s1">'datetime'</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">}</span><span class="s2"> to </span><span class="si">{</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">split_index</span><span class="p">:][</span><span class="s1">'datetime'</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="c1"># Decision Tree with unlimited depth (demonstrating overfitting potential)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"--- Training Decision Tree (Unlimited Depth) ---"</span><span class="p">)</span>
<span class="c1"># DecisionTreeRegressor creates a tree that recursively partitions feature space</span>
<span class="c1"># to minimize mean squared error within each region (leaf node)</span>
<span class="n">tree_unlimited</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="c1"># No max_depth specified = tree grows until leaves are pure or contain min_samples_split</span>
<span class="n">tree_unlimited</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Examine tree structure to understand model complexity</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Tree depth: </span><span class="si">{</span><span class="n">tree_unlimited</span><span class="o">.</span><span class="n">get_depth</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Number of leaves: </span><span class="si">{</span><span class="n">tree_unlimited</span><span class="o">.</span><span class="n">get_n_leaves</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Total nodes: </span><span class="si">{</span><span class="n">tree_unlimited</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">node_count</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="c1"># Generate predictions on both training and testing sets</span>
<span class="n">train_pred_unlimited</span> <span class="o">=</span> <span class="n">tree_unlimited</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">test_pred_unlimited</span> <span class="o">=</span> <span class="n">tree_unlimited</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Calculate performance metrics</span>
<span class="n">train_r2_unlimited</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">train_pred_unlimited</span><span class="p">)</span>
<span class="n">test_r2_unlimited</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">test_pred_unlimited</span><span class="p">)</span>
<span class="n">train_rmse_unlimited</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">train_pred_unlimited</span><span class="p">))</span>
<span class="n">test_rmse_unlimited</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">test_pred_unlimited</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"=== DECISION TREE PERFORMANCE (Unlimited Depth) ==="</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Training:  RÂ² = </span><span class="si">{</span><span class="n">train_r2_unlimited</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, RMSE = </span><span class="si">{</span><span class="n">train_rmse_unlimited</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> bikes"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Testing:   RÂ² = </span><span class="si">{</span><span class="n">test_r2_unlimited</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, RMSE = </span><span class="si">{</span><span class="n">test_rmse_unlimited</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> bikes"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Overfit gap: </span><span class="si">{</span><span class="n">train_r2_unlimited</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">test_r2_unlimited</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="k">if</span> <span class="p">(</span><span class="n">train_r2_unlimited</span> <span class="o">-</span> <span class="n">test_r2_unlimited</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.30</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"âš  SEVERE OVERFITTING DETECTED:"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  â€¢ Training RÂ² near-perfect (</span><span class="si">{</span><span class="n">train_r2_unlimited</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2">) but testing RÂ² only </span><span class="si">{</span><span class="n">test_r2_unlimited</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  â€¢ Gap of </span><span class="si">{</span><span class="n">train_r2_unlimited</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">test_r2_unlimited</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2"> indicates memorization, not learning"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  â€¢ Tree depth of </span><span class="si">{</span><span class="n">tree_unlimited</span><span class="o">.</span><span class="n">get_depth</span><span class="p">()</span><span class="si">}</span><span class="s2"> with </span><span class="si">{</span><span class="n">tree_unlimited</span><span class="o">.</span><span class="n">get_n_leaves</span><span class="p">()</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> leaves creates overly specific rules"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  â€¢ Solution: Limit tree depth or use ensemble methods (Random Forest)"</span><span class="p">)</span>
<span class="k">elif</span> <span class="p">(</span><span class="n">train_r2_unlimited</span> <span class="o">-</span> <span class="n">test_r2_unlimited</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.15</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"âš  MODERATE OVERFITTING:"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  â€¢ Performance gap suggests some memorization of training data"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  â€¢ Consider constraining tree depth or using regularization"</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"âœ“ Good generalization - training and testing performance similar"</span><span class="p">)</span>

<span class="nb">print</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"=== WHY SINGLE TREES OVERFIT ==="</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"â€¢ Decision trees recursively partition data until leaves are pure"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"â€¢ Unlimited depth = tree memorizes training data noise and outliers"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"â€¢ Result: Near-perfect training fit but poor generalization to new data"</span><span class="p">)</span>
</pre>
                      </div>
                    </div>
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing text_cell rendered"
                id="cell-id=c9111908"
                ><div class="prompt input_prompt"> </div
                ><div class="inner_cell">
                  <div class="text_cell_render border-box-sizing rendered_html">
                    <p><strong>What this does:</strong></p>
                    <ul>
                      <li
                        >Creates chronological 80/20 train-test split preserving
                        temporal order for honest evaluation</li
                      >
                      <li
                        >Trains unlimited-depth decision tree showing severe
                        overfitting (training RÂ² â‰ˆ100%, test RÂ² â‰ˆ61%)</li
                      >
                      <li
                        >Displays tree structure metrics (depth, leaves, nodes)
                        revealing model complexity</li
                      >
                      <li
                        >Calculates overfit gap (train RÂ² - test RÂ²)
                        demonstrating why single trees struggle with
                        generalization</li
                      >
                      <li
                        >Shows that unlimited trees memorize training data
                        patterns rather than learning generalizable
                        relationships</li
                      >
                    </ul>
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing text_cell rendered"
                id="cell-id=3a35e605"
                ><div class="prompt input_prompt"> </div
                ><div class="inner_cell">
                  <div class="text_cell_render border-box-sizing rendered_html">
                    <h3 id="Challenge-2:-Visualize-Decision-Tree-Structure"
                      >Challenge 2: Visualize Decision Tree Structure<a
                        class="anchor-link"
                        href="#Challenge-2:-Visualize-Decision-Tree-Structure"
                      ></a></h3
                    ><p
                      >Your client asks: "Can you show me how the tree makes
                      decisions? I want to understand the business rules it
                      learned." Create a visualization of a shallow tree for
                      interpretability.</p
                    >
                    <p
                      ><strong>Your Task:</strong> Train a very shallow tree
                      (max_depth=3) and visualize its structure with feature
                      names and decision thresholds.</p
                    >
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing code_cell rendered"
                id="cell-id=60aed956"
              >
                <div class="input">
                  <div class="prompt input_prompt">InÂ [Â ]:</div>
                  <div class="inner_cell">
                    <div class="input_area">
                      <div class="highlight hl-ipython3">
                        <pre><span></span><span class="c1"># Your code here - create and visualize shallow decision tree</span>

<span class="c1"># Train a shallow tree for visualization (max_depth=3 for clarity)</span>
<span class="n">tree_shallow</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="n">___</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">tree_shallow</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Calculate performance of shallow tree</span>
<span class="n">test_pred_shallow</span> <span class="o">=</span> <span class="n">tree_shallow</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">test_r2_shallow</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">test_pred_shallow</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"=== SHALLOW TREE (max_depth=3) ==="</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Tree depth: </span><span class="si">{</span><span class="n">tree_shallow</span><span class="o">.</span><span class="n">get_depth</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Number of leaves: </span><span class="si">{</span><span class="n">tree_shallow</span><span class="o">.</span><span class="n">get_n_leaves</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Test RÂ²: </span><span class="si">{</span><span class="n">test_r2_shallow</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="c1"># Visualize tree structure</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">plot_tree</span><span class="p">(</span><span class="n">tree_shallow</span><span class="p">,</span>
          <span class="n">feature_names</span><span class="o">=</span><span class="n">_____</span><span class="p">,</span>
          <span class="n">filled</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
          <span class="n">rounded</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
          <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Decision Tree Structure (max_depth=3) - Interpretable Business Rules'</span><span class="p">,</span>
          <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">'bold'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Extract conclusions from the tree</span>
<span class="c1"># Tips for extracting conclusions:</span>
<span class="c1"># - Examine the root node (top) - which feature does it split on first?</span>
<span class="c1"># - Follow the decision paths from root to leaves - what conditions lead to high vs low demand?</span>
<span class="c1"># - Look at node colors - darker nodes predict higher demand, lighter nodes predict lower demand</span>
<span class="c1"># - Translate 2-3 complete paths into business rules (e.g., "If hour &lt;= X AND temp &gt; Y â†’ Predict Z bikes")</span>
<span class="c1"># - Identify practical patterns (rush hour behavior, weather impact, weekday vs weekend differences)</span>
</pre>
                      </div>
                    </div>
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing text_cell rendered"
                id="cell-id=528babcb"
                ><div class="prompt input_prompt"> </div
                ><div class="inner_cell">
                  <div class="text_cell_render border-box-sizing rendered_html">
                    <details>
                      <summary
                        >ðŸ’¡ <strong>Tip</strong> (click to expand)</summary
                      >
                      <p
                        >Use <code>max_depth=3</code> to create a tree shallow
                        enough to visualize clearly on one page. The
                        <code>plot_tree()</code> function requires
                        <code>feature_names=feature_columns</code> (the list of
                        column names you defined in Step 1) to display readable
                        feature labels instead of generic "X[0]" notation. Set
                        <code>filled=True</code> to color nodes by prediction
                        value (darker colors = higher predicted demand) and
                        <code>rounded=True</code> for professional appearance.
                        After visualization, use
                        <code>tree_shallow.feature_importances_</code> to
                        extract which features appear most frequently in the top
                        splits - these are the key drivers the tree identified.
                        A shallow tree sacrifices accuracy for interpretability,
                        so expect test RÂ² around 30-40% (much lower than deeper
                        trees) but you gain the ability to communicate exact
                        decision logic to stakeholders. The visualization will
                        show the actual decision paths - for example, the root
                        node might split on hour to separate night/early morning
                        from daytime periods. These are the if-then business
                        rules your operations team can actually use for
                        planning.</p
                      >
                    </details>
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing text_cell rendered"
                id="cell-id=655d36fa"
                ><div class="prompt input_prompt"> </div
                ><div class="inner_cell">
                  <div class="text_cell_render border-box-sizing rendered_html">
                    <details>
                      <summary
                        >ðŸ¤« <strong>Solution</strong> (click to expand)</summary
                      >
                      <div class="highlight">
                        <pre><span></span><span class="c1"># Train a shallow tree for visualization (max_depth=3 for clarity)</span>
<span class="n">tree_shallow</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">tree_shallow</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Calculate performance of shallow tree</span>
<span class="n">test_pred_shallow</span> <span class="o">=</span> <span class="n">tree_shallow</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">test_r2_shallow</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">test_pred_shallow</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"=== SHALLOW TREE (max_depth=3) ==="</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Tree depth: </span><span class="si">{</span><span class="n">tree_shallow</span><span class="o">.</span><span class="n">get_depth</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Number of leaves: </span><span class="si">{</span><span class="n">tree_shallow</span><span class="o">.</span><span class="n">get_n_leaves</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Test RÂ²: </span><span class="si">{</span><span class="n">test_r2_shallow</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="c1"># Visualize tree structure</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">plot_tree</span><span class="p">(</span><span class="n">tree_shallow</span><span class="p">,</span>
          <span class="n">feature_names</span><span class="o">=</span><span class="n">feature_columns</span><span class="p">,</span>
          <span class="n">filled</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
          <span class="n">rounded</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
          <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Decision Tree Structure (max_depth=3) - Interpretable Business Rules'</span><span class="p">,</span>
          <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">'bold'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Extract conclusions from the tree</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"=== BUSINESS RULE TRANSLATION ==="</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"The tree makes decisions using if-then logic:"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"â€¢ Root node: Splits on most predictive feature (likely 'hour' or 'atemp')"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"â€¢ Each split creates two branches: one for observations meeting condition, one for those that don't"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"â€¢ Leaf nodes (colored boxes): Final demand predictions for observations reaching that leaf"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"â€¢ Node color intensity: Darker = higher predicted demand, Lighter = lower predicted demand"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Example interpretation (based on the actual tree above):"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"'If hour &lt;= 6.5 AND workingday_hour &lt;= 0.5 â†’ Predict ~37 bikes/hour (weekend early morning)'"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"'If hour &gt; 6.5 AND atemp &gt; 23 AND is_rush_hour &gt; 0.5 â†’ Predict ~294 bikes/hour (warm rush hour)'"</span><span class="p">)</span>
</pre>
                      </div>
                    </details>
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing text_cell rendered"
                id="cell-id=fa2d973e"
                ><div class="prompt input_prompt"> </div
                ><div class="inner_cell">
                  <div class="text_cell_render border-box-sizing rendered_html">
                    <hr />
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing text_cell rendered"
                id="cell-id=f8ddac51"
                ><div class="prompt input_prompt"> </div
                ><div class="inner_cell">
                  <div class="text_cell_render border-box-sizing rendered_html">
                    <h2 id="Step-3:-Deploy-Random-Forest-Ensemble"
                      >Step 3: Deploy Random Forest Ensemble<a
                        class="anchor-link"
                        href="#Step-3:-Deploy-Random-Forest-Ensemble"
                      ></a></h2
                    ><p
                      >Let's implement Random Forest to overcome individual tree
                      overfitting through ensemble averaging of multiple diverse
                      trees.</p
                    >
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing code_cell rendered"
                id="cell-id=d2eda9e2"
              >
                <div class="input">
                  <div class="prompt input_prompt">InÂ [Â ]:</div>
                  <div class="inner_cell">
                    <div class="input_area">
                      <div class="highlight hl-ipython3">
                        <pre><span></span><span class="c1"># Import Random Forest from scikit-learn's ensemble module</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.ensemble</span><span class="w"> </span><span class="kn">import</span> <span class="n">RandomForestRegressor</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"=== RANDOM FOREST ENSEMBLE IMPLEMENTATION ===</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Train Random Forest with default parameters first</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"--- Training Random Forest (Default: 100 trees) ---"</span><span class="p">)</span>
<span class="c1"># RandomForestRegressor creates an ensemble of decision trees:</span>
<span class="c1"># - Each tree trains on a bootstrap sample (random sampling with replacement)</span>
<span class="c1"># - Each split considers only a subset of features (max_features='sqrt' by default)</span>
<span class="c1"># - Final prediction = average of all tree predictions (reduces variance)</span>
<span class="n">rf_default</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># n_estimators=100: Build 100 decision trees in the forest</span>
<span class="c1"># random_state=42: Ensures reproducible results across runs</span>
<span class="c1"># n_jobs=-1: Use all CPU cores for parallel training (speeds up computation)</span>
<span class="n">rf_default</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Forest size: </span><span class="si">{</span><span class="n">rf_default</span><span class="o">.</span><span class="n">n_estimators</span><span class="si">}</span><span class="s2"> trees"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Features considered per split: sqrt(</span><span class="si">{</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">) â‰ˆ </span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span><span class="si">}</span><span class="s2"> features"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="c1"># Generate predictions with Random Forest</span>
<span class="n">train_pred_rf</span> <span class="o">=</span> <span class="n">rf_default</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">test_pred_rf</span> <span class="o">=</span> <span class="n">rf_default</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">train_r2_rf</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">train_pred_rf</span><span class="p">)</span>
<span class="n">test_r2_rf</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">test_pred_rf</span><span class="p">)</span>
<span class="n">train_rmse_rf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">train_pred_rf</span><span class="p">))</span>
<span class="n">test_rmse_rf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">test_pred_rf</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"=== RANDOM FOREST PERFORMANCE ==="</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Training:  RÂ² = </span><span class="si">{</span><span class="n">train_r2_rf</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, RMSE = </span><span class="si">{</span><span class="n">train_rmse_rf</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> bikes"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Testing:   RÂ² = </span><span class="si">{</span><span class="n">test_r2_rf</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, RMSE = </span><span class="si">{</span><span class="n">test_rmse_rf</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> bikes"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Overfit gap: </span><span class="si">{</span><span class="n">train_r2_rf</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">test_r2_rf</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="c1"># Compare Random Forest vs Single Decision Tree</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"=== ALGORITHM PERFORMANCE COMPARISON ==="</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Model                          | Train RÂ²  | Test RÂ²   | Overfit Gap | Status"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"-"</span> <span class="o">*</span> <span class="mi">85</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Single Tree (Unlimited)        | </span><span class="si">{</span><span class="n">train_r2_unlimited</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">    | </span><span class="si">{</span><span class="n">test_r2_unlimited</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">    | </span><span class="si">{</span><span class="n">train_r2_unlimited</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">test_r2_unlimited</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">      | Severe Overfit"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Random Forest (100 trees)      | </span><span class="si">{</span><span class="n">train_r2_rf</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">    | </span><span class="si">{</span><span class="n">test_r2_rf</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">    | </span><span class="si">{</span><span class="n">train_r2_rf</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">test_r2_rf</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">      | Good Balance"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="c1"># Calculate competitive advantages for business reporting</span>
<span class="n">test_improvement_vs_tree</span> <span class="o">=</span> <span class="p">(</span><span class="n">test_r2_rf</span> <span class="o">-</span> <span class="n">test_r2_unlimited</span><span class="p">)</span> <span class="o">/</span> <span class="n">test_r2_unlimited</span> <span class="o">*</span> <span class="mi">100</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"=== RANDOM FOREST COMPETITIVE ADVANTAGES ==="</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Test RÂ² improvement vs single tree: </span><span class="si">{</span><span class="n">test_improvement_vs_tree</span><span class="si">:</span><span class="s2">+.1f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Overfit gap reduction: </span><span class="si">{</span><span class="n">train_r2_unlimited</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">test_r2_unlimited</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> â†’ </span><span class="si">{</span><span class="n">train_r2_rf</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">test_r2_rf</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="k">if</span> <span class="n">test_r2_rf</span> <span class="o">&gt;=</span> <span class="mf">0.85</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"âœ“ EXCELLENT PERFORMANCE:"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"  â€¢ Test RÂ² â‰¥ 85% meets Series B investor expectations"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"  â€¢ Production-ready accuracy for operational deployment"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"  â€¢ Competitive advantage over linear baseline established"</span><span class="p">)</span>
<span class="k">elif</span> <span class="n">test_r2_rf</span> <span class="o">&gt;=</span> <span class="mf">0.75</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"âœ“ STRONG PERFORMANCE:"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"  â€¢ Test RÂ² â‰¥ 75</span><span class="si">% r</span><span class="s2">epresents significant improvement"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"  â€¢ Suitable for operational planning and strategic decision-making"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"  â€¢ Demonstrates advanced ML capabilities to stakeholders"</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"âš  MODERATE PERFORMANCE:"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"  â€¢ Test RÂ² suggests room for further optimization"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"  â€¢ Consider additional feature engineering"</span><span class="p">)</span>

<span class="nb">print</span><span class="p">()</span>

<span class="c1"># Demonstrate ensemble diversity by examining individual tree predictions</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"=== ENSEMBLE DIVERSITY DEMONSTRATION ==="</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Examining predictions from first 10 trees for one observation:"</span><span class="p">)</span>
<span class="n">example_obs</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Example observation features:"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Hour: </span><span class="si">{</span><span class="n">example_obs</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">, Temp: </span><span class="si">{</span><span class="n">example_obs</span><span class="p">[</span><span class="s1">'temp'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">Â°C, "</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Working day: </span><span class="si">{</span><span class="n">example_obs</span><span class="p">[</span><span class="s1">'workingday'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">, Rush hour: </span><span class="si">{</span><span class="n">example_obs</span><span class="p">[</span><span class="s1">'is_rush_hour'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="n">tree_predictions</span> <span class="o">=</span> <span class="p">[]</span>
<span class="c1"># Convert to numpy array once to avoid feature name warnings</span>
<span class="n">example_obs_array</span> <span class="o">=</span> <span class="n">example_obs</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">rf_default</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">)):</span>
    <span class="c1"># Each tree in the forest makes independent predictions</span>
    <span class="n">tree_pred</span> <span class="o">=</span> <span class="n">rf_default</span><span class="o">.</span><span class="n">estimators_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">example_obs_array</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">tree_predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tree_pred</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Tree </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">:</span><span class="s2">2d</span><span class="si">}</span><span class="s2"> predicts: </span><span class="si">{</span><span class="n">tree_pred</span><span class="si">:</span><span class="s2">6.1f</span><span class="si">}</span><span class="s2"> bikes"</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Average of 10 trees:  </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">tree_predictions</span><span class="p">)</span><span class="si">:</span><span class="s2">6.1f</span><span class="si">}</span><span class="s2"> bikes"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Full ensemble (100):  </span><span class="si">{</span><span class="n">rf_default</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">example_obs</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">6.1f</span><span class="si">}</span><span class="s2"> bikes"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Prediction spread:    </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">tree_predictions</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">tree_predictions</span><span class="p">)</span><span class="si">:</span><span class="s2">6.1f</span><span class="si">}</span><span class="s2"> bikes"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Standard deviation:   </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">tree_predictions</span><span class="p">)</span><span class="si">:</span><span class="s2">6.1f</span><span class="si">}</span><span class="s2"> bikes"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"WHY DIVERSITY MATTERS:"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"â€¢ Each tree sees different bootstrap sample (random observations)"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"â€¢ Each split uses different random feature subset"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"â€¢ Individual trees make different predictions (some high, some low)"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"â€¢ Averaging cancels individual errors â†’ more stable, reliable forecast"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"â€¢ This is the 'wisdom of crowds' principle: collective intelligence &gt; individual guesses"</span><span class="p">)</span>
</pre>
                      </div>
                    </div>
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing text_cell rendered"
                id="cell-id=3896f823"
                ><div class="prompt input_prompt"> </div
                ><div class="inner_cell">
                  <div class="text_cell_render border-box-sizing rendered_html">
                    <p><strong>What this does:</strong></p>
                    <ul>
                      <li
                        >Trains Random Forest with 100 trees using bootstrap
                        sampling and feature randomness</li
                      >
                      <li
                        >Evaluates on both training and testing sets showing
                        reduced overfitting vs. single tree</li
                      >
                      <li
                        >Compares performance against unlimited decision tree
                        demonstrating ensemble advantages</li
                      >
                      <li
                        >Shows individual tree predictions for one observation
                        revealing diversity in the forest</li
                      >
                      <li
                        >Calculates prediction spread and standard deviation
                        quantifying ensemble variance reduction</li
                      >
                    </ul>
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing text_cell rendered"
                id="cell-id=77e2c774"
                ><div class="prompt input_prompt"> </div
                ><div class="inner_cell">
                  <div class="text_cell_render border-box-sizing rendered_html">
                    <h3 id="Challenge-3:-Compare-Different-Ensemble-Sizes"
                      >Challenge 3: Compare Different Ensemble Sizes<a
                        class="anchor-link"
                        href="#Challenge-3:-Compare-Different-Ensemble-Sizes"
                      ></a></h3
                    ><p
                      >Your client asks: "Do we really need 100 trees? Could we
                      get similar performance with fewer trees (faster training)
                      or do we need more trees for better accuracy?" Experiment
                      with ensemble size.</p
                    >
                    <p
                      ><strong>Your Task:</strong> Train Random Forests with
                      different numbers of trees (10, 50, 100, 200, 300) and
                      analyze the performance vs. training time tradeoff.</p
                    >
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing code_cell rendered"
                id="cell-id=8483db8b"
              >
                <div class="input">
                  <div class="prompt input_prompt">InÂ [Â ]:</div>
                  <div class="inner_cell">
                    <div class="input_area">
                      <div class="highlight hl-ipython3">
                        <pre><span></span><span class="c1"># Your code here - compare different ensemble sizes</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.ensemble</span><span class="w"> </span><span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">r2_score</span><span class="p">,</span> <span class="n">mean_squared_error</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># Load and prepare data (condensed version - run Steps 1-3 above for full feature engineering)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">"https://raw.githubusercontent.com/pmarcelino/predictive-modeling/main/datasets/dataset.csv"</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'datetime'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'datetime'</span><span class="p">])</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">'datetime'</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Create essential features</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'datetime'</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">hour</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'dayofweek'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'datetime'</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">dayofweek</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'month'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'datetime'</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">month</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'is_rush_hour'</span><span class="p">]</span> <span class="o">=</span> <span class="p">((</span><span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">7</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">9</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">17</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">19</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'is_weekend'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'dayofweek'</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'is_night'</span><span class="p">]</span> <span class="o">=</span> <span class="p">((</span><span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">22</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">5</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'weather_severity'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'weather'</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">({</span><span class="mi">1</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">:</span> <span class="mi">3</span><span class="p">})</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'temp_hour_interaction'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'temp'</span><span class="p">]</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'workingday_hour'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'workingday'</span><span class="p">]</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'season_weather'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'season'</span><span class="p">]</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="s1">'weather_severity'</span><span class="p">]</span>

<span class="c1"># Prepare feature matrix</span>
<span class="n">feature_columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'temp'</span><span class="p">,</span> <span class="s1">'atemp'</span><span class="p">,</span> <span class="s1">'humidity'</span><span class="p">,</span> <span class="s1">'windspeed'</span><span class="p">,</span> <span class="s1">'weather_severity'</span><span class="p">,</span>
                   <span class="s1">'hour'</span><span class="p">,</span> <span class="s1">'dayofweek'</span><span class="p">,</span> <span class="s1">'month'</span><span class="p">,</span> <span class="s1">'season'</span><span class="p">,</span>
                   <span class="s1">'workingday'</span><span class="p">,</span> <span class="s1">'holiday'</span><span class="p">,</span> <span class="s1">'is_rush_hour'</span><span class="p">,</span> <span class="s1">'is_weekend'</span><span class="p">,</span> <span class="s1">'is_night'</span><span class="p">,</span>
                   <span class="s1">'temp_hour_interaction'</span><span class="p">,</span> <span class="s1">'workingday_hour'</span><span class="p">,</span> <span class="s1">'season_weather'</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">feature_columns</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'count'</span><span class="p">]</span>

<span class="c1"># Create train-test split</span>
<span class="n">split_index</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.8</span><span class="p">)</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="n">split_index</span><span class="p">]</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">split_index</span><span class="p">:]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="n">split_index</span><span class="p">]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">split_index</span><span class="p">:]</span>

<span class="c1"># Now compare different ensemble sizes</span>
<span class="n">ensemble_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">300</span><span class="p">]</span>
<span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">n_trees</span> <span class="ow">in</span> <span class="n">ensemble_sizes</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Training Random Forest with </span><span class="si">{</span><span class="n">n_trees</span><span class="si">}</span><span class="s2"> trees..."</span><span class="p">)</span>

    <span class="c1"># Time the training process</span>
    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">rf_temp</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="n">_____</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">rf_temp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">training_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>

    <span class="c1"># Evaluate performance</span>
    <span class="n">test_pred_temp</span> <span class="o">=</span> <span class="n">rf_temp</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">test_r2_temp</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">test_pred_temp</span><span class="p">)</span>
    <span class="n">test_rmse_temp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">test_pred_temp</span><span class="p">))</span>

    <span class="c1"># Store results</span>
    <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
        <span class="s1">'n_trees'</span><span class="p">:</span> <span class="n">n_trees</span><span class="p">,</span>
        <span class="s1">'training_time'</span><span class="p">:</span> <span class="n">training_time</span><span class="p">,</span>
        <span class="s1">'test_r2'</span><span class="p">:</span> <span class="n">test_r2_temp</span><span class="p">,</span>
        <span class="s1">'test_rmse'</span><span class="p">:</span> <span class="n">test_rmse_temp</span>
    <span class="p">})</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Training time: </span><span class="si">{</span><span class="n">training_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">s, Test RÂ²: </span><span class="si">{</span><span class="n">test_r2_temp</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>

<span class="c1"># Visualize performance vs ensemble size</span>
<span class="n">results_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="c1"># Panel 1: Test RÂ² vs ensemble size</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">results_df</span><span class="p">[</span><span class="s1">'n_trees'</span><span class="p">],</span> <span class="n">results_df</span><span class="p">[</span><span class="s1">'test_r2'</span><span class="p">],</span> <span class="s1">'o-'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'darkgreen'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'Number of Trees'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'Test RÂ²'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'Test Performance vs Ensemble Size'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">'bold'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="c1"># Panel 2: Training time vs ensemble size</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">results_df</span><span class="p">[</span><span class="s1">'n_trees'</span><span class="p">],</span> <span class="n">results_df</span><span class="p">[</span><span class="s1">'training_time'</span><span class="p">],</span> <span class="s1">'s-'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'darkorange'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'Number of Trees'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'Training Time (seconds)'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'Training Time vs Ensemble Size'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">'bold'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Business recommendation</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"=== ENSEMBLE SIZE RECOMMENDATION ==="</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">results_df</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
</pre>
                      </div>
                    </div>
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing text_cell rendered"
                id="cell-id=7eecc792"
                ><div class="prompt input_prompt"> </div
                ><div class="inner_cell">
                  <div class="text_cell_render border-box-sizing rendered_html">
                    <details>
                      <summary
                        >ðŸ’¡ <strong>Tip</strong> (click to expand)</summary
                      >
                      <p
                        >Loop through each ensemble size and create a fresh
                        <code
                          >RandomForestRegressor(n_estimators=n_trees,
                          random_state=42, n_jobs=-1)</code
                        >
                        for each iteration. Use <code>time.time()</code> before
                        and after <code>.fit()</code> to measure training
                        duration:
                        <code
                          >start = time.time(); model.fit(X, y); duration =
                          time.time() - start</code
                        >. Store all results in a list of dictionaries, then
                        convert to DataFrame for easy analysis and
                        visualization. The performance curve typically shows
                        diminishing returns: 10â†’50 trees gives large
                        improvement, 100â†’200 gives small improvement, 200â†’300
                        gives minimal improvement. Training time increases
                        linearly with tree count (200 trees takes ~2x as long as
                        100 trees) so there's a clear tradeoff. Business
                        insight: 100-200 trees usually provides the sweet spot -
                        excellent performance without excessive training time.
                        For production deployment, consider whether faster
                        predictions (fewer trees) or maximum accuracy (more
                        trees) matters more to your client's use case. If they
                        need real-time predictions for millions of users, fewer
                        trees might be preferable; if they're doing daily batch
                        forecasting for operational planning, more trees at
                        higher accuracy makes sense.</p
                      >
                    </details>
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing text_cell rendered"
                id="cell-id=eb5b7bcf"
                ><div class="prompt input_prompt"> </div
                ><div class="inner_cell">
                  <div class="text_cell_render border-box-sizing rendered_html">
                    <details>
                      <summary
                        >ðŸ¤« <strong>Solution</strong> (click to expand)</summary
                      >
                      <div class="highlight">
                        <pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.ensemble</span><span class="w"> </span><span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">r2_score</span><span class="p">,</span> <span class="n">mean_squared_error</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># Load and prepare data</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">"https://raw.githubusercontent.com/pmarcelino/predictive-modeling/main/datasets/dataset.csv"</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'datetime'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'datetime'</span><span class="p">])</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">'datetime'</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Create essential features</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'datetime'</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">hour</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'dayofweek'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'datetime'</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">dayofweek</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'month'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'datetime'</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">month</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'is_rush_hour'</span><span class="p">]</span> <span class="o">=</span> <span class="p">((</span><span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">7</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">9</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">17</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">19</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'is_weekend'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'dayofweek'</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'is_night'</span><span class="p">]</span> <span class="o">=</span> <span class="p">((</span><span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">22</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">5</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'weather_severity'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'weather'</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">({</span><span class="mi">1</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">:</span> <span class="mi">3</span><span class="p">})</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'temp_hour_interaction'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'temp'</span><span class="p">]</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'workingday_hour'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'workingday'</span><span class="p">]</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'season_weather'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'season'</span><span class="p">]</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="s1">'weather_severity'</span><span class="p">]</span>

<span class="c1"># Prepare feature matrix</span>
<span class="n">feature_columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'temp'</span><span class="p">,</span> <span class="s1">'atemp'</span><span class="p">,</span> <span class="s1">'humidity'</span><span class="p">,</span> <span class="s1">'windspeed'</span><span class="p">,</span> <span class="s1">'weather_severity'</span><span class="p">,</span>
                   <span class="s1">'hour'</span><span class="p">,</span> <span class="s1">'dayofweek'</span><span class="p">,</span> <span class="s1">'month'</span><span class="p">,</span> <span class="s1">'season'</span><span class="p">,</span>
                   <span class="s1">'workingday'</span><span class="p">,</span> <span class="s1">'holiday'</span><span class="p">,</span> <span class="s1">'is_rush_hour'</span><span class="p">,</span> <span class="s1">'is_weekend'</span><span class="p">,</span> <span class="s1">'is_night'</span><span class="p">,</span>
                   <span class="s1">'temp_hour_interaction'</span><span class="p">,</span> <span class="s1">'workingday_hour'</span><span class="p">,</span> <span class="s1">'season_weather'</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">feature_columns</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'count'</span><span class="p">]</span>

<span class="c1"># Create train-test split</span>
<span class="n">split_index</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.8</span><span class="p">)</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="n">split_index</span><span class="p">]</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">split_index</span><span class="p">:]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="n">split_index</span><span class="p">]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">split_index</span><span class="p">:]</span>

<span class="c1"># Compare different ensemble sizes</span>
<span class="n">ensemble_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">300</span><span class="p">]</span>
<span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">n_trees</span> <span class="ow">in</span> <span class="n">ensemble_sizes</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Training Random Forest with </span><span class="si">{</span><span class="n">n_trees</span><span class="si">}</span><span class="s2"> trees..."</span><span class="p">)</span>

    <span class="c1"># Time the training process</span>
    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">rf_temp</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="n">n_trees</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">rf_temp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">training_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>

    <span class="c1"># Evaluate performance</span>
    <span class="n">test_pred_temp</span> <span class="o">=</span> <span class="n">rf_temp</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">test_r2_temp</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">test_pred_temp</span><span class="p">)</span>
    <span class="n">test_rmse_temp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">test_pred_temp</span><span class="p">))</span>

    <span class="c1"># Store results</span>
    <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
        <span class="s1">'n_trees'</span><span class="p">:</span> <span class="n">n_trees</span><span class="p">,</span>
        <span class="s1">'training_time'</span><span class="p">:</span> <span class="n">training_time</span><span class="p">,</span>
        <span class="s1">'test_r2'</span><span class="p">:</span> <span class="n">test_r2_temp</span><span class="p">,</span>
        <span class="s1">'test_rmse'</span><span class="p">:</span> <span class="n">test_rmse_temp</span>
    <span class="p">})</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Training time: </span><span class="si">{</span><span class="n">training_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">s, Test RÂ²: </span><span class="si">{</span><span class="n">test_r2_temp</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>

<span class="c1"># Visualize performance vs ensemble size</span>
<span class="n">results_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="c1"># Panel 1: Test RÂ² vs ensemble size</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">results_df</span><span class="p">[</span><span class="s1">'n_trees'</span><span class="p">],</span> <span class="n">results_df</span><span class="p">[</span><span class="s1">'test_r2'</span><span class="p">],</span> <span class="s1">'o-'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'darkgreen'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'Number of Trees'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'Test RÂ²'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'Test Performance vs Ensemble Size'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">'bold'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="c1"># Panel 2: Training time vs ensemble size</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">results_df</span><span class="p">[</span><span class="s1">'n_trees'</span><span class="p">],</span> <span class="n">results_df</span><span class="p">[</span><span class="s1">'training_time'</span><span class="p">],</span> <span class="s1">'s-'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'darkorange'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'Number of Trees'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'Training Time (seconds)'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'Training Time vs Ensemble Size'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">'bold'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Business recommendation</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"=== ENSEMBLE SIZE RECOMMENDATION ==="</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">results_df</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="nb">print</span><span class="p">()</span>

<span class="n">best_value_idx</span> <span class="o">=</span> <span class="n">results_df</span><span class="p">[</span><span class="s1">'test_r2'</span><span class="p">]</span><span class="o">.</span><span class="n">idxmax</span><span class="p">()</span>
<span class="n">best_value</span> <span class="o">=</span> <span class="n">results_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">best_value_idx</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"âœ“ Recommended: </span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">best_value</span><span class="p">[</span><span class="s1">'n_trees'</span><span class="p">])</span><span class="si">}</span><span class="s2"> trees"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  â€¢ Test RÂ²: </span><span class="si">{</span><span class="n">best_value</span><span class="p">[</span><span class="s1">'test_r2'</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  â€¢ Training time: </span><span class="si">{</span><span class="n">best_value</span><span class="p">[</span><span class="s1">'training_time'</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">s"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  â€¢ Rationale: </span><span class="si">{</span><span class="s1">'Excellent accuracy-speed balance'</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">best_value</span><span class="p">[</span><span class="s1">'n_trees'</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="mi">100</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">'Maximum accuracy justified for critical forecasting'</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre>
                      </div>
                    </details>
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing text_cell rendered"
                id="cell-id=53d53759"
                ><div class="prompt input_prompt"> </div
                ><div class="inner_cell">
                  <div class="text_cell_render border-box-sizing rendered_html">
                    <hr />
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing text_cell rendered"
                id="cell-id=31ddb3f8"
                ><div class="prompt input_prompt"> </div
                ><div class="inner_cell">
                  <div class="text_cell_render border-box-sizing rendered_html">
                    <h2 id="Step-4:-Feature-Importance-Analysis"
                      >Step 4: Feature Importance Analysis<a
                        class="anchor-link"
                        href="#Step-4:-Feature-Importance-Analysis"
                      ></a></h2
                    ><p
                      >Now that we've develop a Random Forest model and
                      optimized it, we can analyze which features drive bike
                      demand predictions. Understanding feature importance helps
                      guide strategic investments (e.g., which sensors to
                      maintain) and operational decisions (e.g., which
                      conditions to monitor most closely).</p
                    >
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing code_cell rendered"
                id="cell-id=69518e7b"
              >
                <div class="input">
                  <div class="prompt input_prompt">InÂ [Â ]:</div>
                  <div class="inner_cell">
                    <div class="input_area">
                      <div class="highlight hl-ipython3">
                        <pre><span></span><span class="c1"># Import libraries</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.ensemble</span><span class="w"> </span><span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">r2_score</span><span class="p">,</span> <span class="n">mean_squared_error</span>

<span class="c1"># Load and prepare data</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">"https://raw.githubusercontent.com/pmarcelino/predictive-modeling/main/datasets/dataset.csv"</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'datetime'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'datetime'</span><span class="p">])</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">'datetime'</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Feature engineering</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'datetime'</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">hour</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'dayofweek'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'datetime'</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">dayofweek</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'month'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'datetime'</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">month</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'year'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'datetime'</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">year</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'is_rush_hour'</span><span class="p">]</span> <span class="o">=</span> <span class="p">((</span><span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">7</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">9</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">17</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">19</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'is_weekend'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'dayofweek'</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'is_night'</span><span class="p">]</span> <span class="o">=</span> <span class="p">((</span><span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">22</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">5</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'weather_severity'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'weather'</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">({</span><span class="mi">1</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">:</span> <span class="mi">3</span><span class="p">})</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'temp_hour_interaction'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'temp'</span><span class="p">]</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'workingday_hour'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'workingday'</span><span class="p">]</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'season_weather'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'season'</span><span class="p">]</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="s1">'weather_severity'</span><span class="p">]</span>

<span class="c1"># Prepare features</span>
<span class="n">feature_columns</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">'temp'</span><span class="p">,</span> <span class="s1">'atemp'</span><span class="p">,</span> <span class="s1">'humidity'</span><span class="p">,</span> <span class="s1">'windspeed'</span><span class="p">,</span> <span class="s1">'weather_severity'</span><span class="p">,</span>
    <span class="s1">'hour'</span><span class="p">,</span> <span class="s1">'dayofweek'</span><span class="p">,</span> <span class="s1">'month'</span><span class="p">,</span> <span class="s1">'season'</span><span class="p">,</span>
    <span class="s1">'workingday'</span><span class="p">,</span> <span class="s1">'holiday'</span><span class="p">,</span> <span class="s1">'is_rush_hour'</span><span class="p">,</span> <span class="s1">'is_weekend'</span><span class="p">,</span> <span class="s1">'is_night'</span><span class="p">,</span>
    <span class="s1">'temp_hour_interaction'</span><span class="p">,</span> <span class="s1">'workingday_hour'</span><span class="p">,</span> <span class="s1">'season_weather'</span>
<span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">feature_columns</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'count'</span><span class="p">]</span>

<span class="c1"># Train-test split</span>
<span class="n">split_index</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.8</span><span class="p">)</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="n">split_index</span><span class="p">]</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">split_index</span><span class="p">:]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="n">split_index</span><span class="p">]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">split_index</span><span class="p">:]</span>

<span class="c1"># Train Random Forest</span>
<span class="n">rf_default</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">rf_default</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Calculate performance for reference</span>
<span class="n">test_pred_rf</span> <span class="o">=</span> <span class="n">rf_default</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">test_r2_rf</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">test_pred_rf</span><span class="p">)</span>
<span class="n">test_rmse_rf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">test_pred_rf</span><span class="p">))</span>

<span class="c1"># Extract feature importance from trained Random Forest</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"=== RANDOM FOREST FEATURE IMPORTANCE ANALYSIS ===</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Feature importance based on mean decrease in impurity (MDI)</span>
<span class="c1"># Higher values = feature contributed more to prediction accuracy across all trees</span>
<span class="n">feature_importance</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">'feature'</span><span class="p">:</span> <span class="n">feature_columns</span><span class="p">,</span>
    <span class="s1">'importance'</span><span class="p">:</span> <span class="n">rf_default</span><span class="o">.</span><span class="n">feature_importances_</span>
<span class="p">})</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">'importance'</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"--- Feature Importance Rankings ---"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="s1">'Rank'</span><span class="si">:</span><span class="s2">&lt;6</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">'Feature'</span><span class="si">:</span><span class="s2">&lt;25</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">'Importance'</span><span class="si">:</span><span class="s2">&lt;12</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">'Percentage'</span><span class="si">:</span><span class="s2">&lt;12</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">'Visual'</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"-"</span> <span class="o">*</span> <span class="mi">75</span><span class="p">)</span>

<span class="k">for</span> <span class="n">rank</span><span class="p">,</span> <span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">row</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">feature_importance</span><span class="o">.</span><span class="n">iterrows</span><span class="p">(),</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">bar</span> <span class="o">=</span> <span class="s1">'â–ˆ'</span> <span class="o">*</span> <span class="nb">int</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">'importance'</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">percentage</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s1">'importance'</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">rank</span><span class="si">:</span><span class="s2">&lt;6</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">row</span><span class="p">[</span><span class="s1">'feature'</span><span class="p">]</span><span class="si">:</span><span class="s2">&lt;25</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">row</span><span class="p">[</span><span class="s1">'importance'</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">       </span><span class="si">{</span><span class="n">percentage</span><span class="si">:</span><span class="s2">&gt;6.2f</span><span class="si">}</span><span class="s2">%        </span><span class="si">{</span><span class="n">bar</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="nb">print</span><span class="p">()</span>

<span class="c1"># Calculate cumulative importance to identify critical feature subset</span>
<span class="n">feature_importance</span><span class="p">[</span><span class="s1">'cumulative'</span><span class="p">]</span> <span class="o">=</span> <span class="n">feature_importance</span><span class="p">[</span><span class="s1">'importance'</span><span class="p">]</span><span class="o">.</span><span class="n">cumsum</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"--- Cumulative Importance Analysis ---"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">feature_importance</span><span class="p">))):</span>
    <span class="n">feature_name</span> <span class="o">=</span> <span class="n">feature_importance</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">'feature'</span><span class="p">]</span>
    <span class="n">cumulative</span> <span class="o">=</span> <span class="n">feature_importance</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">'cumulative'</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Top </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2"> feature(s): </span><span class="si">{</span><span class="n">cumulative</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2"> of total predictive power"</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">cumulative</span> <span class="o">&gt;=</span> <span class="mf">0.80</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  â†’ </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2"> features capture 80% of model intelligence"</span><span class="p">)</span>
        <span class="k">break</span>

<span class="nb">print</span><span class="p">()</span>

<span class="c1"># Visualize feature importance</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="c1"># Panel 1: Horizontal bar chart of top 10 features</span>
<span class="n">top_features</span> <span class="o">=</span> <span class="n">feature_importance</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">colors</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">viridis</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">top_features</span><span class="p">)))</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">top_features</span><span class="p">)),</span> <span class="n">top_features</span><span class="p">[</span><span class="s1">'importance'</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">top_features</span><span class="p">)))</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">top_features</span><span class="p">[</span><span class="s1">'feature'</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">()</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'Importance Score'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'Top 10 Feature Importance'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">'bold'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s1">'x'</span><span class="p">)</span>

<span class="c1"># Panel 2: Cumulative importance curve</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">feature_importance</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">feature_importance</span><span class="p">[</span><span class="s1">'cumulative'</span><span class="p">],</span>
             <span class="s1">'o-'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'darkgreen'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mf">0.80</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">'--'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'80% threshold'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mf">0.90</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'orange'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">'--'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'90% threshold'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'Number of Top Features'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'Cumulative Importance'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'Cumulative Feature Contribution'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">'bold'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"=== BUSINESS INSIGHTS FOR CAPITAL CITY BIKES ==="</span><span class="p">)</span>

<span class="c1"># Interpret top 3 features for strategic recommendations</span>
<span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">feature_importance</span><span class="p">))):</span>
    <span class="n">feature</span> <span class="o">=</span> <span class="n">feature_importance</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">rank</span><span class="p">][</span><span class="s1">'feature'</span><span class="p">]</span>
    <span class="n">importance</span> <span class="o">=</span> <span class="n">feature_importance</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">rank</span><span class="p">][</span><span class="s1">'importance'</span><span class="p">]</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="si">{</span><span class="n">rank</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">. </span><span class="si">{</span><span class="n">feature</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">importance</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2"> importance"</span><span class="p">)</span>

    <span class="c1"># Business interpretation by feature type</span>
    <span class="k">if</span> <span class="n">feature</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'hour'</span><span class="p">,</span> <span class="s1">'is_rush_hour'</span><span class="p">]:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"   â†’ IMPLICATION: Time-of-day dominates demand patterns"</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"   â†’ STRATEGY: Optimize fleet positioning by hour (rush hours critical)"</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"   â†’ INVESTMENT: Real-time repositioning systems, surge pricing algorithms"</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">feature</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'temp'</span><span class="p">,</span> <span class="s1">'atemp'</span><span class="p">]:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"   â†’ IMPLICATION: Temperature drives cycling comfort decisions"</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"   â†’ STRATEGY: Weather-responsive capacity planning"</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"   â†’ INVESTMENT: Weather API integration, temperature-based forecasting"</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">feature</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'workingday'</span><span class="p">,</span> <span class="s1">'dayofweek'</span><span class="p">,</span> <span class="s1">'is_weekend'</span><span class="p">]:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"   â†’ IMPLICATION: Commuter vs. leisure patterns differ fundamentally"</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"   â†’ STRATEGY: Separate weekday (commute) vs. weekend (leisure) operations"</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"   â†’ INVESTMENT: Day-specific marketing, differential pricing strategies"</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">feature</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'season'</span><span class="p">,</span> <span class="s1">'month'</span><span class="p">]:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"   â†’ IMPLICATION: Seasonal variations require long-term planning"</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"   â†’ STRATEGY: Adjust fleet size, maintenance schedules by season"</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"   â†’ INVESTMENT: Seasonal fleet scaling, predictive maintenance"</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">feature</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'weather_severity'</span><span class="p">,</span> <span class="s1">'humidity'</span><span class="p">,</span> <span class="s1">'windspeed'</span><span class="p">]:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"   â†’ IMPLICATION: Weather conditions directly impact usage decisions"</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"   â†’ STRATEGY: Dynamic bike redistribution based on forecasts"</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"   â†’ INVESTMENT: Weather-triggered alerts, covered bike stations"</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"   â†’ IMPLICATION: Feature provides supplementary predictive value"</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"   â†’ STRATEGY: Maintain in model for accuracy gains"</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span> <span class="o">+</span> <span class="s2">"="</span><span class="o">*</span><span class="mi">75</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"STRATEGIC RECOMMENDATION:"</span><span class="p">)</span>
<span class="n">top_feature</span> <span class="o">=</span> <span class="n">feature_importance</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">'feature'</span><span class="p">]</span>
<span class="n">top_importance</span> <span class="o">=</span> <span class="n">feature_importance</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">'importance'</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"âœ“ '</span><span class="si">{</span><span class="n">top_feature</span><span class="si">}</span><span class="s2">' dominates with </span><span class="si">{</span><span class="n">top_importance</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2"> importance"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"âœ“ Top 3 features capture </span><span class="si">{</span><span class="n">feature_importance</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="s1">'cumulative'</span><span class="p">]</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2"> of predictive power"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"âœ“ Top 7 features capture more than 80% of predictive power and the top 10 features capture more than 90% of predictive power"</span><span class="p">)</span>
</pre>
                      </div>
                    </div>
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing text_cell rendered"
                id="cell-id=4af874d4"
                ><div class="prompt input_prompt"> </div
                ><div class="inner_cell">
                  <div class="text_cell_render border-box-sizing rendered_html">
                    <p><strong>What this does:</strong></p>
                    <ul>
                      <li
                        >Extracts <code>.feature_importances_</code> from
                        trained Random Forest showing MDI (Mean Decrease in
                        Impurity) scores</li
                      >
                      <li
                        >Displays ranked table with importance scores,
                        percentages, and visual bars for quick
                        interpretation</li
                      >
                      <li
                        >Calculates cumulative importance showing how many
                        features capture 80%/90% of predictive power</li
                      >
                      <li
                        >Creates two-panel visualization: horizontal bar chart
                        (top 10 features) and cumulative curve</li
                      >
                    </ul>
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing text_cell rendered"
                id="cell-id=1849e02c"
                ><div class="prompt input_prompt"> </div
                ><div class="inner_cell">
                  <div class="text_cell_render border-box-sizing rendered_html">
                    <h3
                      id="Challenge-4:-Experiment-with-New-Features-and-Analyze-Feature-Importance"
                      >Challenge 4: Experiment with New Features and Analyze
                      Feature Importance<a
                        class="anchor-link"
                        href="#Challenge-4:-Experiment-with-New-Features-and-Analyze-Feature-Importance"
                      ></a></h3
                    ><p
                      >Your client asks: "We've seen what features matter now,
                      but what if we engineer additional features? Could we
                      discover new patterns that improve predictions? I want to
                      experiment with new features and see how they compare in
                      the importance rankings."</p
                    >
                    <p
                      ><strong>Your Task:</strong> Create 3-5 new experimental
                      features (e.g., lag features, new time windows, weather
                      combinations), retrain the Random Forest, and analyze how
                      feature importance changes.</p
                    >
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing code_cell rendered"
                id="cell-id=92bb9486"
              >
                <div class="input">
                  <div class="prompt input_prompt">InÂ [Â ]:</div>
                  <div class="inner_cell">
                    <div class="input_area">
                      <div class="highlight hl-ipython3">
                        <pre><span></span><span class="c1"># Your code here - create new features and analyze importance changes</span>

<span class="c1"># Step 1: Create new experimental features</span>
<span class="c1"># Examples of features you might try:</span>
<span class="c1"># - Lag features: lag_1hour (previous hour demand), lag_24hour (same hour yesterday)</span>
<span class="c1"># - New time windows: is_midday, is_late_night</span>
<span class="c1"># - Weather combinations: temp_humidity_interaction</span>
<span class="c1"># - Day type combinations: weekend_weather</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"=== EXPERIMENTING WITH NEW FEATURES ===</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Add your new features to the dataframe</span>
<span class="c1"># Lag features capture temporal patterns from previous time periods</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'lag_1hour'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'count'</span><span class="p">]</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Previous hour's demand</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'lag_24hour'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'count'</span><span class="p">]</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="mi">24</span><span class="p">)</span>  <span class="c1"># Same hour yesterday</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'___'</span><span class="p">]</span> <span class="o">=</span> <span class="n">___</span>  <span class="c1"># Add 2-3 more experimental features</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'___'</span><span class="p">]</span> <span class="o">=</span> <span class="n">___</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'___'</span><span class="p">]</span> <span class="o">=</span> <span class="n">___</span>

<span class="c1"># Fill NaN values created by shift (first observations have no previous data)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'lag_1hour'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'lag_1hour'</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'count'</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'lag_24hour'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'lag_24hour'</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'count'</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>

<span class="c1"># Create new feature list including original + experimental features</span>
<span class="n">experimental_features</span> <span class="o">=</span> <span class="n">feature_columns</span> <span class="o">+</span> <span class="p">[</span><span class="s1">'lag_1hour'</span><span class="p">,</span> <span class="s1">'lag_24hour'</span><span class="p">,</span> <span class="s1">'___'</span><span class="p">,</span> <span class="s1">'___'</span><span class="p">,</span> <span class="s1">'___'</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Original features: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">feature_columns</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Experimental features: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">experimental_features</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"New features added: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">experimental_features</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nb">len</span><span class="p">(</span><span class="n">feature_columns</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="c1"># Step 2: Train Random Forest with expanded feature set</span>
<span class="n">X_experimental</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">experimental_features</span><span class="p">]</span>
<span class="n">y_experimental</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'count'</span><span class="p">]</span>

<span class="n">X_train_exp</span> <span class="o">=</span> <span class="n">X_experimental</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="n">split_index</span><span class="p">]</span>
<span class="n">X_test_exp</span> <span class="o">=</span> <span class="n">X_experimental</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">split_index</span><span class="p">:]</span>

<span class="n">rf_experimental</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">rf_experimental</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_exp</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Step 3: Evaluate performance change</span>
<span class="n">test_pred_exp</span> <span class="o">=</span> <span class="n">rf_experimental</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_exp</span><span class="p">)</span>
<span class="n">test_r2_exp</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">test_pred_exp</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"=== PERFORMANCE COMPARISON ==="</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Baseline model (original features):     RÂ² = </span><span class="si">{</span><span class="n">test_r2_rf</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Experimental model (expanded features): RÂ² = </span><span class="si">{</span><span class="n">test_r2_exp</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Performance change:                     </span><span class="si">{</span><span class="p">(</span><span class="n">test_r2_exp</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">test_r2_rf</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="p">((</span><span class="n">test_r2_exp</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">test_r2_rf</span><span class="p">)</span><span class="o">/</span><span class="n">test_r2_rf</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">+.2f</span><span class="si">}</span><span class="s2">%)"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="c1"># Step 4: Analyze new feature importance rankings</span>
<span class="n">feature_importance_exp</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">'feature'</span><span class="p">:</span> <span class="n">experimental_features</span><span class="p">,</span>
    <span class="s1">'importance'</span><span class="p">:</span> <span class="n">rf_experimental</span><span class="o">.</span><span class="n">feature_importances_</span>
<span class="p">})</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">'importance'</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"=== TOP 15 FEATURES (WITH EXPERIMENTAL FEATURES) ==="</span><span class="p">)</span>
<span class="k">for</span> <span class="n">rank</span><span class="p">,</span> <span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">row</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">feature_importance_exp</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">15</span><span class="p">)</span><span class="o">.</span><span class="n">iterrows</span><span class="p">(),</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">is_new</span> <span class="o">=</span> <span class="s1">'ðŸ†• NEW'</span> <span class="k">if</span> <span class="n">row</span><span class="p">[</span><span class="s1">'feature'</span><span class="p">]</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">feature_columns</span> <span class="k">else</span> <span class="s1">'      '</span>
    <span class="n">bar</span> <span class="o">=</span> <span class="s1">'â–ˆ'</span> <span class="o">*</span> <span class="nb">int</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">'importance'</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">rank</span><span class="si">:</span><span class="s2">&lt;3</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">is_new</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">row</span><span class="p">[</span><span class="s1">'feature'</span><span class="p">]</span><span class="si">:</span><span class="s2">&lt;30</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">row</span><span class="p">[</span><span class="s1">'importance'</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">  </span><span class="si">{</span><span class="n">bar</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="nb">print</span><span class="p">()</span>

<span class="c1"># Step 5: Compare feature importance distributions</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="c1"># Panel 1: Original model top 10</span>
<span class="n">top_original</span> <span class="o">=</span> <span class="n">feature_importance</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">colors_original</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">viridis</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">top_original</span><span class="p">)))</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">top_original</span><span class="p">)),</span> <span class="n">top_original</span><span class="p">[</span><span class="s1">'importance'</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="n">colors_original</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">top_original</span><span class="p">)))</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">top_original</span><span class="p">[</span><span class="s1">'feature'</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">()</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'Importance Score'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'Baseline Model - Top 10 Features'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">'bold'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s1">'x'</span><span class="p">)</span>

<span class="c1"># Panel 2: Experimental model top 10</span>
<span class="n">top_experimental</span> <span class="o">=</span> <span class="n">feature_importance_exp</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">colors_experimental</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">plasma</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">top_experimental</span><span class="p">)))</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">top_experimental</span><span class="p">)),</span> <span class="n">top_experimental</span><span class="p">[</span><span class="s1">'importance'</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="n">colors_experimental</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">top_experimental</span><span class="p">)))</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">top_experimental</span><span class="p">[</span><span class="s1">'feature'</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">()</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'Importance Score'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'Experimental Model - Top 10 Features'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">'bold'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s1">'x'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Step 6: Analyze insights</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"=== EXPERIMENTAL FEATURE INSIGHTS ==="</span><span class="p">)</span>
<span class="c1"># Check if any new features made it to top 10</span>
<span class="n">new_features_in_top10</span> <span class="o">=</span> <span class="p">[</span><span class="n">f</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">top_experimental</span><span class="p">[</span><span class="s1">'feature'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span> <span class="k">if</span> <span class="n">f</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">feature_columns</span><span class="p">]</span>
<span class="k">if</span> <span class="n">new_features_in_top10</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"âœ“ </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">new_features_in_top10</span><span class="p">)</span><span class="si">}</span><span class="s2"> new feature(s) in top 10: </span><span class="si">{</span><span class="s1">', '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">new_features_in_top10</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"  â†’ These features captured previously hidden patterns"</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"âœ— No new features in top 10"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"  â†’ Original features still dominate, experimental features add marginal value"</span><span class="p">)</span>
</pre>
                      </div>
                    </div>
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing text_cell rendered"
                id="cell-id=1663db13"
                ><div class="prompt input_prompt"> </div
                ><div class="inner_cell">
                  <div class="text_cell_render border-box-sizing rendered_html">
                    <details>
                      <summary
                        >ðŸ’¡ <strong>Tip</strong> (click to expand)</summary
                      >
                      <p
                        >Good experimental features to try:
                        <code>lag_1hour = df['count'].shift(1)</code> (previous
                        hour's demand captures momentum),
                        <code>lag_24hour = df['count'].shift(24)</code> (same
                        hour yesterday captures daily patterns),
                        <code
                          >is_midday = ((df['hour'] &gt;= 11) &amp; (df['hour']
                          &lt;= 14)).astype(int)</code
                        >
                        (lunch hour patterns),
                        <code
                          >temp_humidity_interaction = df['temp'] *
                          df['humidity']</code
                        >
                        (discomfort index), or
                        <code
                          >weekend_weather = df['is_weekend'] *
                          df['weather_severity']</code
                        >
                        (weekend sensitivity to bad weather). Important: Lag
                        features create NaN values at the start of your data -
                        use <code>.fillna(df['count'].mean())</code> to handle
                        them. After creating features, ensure they're included
                        in
                        <code
                          >experimental_features = feature_columns +
                          ['new_feature1', 'new_feature2', ...]</code
                        >. When analyzing importance, look for: (1) Did any new
                        features break into top 10? (2) Did performance improve
                        meaningfully (&gt;1% RÂ² gain)? (3) Are new features
                        interpretable enough for business use? Lag features
                        often rank highly because they directly encode recent
                        demand patterns. The visualization comparison shows if
                        new features displace old ones or just add marginal
                        value at the bottom of rankings. Business insight: Only
                        keep experimental features that both improve performance
                        AND rank in top 15 - otherwise they add computational
                        cost without strategic benefit.</p
                      >
                    </details>
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing text_cell rendered"
                id="cell-id=b63e888f"
                ><div class="prompt input_prompt"> </div
                ><div class="inner_cell">
                  <div class="text_cell_render border-box-sizing rendered_html">
                    <details>
                      <summary
                        >ðŸ¤« <strong>Solution</strong> (click to expand)</summary
                      >
                      <div class="highlight">
                        <pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">"=== EXPERIMENTING WITH NEW FEATURES ===</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Step 1: Create experimental features</span>
<span class="c1"># Lag features capture temporal patterns from previous time periods</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'lag_1hour'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'count'</span><span class="p">]</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Previous hour's demand</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'lag_24hour'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'count'</span><span class="p">]</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="mi">24</span><span class="p">)</span>  <span class="c1"># Same hour yesterday</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'is_midday'</span><span class="p">]</span> <span class="o">=</span> <span class="p">((</span><span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">11</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">14</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>  <span class="c1"># Lunch period</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'temp_humidity_interaction'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'temp'</span><span class="p">]</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="s1">'humidity'</span><span class="p">]</span>  <span class="c1"># Discomfort index</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'weekend_weather'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'is_weekend'</span><span class="p">]</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="s1">'weather_severity'</span><span class="p">]</span>  <span class="c1"># Weekend weather sensitivity</span>

<span class="c1"># Fill NaN values created by shift operations</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'lag_1hour'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'lag_1hour'</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'count'</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'lag_24hour'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'lag_24hour'</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'count'</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>

<span class="c1"># Create expanded feature list</span>
<span class="n">experimental_features</span> <span class="o">=</span> <span class="n">feature_columns</span> <span class="o">+</span> <span class="p">[</span>
    <span class="s1">'lag_1hour'</span><span class="p">,</span> <span class="s1">'lag_24hour'</span><span class="p">,</span> <span class="s1">'is_midday'</span><span class="p">,</span> 
    <span class="s1">'temp_humidity_interaction'</span><span class="p">,</span> <span class="s1">'weekend_weather'</span>
<span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Original features: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">feature_columns</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Experimental features: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">experimental_features</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"New features added: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">experimental_features</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nb">len</span><span class="p">(</span><span class="n">feature_columns</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">New features: lag_1hour, lag_24hour, is_midday, temp_humidity_interaction, weekend_weather"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="c1"># Step 2: Train Random Forest with expanded feature set</span>
<span class="n">X_experimental</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">experimental_features</span><span class="p">]</span>
<span class="n">y_experimental</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'count'</span><span class="p">]</span>

<span class="n">X_train_exp</span> <span class="o">=</span> <span class="n">X_experimental</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="n">split_index</span><span class="p">]</span>
<span class="n">X_test_exp</span> <span class="o">=</span> <span class="n">X_experimental</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">split_index</span><span class="p">:]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Training Random Forest with experimental features..."</span><span class="p">)</span>
<span class="n">rf_experimental</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">rf_experimental</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_exp</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Step 3: Evaluate performance change</span>
<span class="n">test_pred_exp</span> <span class="o">=</span> <span class="n">rf_experimental</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_exp</span><span class="p">)</span>
<span class="n">test_r2_exp</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">test_pred_exp</span><span class="p">)</span>
<span class="n">test_rmse_exp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">test_pred_exp</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">=== PERFORMANCE COMPARISON ==="</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Baseline model (17 original features):"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  RÂ² = </span><span class="si">{</span><span class="n">test_r2_rf</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, RMSE = </span><span class="si">{</span><span class="n">test_rmse_rf</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> bikes"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Experimental model (22 expanded features):"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  RÂ² = </span><span class="si">{</span><span class="n">test_r2_exp</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, RMSE = </span><span class="si">{</span><span class="n">test_rmse_exp</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> bikes"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Performance change:"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Î”RÂ² = </span><span class="si">{</span><span class="p">(</span><span class="n">test_r2_exp</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">test_r2_rf</span><span class="p">)</span><span class="si">:</span><span class="s2">+.4f</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="p">((</span><span class="n">test_r2_exp</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">test_r2_rf</span><span class="p">)</span><span class="o">/</span><span class="n">test_r2_rf</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">+.2f</span><span class="si">}</span><span class="s2">%)"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Î”RMSE = </span><span class="si">{</span><span class="p">(</span><span class="n">test_rmse_exp</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">test_rmse_rf</span><span class="p">)</span><span class="si">:</span><span class="s2">+.2f</span><span class="si">}</span><span class="s2"> bikes"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="c1"># Step 4: Analyze new feature importance rankings</span>
<span class="n">feature_importance_exp</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">'feature'</span><span class="p">:</span> <span class="n">experimental_features</span><span class="p">,</span>
    <span class="s1">'importance'</span><span class="p">:</span> <span class="n">rf_experimental</span><span class="o">.</span><span class="n">feature_importances_</span>
<span class="p">})</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">'importance'</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"=== TOP 15 FEATURES (WITH EXPERIMENTAL FEATURES) ==="</span><span class="p">)</span>
<span class="k">for</span> <span class="n">rank</span><span class="p">,</span> <span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">row</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">feature_importance_exp</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">15</span><span class="p">)</span><span class="o">.</span><span class="n">iterrows</span><span class="p">(),</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">is_new</span> <span class="o">=</span> <span class="s1">'ðŸ†• NEW'</span> <span class="k">if</span> <span class="n">row</span><span class="p">[</span><span class="s1">'feature'</span><span class="p">]</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">feature_columns</span> <span class="k">else</span> <span class="s1">'      '</span>
    <span class="n">bar</span> <span class="o">=</span> <span class="s1">'â–ˆ'</span> <span class="o">*</span> <span class="nb">int</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">'importance'</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">percentage</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s1">'importance'</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">rank</span><span class="si">:</span><span class="s2">&lt;3</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">is_new</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">row</span><span class="p">[</span><span class="s1">'feature'</span><span class="p">]</span><span class="si">:</span><span class="s2">&lt;30</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">row</span><span class="p">[</span><span class="s1">'importance'</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">percentage</span><span class="si">:</span><span class="s2">&gt;5.2f</span><span class="si">}</span><span class="s2">%)  </span><span class="si">{</span><span class="n">bar</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="nb">print</span><span class="p">()</span>

<span class="c1"># Step 5: Compare feature importance distributions</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="c1"># Panel 1: Original model top 10</span>
<span class="n">top_original</span> <span class="o">=</span> <span class="n">feature_importance</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">colors_original</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">viridis</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">top_original</span><span class="p">)))</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">top_original</span><span class="p">)),</span> <span class="n">top_original</span><span class="p">[</span><span class="s1">'importance'</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="n">colors_original</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">top_original</span><span class="p">)))</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">top_original</span><span class="p">[</span><span class="s1">'feature'</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">()</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'Importance Score'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'Baseline Model - Top 10 Features'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">'bold'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s1">'x'</span><span class="p">)</span>

<span class="c1"># Panel 2: Experimental model top 10</span>
<span class="n">top_experimental</span> <span class="o">=</span> <span class="n">feature_importance_exp</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">colors_experimental</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">plasma</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">top_experimental</span><span class="p">)))</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">top_experimental</span><span class="p">)),</span> <span class="n">top_experimental</span><span class="p">[</span><span class="s1">'importance'</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="n">colors_experimental</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">top_experimental</span><span class="p">)))</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">top_experimental</span><span class="p">[</span><span class="s1">'feature'</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">()</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'Importance Score'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'Experimental Model - Top 10 Features'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">'bold'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s1">'x'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Step 6: Detailed analysis of experimental features</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"=== EXPERIMENTAL FEATURE INSIGHTS ==="</span><span class="p">)</span>

<span class="c1"># Check if any new features made it to top 10</span>
<span class="n">new_features_list</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'lag_1hour'</span><span class="p">,</span> <span class="s1">'lag_24hour'</span><span class="p">,</span> <span class="s1">'is_midday'</span><span class="p">,</span> 
                     <span class="s1">'temp_humidity_interaction'</span><span class="p">,</span> <span class="s1">'weekend_weather'</span><span class="p">]</span>
<span class="n">new_features_in_top10</span> <span class="o">=</span> <span class="p">[</span><span class="n">f</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">top_experimental</span><span class="p">[</span><span class="s1">'feature'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span> <span class="k">if</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">new_features_list</span><span class="p">]</span>

<span class="k">if</span> <span class="n">new_features_in_top10</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"âœ“ </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">new_features_in_top10</span><span class="p">)</span><span class="si">}</span><span class="s2"> new feature(s) in top 10:"</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">nf</span> <span class="ow">in</span> <span class="n">new_features_in_top10</span><span class="p">:</span>
        <span class="n">rank</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">feature_importance_exp</span><span class="p">[</span><span class="s1">'feature'</span><span class="p">])</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">nf</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">importance</span> <span class="o">=</span> <span class="n">feature_importance_exp</span><span class="p">[</span><span class="n">feature_importance_exp</span><span class="p">[</span><span class="s1">'feature'</span><span class="p">]</span> <span class="o">==</span> <span class="n">nf</span><span class="p">][</span><span class="s1">'importance'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  â€¢ </span><span class="si">{</span><span class="n">nf</span><span class="si">}</span><span class="s2">: Rank #</span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">importance</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2"> importance)"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"  â†’ These features bring predictive power to the model!"</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"âœ— No new features in top 10"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"  â†’ Original features still dominate"</span><span class="p">)</span>

<span class="nb">print</span><span class="p">()</span>

<span class="c1"># Individual experimental feature analysis</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"=== INDIVIDUAL EXPERIMENTAL FEATURE RANKINGS ==="</span><span class="p">)</span>
<span class="k">for</span> <span class="n">exp_feat</span> <span class="ow">in</span> <span class="n">new_features_list</span><span class="p">:</span>
    <span class="n">rank</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">feature_importance_exp</span><span class="p">[</span><span class="s1">'feature'</span><span class="p">])</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">exp_feat</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">importance</span> <span class="o">=</span> <span class="n">feature_importance_exp</span><span class="p">[</span><span class="n">feature_importance_exp</span><span class="p">[</span><span class="s1">'feature'</span><span class="p">]</span> <span class="o">==</span> <span class="n">exp_feat</span><span class="p">][</span><span class="s1">'importance'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">exp_feat</span><span class="si">:</span><span class="s2">&lt;30</span><span class="si">}</span><span class="s2"> Rank: #</span><span class="si">{</span><span class="n">rank</span><span class="si">:</span><span class="s2">2d</span><span class="si">}</span><span class="s2">/22  |  Importance: </span><span class="si">{</span><span class="n">importance</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">importance</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%)"</span><span class="p">)</span>

<span class="nb">print</span><span class="p">()</span>

<span class="c1"># Business recommendation</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"=== RECOMMENDATION FOR CAPITAL CITY BIKES ==="</span><span class="p">)</span>
<span class="k">if</span> <span class="n">test_r2_exp</span> <span class="o">&gt;</span> <span class="n">test_r2_rf</span> <span class="o">+</span> <span class="mf">0.01</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"âœ“ ADOPT experimental features: </span><span class="si">{</span><span class="p">((</span><span class="n">test_r2_exp</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">test_r2_rf</span><span class="p">)</span><span class="o">/</span><span class="n">test_r2_rf</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">+.1f</span><span class="si">}</span><span class="s2">% improvement justifies added complexity"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"âœ“ Focus on: </span><span class="si">{</span><span class="s1">', '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">new_features_in_top10</span><span class="p">[:</span><span class="mi">3</span><span class="p">])</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">new_features_in_top10</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">'top-ranked experimental features'</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="k">elif</span> <span class="n">test_r2_exp</span> <span class="o">&gt;</span> <span class="n">test_r2_rf</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"~ MARGINAL improvement (</span><span class="si">{</span><span class="p">((</span><span class="n">test_r2_exp</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">test_r2_rf</span><span class="p">)</span><span class="o">/</span><span class="n">test_r2_rf</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">+.1f</span><span class="si">}</span><span class="s2">%): Consider if complexity is worth small gain"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"~ New features add minimal predictive value but increase computation"</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"âœ— NO improvement: Keep baseline model, experimental features don't help"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"âœ— Original feature engineering was already optimal for this problem"</span><span class="p">)</span>

<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Key insight: </span><span class="si">{</span><span class="s1">'Expanded feature engineering successful!'</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">test_r2_exp</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">test_r2_rf</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mf">0.01</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">'Original features sufficient - diminishing returns from additional engineering'</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre>
                      </div>
                    </details>
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing text_cell rendered"
                id="cell-id=81864d0d"
                ><div class="prompt input_prompt"> </div
                ><div class="inner_cell">
                  <div class="text_cell_render border-box-sizing rendered_html">
                    <hr />
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing text_cell rendered"
                id="cell-id=5e510069"
                ><div class="prompt input_prompt"> </div
                ><div class="inner_cell">
                  <div class="text_cell_render border-box-sizing rendered_html">
                    <h2
                      id="Step-5:-Validate-Random-Forest-with-Time-Series-Cross-Validation"
                      >Step 5: Validate Random Forest with Time Series
                      Cross-Validation<a
                        class="anchor-link"
                        href="#Step-5:-Validate-Random-Forest-with-Time-Series-Cross-Validation"
                      ></a></h2
                    ><p
                      >Let's apply TimeSeriesSplit to evaluate Random Forest
                      performance across multiple temporal windows, ensuring our
                      model generalizes reliably to future periods.</p
                    >
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing code_cell rendered"
                id="cell-id=732bc900"
              >
                <div class="input">
                  <div class="prompt input_prompt">InÂ [Â ]:</div>
                  <div class="inner_cell">
                    <div class="input_area">
                      <div class="highlight hl-ipython3">
                        <pre><span></span><span class="c1"># Import libraries</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.ensemble</span><span class="w"> </span><span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">TimeSeriesSplit</span><span class="p">,</span> <span class="n">cross_val_score</span>

<span class="c1"># Load and prepare data</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">"https://raw.githubusercontent.com/pmarcelino/predictive-modeling/main/datasets/dataset.csv"</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'datetime'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'datetime'</span><span class="p">])</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">'datetime'</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Feature engineering</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'datetime'</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">hour</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'dayofweek'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'datetime'</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">dayofweek</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'month'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'datetime'</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">month</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'year'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'datetime'</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">year</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'is_rush_hour'</span><span class="p">]</span> <span class="o">=</span> <span class="p">((</span><span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">7</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">9</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">17</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">19</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'is_weekend'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'dayofweek'</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'is_night'</span><span class="p">]</span> <span class="o">=</span> <span class="p">((</span><span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">22</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">5</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'weather_severity'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'weather'</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">({</span><span class="mi">1</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">:</span> <span class="mi">3</span><span class="p">})</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'temp_hour_interaction'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'temp'</span><span class="p">]</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'workingday_hour'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'workingday'</span><span class="p">]</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'season_weather'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'season'</span><span class="p">]</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="s1">'weather_severity'</span><span class="p">]</span>

<span class="c1"># Prepare features</span>
<span class="n">feature_columns</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">'temp'</span><span class="p">,</span> <span class="s1">'atemp'</span><span class="p">,</span> <span class="s1">'humidity'</span><span class="p">,</span> <span class="s1">'windspeed'</span><span class="p">,</span> <span class="s1">'weather_severity'</span><span class="p">,</span>
    <span class="s1">'hour'</span><span class="p">,</span> <span class="s1">'dayofweek'</span><span class="p">,</span> <span class="s1">'month'</span><span class="p">,</span> <span class="s1">'season'</span><span class="p">,</span>
    <span class="s1">'workingday'</span><span class="p">,</span> <span class="s1">'holiday'</span><span class="p">,</span> <span class="s1">'is_rush_hour'</span><span class="p">,</span> <span class="s1">'is_weekend'</span><span class="p">,</span> <span class="s1">'is_night'</span><span class="p">,</span>
    <span class="s1">'temp_hour_interaction'</span><span class="p">,</span> <span class="s1">'workingday_hour'</span><span class="p">,</span> <span class="s1">'season_weather'</span>
<span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">feature_columns</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'count'</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"=== TIME SERIES CROSS-VALIDATION FOR RANDOM FOREST ===</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Create TimeSeriesSplit with 5 folds (expanding window)</span>
<span class="c1"># Each fold trains on all past data and tests on the next time period</span>
<span class="n">tscv</span> <span class="o">=</span> <span class="n">TimeSeriesSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"--- Why TimeSeriesSplit for Random Forests? ---"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"âš  CRITICAL PRINCIPLE: Time series data requires chronological validation"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"â€¢ Random Forest's bootstrap sampling randomizes WITHIN training set"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"â€¢ Bootstrap does NOT protect against training on future to predict past"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"â€¢ Without chronological splits = DATA LEAKAGE = invalid performance estimates"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"â€¢ TimeSeriesSplit ensures we ALWAYS train on past, validate on future"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="c1"># Show fold structure with dates</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"--- Time Series Cross-Validation Fold Structure ---"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Expanding window approach: each fold adds more training data</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>

<span class="k">for</span> <span class="n">fold_num</span><span class="p">,</span> <span class="p">(</span><span class="n">train_idx</span><span class="p">,</span> <span class="n">test_idx</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tscv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">train_dates</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_idx</span><span class="p">][</span><span class="s1">'datetime'</span><span class="p">]</span>
    <span class="n">test_dates</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_idx</span><span class="p">][</span><span class="s1">'datetime'</span><span class="p">]</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Fold </span><span class="si">{</span><span class="n">fold_num</span><span class="si">}</span><span class="s2">:"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Training: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_idx</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> obs | </span><span class="si">{</span><span class="n">train_dates</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="o">.</span><span class="n">date</span><span class="p">()</span><span class="si">}</span><span class="s2"> to </span><span class="si">{</span><span class="n">train_dates</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">date</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Testing:  </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">test_idx</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> obs | </span><span class="si">{</span><span class="n">test_dates</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="o">.</span><span class="n">date</span><span class="p">()</span><span class="si">}</span><span class="s2"> to </span><span class="si">{</span><span class="n">test_dates</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">date</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>

<span class="c1"># Train Random Forest with same parameters from Step 3</span>
<span class="n">rf_model</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Run cross-validation using TimeSeriesSplit</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"--- Running Cross-Validation (this may take 1-2 minutes) ---"</span><span class="p">)</span>
<span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">rf_model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">tscv</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">'r2'</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"=== RANDOM FOREST CROSS-VALIDATION RESULTS ===</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Display fold-by-fold performance</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Fold </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: RÂ² = </span><span class="si">{</span><span class="n">score</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Calculate summary statistics</span>
<span class="n">cv_mean</span> <span class="o">=</span> <span class="n">cv_scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">cv_std</span> <span class="o">=</span> <span class="n">cv_scores</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
<span class="n">cv_min</span> <span class="o">=</span> <span class="n">cv_scores</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
<span class="n">cv_max</span> <span class="o">=</span> <span class="n">cv_scores</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">--- Performance Summary ---"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Mean RÂ²:      </span><span class="si">{</span><span class="n">cv_mean</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Std Dev:      </span><span class="si">{</span><span class="n">cv_std</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Range:        </span><span class="si">{</span><span class="n">cv_min</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> to </span><span class="si">{</span><span class="n">cv_max</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"95% CI:       </span><span class="si">{</span><span class="n">cv_mean</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mf">1.96</span><span class="o">*</span><span class="n">cv_std</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> to </span><span class="si">{</span><span class="n">cv_mean</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mf">1.96</span><span class="o">*</span><span class="n">cv_std</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="c1"># Interpret consistency</span>
<span class="k">if</span> <span class="n">cv_std</span> <span class="o">&lt;</span> <span class="mf">0.03</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"âœ“ EXCELLENT CONSISTENCY:"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"  â€¢ Very low variability (std &lt; 0.03)"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"  â€¢ Model performs reliably across different time periods"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"  â€¢ Suitable for production deployment with confidence"</span><span class="p">)</span>
<span class="k">elif</span> <span class="n">cv_std</span> <span class="o">&lt;</span> <span class="mf">0.06</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"âœ“ GOOD CONSISTENCY:"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"  â€¢ Moderate variability (std &lt; 0.06)"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"  â€¢ Model performs well but some temporal variation exists"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"  â€¢ Acceptable for production with monitoring"</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"âš  HIGH VARIABILITY:"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"  â€¢ Substantial performance differences across time periods"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"  â€¢ Investigate causes: seasonality, data drift, feature instability"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"  â€¢ Consider temporal feature engineering or separate seasonal models"</span><span class="p">)</span>

<span class="nb">print</span><span class="p">()</span>

<span class="c1"># Visualize cross-validation performance</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">cv_scores</span><span class="p">,</span> <span class="s1">'o-'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
         <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'darkgreen'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Fold RÂ²'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">cv_mean</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">'--'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">'Mean RÂ² = </span><span class="si">{</span><span class="n">cv_mean</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">cv_mean</span> <span class="o">+</span> <span class="n">cv_std</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">':'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Â±1 Std Dev'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">cv_mean</span> <span class="o">-</span> <span class="n">cv_std</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">':'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">1.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Fold Number'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'RÂ² Score'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Random Forest Cross-Validation Performance'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">'bold'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"=== BUSINESS INTERPRETATION FOR CAPITAL CITY BIKES ==="</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"âœ“ Expected production performance: </span><span class="si">{</span><span class="n">cv_mean</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2"> RÂ² (Â±</span><span class="si">{</span><span class="n">cv_std</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2">)"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"âœ“ Worst-case scenario: </span><span class="si">{</span><span class="n">cv_min</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2"> RÂ² (prepare for this in capacity planning)"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"âœ“ Best-case scenario: </span><span class="si">{</span><span class="n">cv_max</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2"> RÂ² (demonstrates model potential)"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"âœ“ Model reliability: </span><span class="si">{</span><span class="s1">'High'</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">cv_std</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mf">0.03</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">'Moderate'</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">cv_std</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mf">0.06</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">'Variable'</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre>
                      </div>
                    </div>
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing text_cell rendered"
                id="cell-id=dd57c2da"
                ><div class="prompt input_prompt"> </div
                ><div class="inner_cell">
                  <div class="text_cell_render border-box-sizing rendered_html">
                    <p><strong>What this does:</strong></p>
                    <ul>
                      <li
                        >Creates TimeSeriesSplit with 5 folds using expanding
                        window approach (each fold trains on more historical
                        data)</li
                      >
                      <li
                        >Explicitly explains why bootstrap sampling in Random
                        Forest doesn't eliminate need for chronological
                        validation</li
                      >
                      <li
                        >Displays fold structure with actual dates showing
                        train/test periods for transparency</li
                      >
                      <li
                        >Runs cross_val_score() with TimeSeriesSplit to get
                        robust performance estimates across time</li
                      >
                      <li
                        >Calculates mean, standard deviation, and 95% confidence
                        interval for expected production performance</li
                      >
                      <li
                        >Visualizes fold-by-fold performance with confidence
                        bands showing mean and standard deviation</li
                      >
                      <li
                        >Provides business-focused interpretation of consistency
                        and worst/best-case scenarios</li
                      >
                    </ul>
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing text_cell rendered"
                id="cell-id=b3ec0e91"
                ><div class="prompt input_prompt"> </div
                ><div class="inner_cell">
                  <div class="text_cell_render border-box-sizing rendered_html">
                    <h3
                      id="Challenge-5:-Validate-Experimental-Features-with-Cross-Validation"
                      >Challenge 5: Validate Experimental Features with
                      Cross-Validation<a
                        class="anchor-link"
                        href="#Challenge-5:-Validate-Experimental-Features-with-Cross-Validation"
                      ></a></h3
                    ><p
                      >Your client asks: "The experimental features from
                      Challenge 4 showed promising results on a single test set.
                      But do they provide consistent improvements across
                      different time periods? I need to know if these features
                      are reliably better before we commit to the added
                      complexity in production."</p
                    >
                    <p
                      ><strong>Your Task:</strong> Run TimeSeriesSplit
                      cross-validation on both the baseline model (17 original
                      features) and experimental model (22 features with lag
                      variables), then compare their temporal stability.</p
                    >
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing code_cell rendered"
                id="cell-id=880e92e1"
              >
                <div class="input">
                  <div class="prompt input_prompt">InÂ [Â ]:</div>
                  <div class="inner_cell">
                    <div class="input_area">
                      <div class="highlight hl-ipython3">
                        <pre><span></span><span class="c1"># Your code here - compare CV stability between baseline and experimental models</span>

<span class="c1"># Prepare baseline feature set (from Step 4)</span>
<span class="n">X_baseline</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">feature_columns</span><span class="p">]</span>

<span class="c1"># Prepare experimental feature set (from Challenge 4 solution)</span>
<span class="c1"># First create the experimental features</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'lag_1hour'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'count'</span><span class="p">]</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'count'</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'lag_24hour'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'count'</span><span class="p">]</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="mi">24</span><span class="p">)</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'count'</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'is_midday'</span><span class="p">]</span> <span class="o">=</span> <span class="p">((</span><span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">11</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">14</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'temp_humidity_interaction'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'temp'</span><span class="p">]</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="s1">'humidity'</span><span class="p">]</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'weekend_weather'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'is_weekend'</span><span class="p">]</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="s1">'weather_severity'</span><span class="p">]</span>

<span class="n">experimental_features</span> <span class="o">=</span> <span class="n">feature_columns</span> <span class="o">+</span> <span class="p">[</span>
    <span class="s1">'lag_1hour'</span><span class="p">,</span> <span class="s1">'lag_24hour'</span><span class="p">,</span> <span class="s1">'is_midday'</span><span class="p">,</span>
    <span class="s1">'temp_humidity_interaction'</span><span class="p">,</span> <span class="s1">'weekend_weather'</span>
<span class="p">]</span>
<span class="n">X_experimental</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">experimental_features</span><span class="p">]</span>

<span class="c1"># Create TimeSeriesSplit</span>
<span class="n">tscv</span> <span class="o">=</span> <span class="n">TimeSeriesSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="c1"># Model 1: Baseline Random Forest (17 features)</span>
<span class="n">rf_baseline</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">cv_scores_baseline</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">_____</span><span class="p">,</span> <span class="n">_____</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">_____</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">'r2'</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Model 2: Experimental Random Forest (22 features)</span>
<span class="n">rf_experimental</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">cv_scores_experimental</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">_____</span><span class="p">,</span> <span class="n">_____</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">_____</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">'r2'</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Calculate statistics for both models</span>
<span class="n">baseline_mean</span> <span class="o">=</span> <span class="n">cv_scores_baseline</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">baseline_std</span> <span class="o">=</span> <span class="n">cv_scores_baseline</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
<span class="n">experimental_mean</span> <span class="o">=</span> <span class="n">cv_scores_experimental</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">experimental_std</span> <span class="o">=</span> <span class="n">cv_scores_experimental</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"=== BASELINE VS EXPERIMENTAL MODEL COMPARISON ==="</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Baseline Model (17 original features):"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Mean RÂ²: </span><span class="si">{</span><span class="n">baseline_mean</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Std Dev: </span><span class="si">{</span><span class="n">baseline_std</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Range:   </span><span class="si">{</span><span class="n">cv_scores_baseline</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> to </span><span class="si">{</span><span class="n">cv_scores_baseline</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Experimental Model (22 features with lag variables):"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Mean RÂ²: </span><span class="si">{</span><span class="n">experimental_mean</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Std Dev: </span><span class="si">{</span><span class="n">experimental_std</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Range:   </span><span class="si">{</span><span class="n">cv_scores_experimental</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> to </span><span class="si">{</span><span class="n">cv_scores_experimental</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Visualize comparison</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">x_pos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">cv_scores_baseline</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">width</span> <span class="o">=</span> <span class="mf">0.35</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">x_pos</span> <span class="o">-</span> <span class="n">width</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">cv_scores_baseline</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Baseline (17 features)'</span><span class="p">,</span>
        <span class="n">color</span><span class="o">=</span><span class="s1">'steelblue'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">x_pos</span> <span class="o">+</span> <span class="n">width</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">cv_scores_experimental</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Experimental (22 features)'</span><span class="p">,</span>
        <span class="n">color</span><span class="o">=</span><span class="s1">'darkgreen'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Fold Number'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'RÂ² Score'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Fold-by-Fold Performance Comparison'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">'bold'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s1">'y'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Analysis</span>
<span class="n">performance_improvement</span> <span class="o">=</span> <span class="p">(</span><span class="n">experimental_mean</span> <span class="o">-</span> <span class="n">baseline_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">baseline_mean</span> <span class="o">*</span> <span class="mi">100</span>
<span class="n">stability_change</span> <span class="o">=</span> <span class="p">((</span><span class="n">experimental_std</span> <span class="o">-</span> <span class="n">baseline_std</span><span class="p">)</span> <span class="o">/</span> <span class="n">baseline_std</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">=== EXPERIMENTAL FEATURES VALIDATION ==="</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Performance improvement: </span><span class="si">{</span><span class="n">performance_improvement</span><span class="si">:</span><span class="s2">+.1f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Stability change:        </span><span class="si">{</span><span class="n">stability_change</span><span class="si">:</span><span class="s2">+.1f</span><span class="si">}</span><span class="s2">% (</span><span class="si">{</span><span class="s1">'worse'</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">stability_change</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">'better'</span><span class="si">}</span><span class="s2"> variability)"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Conclusion: Experimental features provide </span><span class="si">{</span><span class="s1">'consistent'</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">experimental_mean</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">baseline_mean</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">'inconsistent'</span><span class="si">}</span><span class="s2"> improvements"</span><span class="p">)</span>
</pre>
                      </div>
                    </div>
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing text_cell rendered"
                id="cell-id=b62f296e"
                ><div class="prompt input_prompt"> </div
                ><div class="inner_cell">
                  <div class="text_cell_render border-box-sizing rendered_html">
                    <details>
                      <summary
                        >ðŸ’¡ <strong>Tip</strong> (click to expand)</summary
                      >
                      <p
                        >Use the same
                        <code>tscv = TimeSeriesSplit(n_splits=5)</code> for both
                        models to ensure identical fold splits for fair
                        comparison. Remember to create the experimental features
                        BEFORE running cross-validation - the lag features
                        (<code>shift(1)</code>, <code>shift(24)</code>), midday
                        indicator, and interaction terms from Challenge 4. Call
                        <code
                          >cross_val_score(rf_baseline, X_baseline, y, cv=tscv,
                          scoring='r2', n_jobs=-1)</code
                        >
                        and similarly for experimental model. The key question:
                        Does the experimental model show improvement across ALL
                        folds or just some? If lag features help consistently,
                        you'll see experimental scores higher in every fold. If
                        they only help in certain periods, that's a warning
                        sign. The bar chart visualization makes this pattern
                        immediately obvious - look for green bars consistently
                        taller than blue bars. Calculate both mean improvement
                        (overall performance gain) and stability change (whether
                        variability increased or decreased). Business insight:
                        An experimental model that shows +5% mean improvement
                        but +50% increased variability might be risky for
                        production - it could perform brilliantly or poorly
                        depending on the time period. Ideally, you want
                        experimental features that improve BOTH mean performance
                        AND stability. Look for: (1) experimental mean &gt;
                        baseline mean (better average), (2) experimental std
                        &lt; baseline std (more consistent), (3) experimental
                        min &gt; baseline min (better worst-case). If lag
                        features significantly improve performance, it suggests
                        temporal autocorrelation in demand - recent patterns
                        strongly predict future patterns.</p
                      >
                    </details>
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing text_cell rendered"
                id="cell-id=1407ea91"
                ><div class="prompt input_prompt"> </div
                ><div class="inner_cell">
                  <div class="text_cell_render border-box-sizing rendered_html">
                    <details>
                      <summary
                        >ðŸ¤« <strong>Solution</strong> (click to expand)</summary
                      >
                      <div class="highlight">
                        <pre><span></span><span class="c1"># Prepare baseline feature set (from Step 4)</span>
<span class="n">X_baseline</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">feature_columns</span><span class="p">]</span>

<span class="c1"># Prepare experimental feature set (from Challenge 4 solution)</span>
<span class="c1"># First create the experimental features</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'lag_1hour'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'count'</span><span class="p">]</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'count'</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'lag_24hour'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'count'</span><span class="p">]</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="mi">24</span><span class="p">)</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'count'</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'is_midday'</span><span class="p">]</span> <span class="o">=</span> <span class="p">((</span><span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">11</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'hour'</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">14</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'temp_humidity_interaction'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'temp'</span><span class="p">]</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="s1">'humidity'</span><span class="p">]</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'weekend_weather'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'is_weekend'</span><span class="p">]</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="s1">'weather_severity'</span><span class="p">]</span>

<span class="n">experimental_features</span> <span class="o">=</span> <span class="n">feature_columns</span> <span class="o">+</span> <span class="p">[</span>
    <span class="s1">'lag_1hour'</span><span class="p">,</span> <span class="s1">'lag_24hour'</span><span class="p">,</span> <span class="s1">'is_midday'</span><span class="p">,</span>
    <span class="s1">'temp_humidity_interaction'</span><span class="p">,</span> <span class="s1">'weekend_weather'</span>
<span class="p">]</span>
<span class="n">X_experimental</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">experimental_features</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"=== VALIDATING EXPERIMENTAL FEATURES WITH CROSS-VALIDATION ===</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Create TimeSeriesSplit</span>
<span class="n">tscv</span> <span class="o">=</span> <span class="n">TimeSeriesSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="c1"># Model 1: Baseline Random Forest (17 features)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Running cross-validation on baseline model (17 features)..."</span><span class="p">)</span>
<span class="n">rf_baseline</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">cv_scores_baseline</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">rf_baseline</span><span class="p">,</span> <span class="n">X_baseline</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">tscv</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">'r2'</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Model 2: Experimental Random Forest (22 features)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Running cross-validation on experimental model (22 features)..."</span><span class="p">)</span>
<span class="n">rf_experimental</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">cv_scores_experimental</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">rf_experimental</span><span class="p">,</span> <span class="n">X_experimental</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">tscv</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">'r2'</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Calculate statistics for both models</span>
<span class="n">baseline_mean</span> <span class="o">=</span> <span class="n">cv_scores_baseline</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">baseline_std</span> <span class="o">=</span> <span class="n">cv_scores_baseline</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
<span class="n">experimental_mean</span> <span class="o">=</span> <span class="n">cv_scores_experimental</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">experimental_std</span> <span class="o">=</span> <span class="n">cv_scores_experimental</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">=== BASELINE VS EXPERIMENTAL MODEL COMPARISON ==="</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Baseline Model (17 original features):"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Mean RÂ²: </span><span class="si">{</span><span class="n">baseline_mean</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Std Dev: </span><span class="si">{</span><span class="n">baseline_std</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Range:   </span><span class="si">{</span><span class="n">cv_scores_baseline</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> to </span><span class="si">{</span><span class="n">cv_scores_baseline</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  95% CI:  </span><span class="si">{</span><span class="n">baseline_mean</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mf">1.96</span><span class="o">*</span><span class="n">baseline_std</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> to </span><span class="si">{</span><span class="n">baseline_mean</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mf">1.96</span><span class="o">*</span><span class="n">baseline_std</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Experimental Model (22 features with lag variables):"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Mean RÂ²: </span><span class="si">{</span><span class="n">experimental_mean</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Std Dev: </span><span class="si">{</span><span class="n">experimental_std</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Range:   </span><span class="si">{</span><span class="n">cv_scores_experimental</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> to </span><span class="si">{</span><span class="n">cv_scores_experimental</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  95% CI:  </span><span class="si">{</span><span class="n">experimental_mean</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mf">1.96</span><span class="o">*</span><span class="n">experimental_std</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> to </span><span class="si">{</span><span class="n">experimental_mean</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mf">1.96</span><span class="o">*</span><span class="n">experimental_std</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Display fold-by-fold comparison</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">--- Fold-by-Fold Comparison ---"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="s1">'Fold'</span><span class="si">:</span><span class="s2">&lt;8</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">'Baseline RÂ²'</span><span class="si">:</span><span class="s2">&lt;15</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">'Experimental RÂ²'</span><span class="si">:</span><span class="s2">&lt;18</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">'Improvement'</span><span class="si">:</span><span class="s2">&lt;15</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"-"</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">base_score</span><span class="p">,</span> <span class="n">exp_score</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">cv_scores_baseline</span><span class="p">,</span> <span class="n">cv_scores_experimental</span><span class="p">),</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">improvement</span> <span class="o">=</span> <span class="n">exp_score</span> <span class="o">-</span> <span class="n">base_score</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">i</span><span class="si">:</span><span class="s2">&lt;8</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">base_score</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">          </span><span class="si">{</span><span class="n">exp_score</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">             </span><span class="si">{</span><span class="n">improvement</span><span class="si">:</span><span class="s2">+.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Visualize comparison</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">x_pos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">cv_scores_baseline</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">width</span> <span class="o">=</span> <span class="mf">0.35</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">x_pos</span> <span class="o">-</span> <span class="n">width</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">cv_scores_baseline</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Baseline (17 features)'</span><span class="p">,</span>
        <span class="n">color</span><span class="o">=</span><span class="s1">'steelblue'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">x_pos</span> <span class="o">+</span> <span class="n">width</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">cv_scores_experimental</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Experimental (22 features)'</span><span class="p">,</span>
        <span class="n">color</span><span class="o">=</span><span class="s1">'darkgreen'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Fold Number'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'RÂ² Score'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Fold-by-Fold Performance Comparison'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">'bold'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s1">'y'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Comprehensive analysis</span>
<span class="n">performance_improvement</span> <span class="o">=</span> <span class="p">(</span><span class="n">experimental_mean</span> <span class="o">-</span> <span class="n">baseline_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">baseline_mean</span> <span class="o">*</span> <span class="mi">100</span>
<span class="n">stability_change</span> <span class="o">=</span> <span class="p">((</span><span class="n">experimental_std</span> <span class="o">-</span> <span class="n">baseline_std</span><span class="p">)</span> <span class="o">/</span> <span class="n">baseline_std</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>
<span class="n">consistent_wins</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">cv_scores_experimental</span> <span class="o">&gt;</span> <span class="n">cv_scores_baseline</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">=== EXPERIMENTAL FEATURES VALIDATION RESULTS ==="</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Performance improvement:     </span><span class="si">{</span><span class="n">performance_improvement</span><span class="si">:</span><span class="s2">+.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Stability change:            </span><span class="si">{</span><span class="n">stability_change</span><span class="si">:</span><span class="s2">+.2f</span><span class="si">}</span><span class="s2">% (</span><span class="si">{</span><span class="s1">'increased'</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">stability_change</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">'reduced'</span><span class="si">}</span><span class="s2"> variability)"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Consistent wins:             </span><span class="si">{</span><span class="n">consistent_wins</span><span class="si">}</span><span class="s2">/5 folds"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Worst-case improvement:      </span><span class="si">{</span><span class="n">cv_scores_experimental</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">cv_scores_baseline</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">:</span><span class="s2">+.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Best-case improvement:       </span><span class="si">{</span><span class="n">cv_scores_experimental</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">cv_scores_baseline</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">:</span><span class="s2">+.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"=== BUSINESS INTERPRETATION FOR CAPITAL CITY BIKES ==="</span><span class="p">)</span>

<span class="k">if</span> <span class="n">experimental_mean</span> <span class="o">&gt;</span> <span class="n">baseline_mean</span> <span class="ow">and</span> <span class="n">consistent_wins</span> <span class="o">&gt;=</span> <span class="mi">4</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"âœ“ STRONG VALIDATION: Experimental features improve performance in </span><span class="si">{</span><span class="n">consistent_wins</span><span class="si">}</span><span class="s2">/5 folds"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"âœ“ Mean improvement of </span><span class="si">{</span><span class="n">performance_improvement</span><span class="si">:</span><span class="s2">+.1f</span><span class="si">}</span><span class="s2">% demonstrates consistent value"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"âœ“ Lag features capture temporal autocorrelation - recent demand predicts future demand"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"âœ“ RECOMMENDATION: Deploy experimental model to production"</span><span class="p">)</span>
<span class="k">elif</span> <span class="n">experimental_mean</span> <span class="o">&gt;</span> <span class="n">baseline_mean</span> <span class="ow">and</span> <span class="n">consistent_wins</span> <span class="o">&gt;=</span> <span class="mi">3</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"âœ“ MODERATE VALIDATION: Experimental features help in </span><span class="si">{</span><span class="n">consistent_wins</span><span class="si">}</span><span class="s2">/5 folds"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"âœ“ Mean improvement of </span><span class="si">{</span><span class="n">performance_improvement</span><span class="si">:</span><span class="s2">+.1f</span><span class="si">}</span><span class="s2">% but some temporal variability"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"~ Consider: Feature improvements may be period-specific (e.g., stronger in certain seasons)"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"~ RECOMMENDATION: Deploy with monitoring, investigate periods where features don't help"</span><span class="p">)</span>
<span class="k">elif</span> <span class="n">experimental_mean</span> <span class="o">&gt;</span> <span class="n">baseline_mean</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"âš  WEAK VALIDATION: Only </span><span class="si">{</span><span class="n">consistent_wins</span><span class="si">}</span><span class="s2">/5 folds show improvement"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"âš  Mean improvement of </span><span class="si">{</span><span class="n">performance_improvement</span><span class="si">:</span><span class="s2">+.1f</span><span class="si">}</span><span class="s2">% but highly inconsistent"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"âš  Risk: Experimental features may overfit to specific time periods"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"âš  RECOMMENDATION: Keep baseline model, investigate why experimental features are unstable"</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"âœ— NO VALIDATION: Experimental features don't improve cross-validated performance"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"âœ— Single test set improvement was likely statistical noise or overfitting"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"âœ— RECOMMENDATION: Discard experimental features, keep baseline model"</span><span class="p">)</span>

<span class="nb">print</span><span class="p">()</span>

<span class="k">if</span> <span class="n">stability_change</span> <span class="o">&lt;</span> <span class="o">-</span><span class="mi">10</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"âœ“ BONUS: Experimental model is </span><span class="si">{</span><span class="nb">abs</span><span class="p">(</span><span class="n">stability_change</span><span class="p">)</span><span class="si">:</span><span class="s2">.0f</span><span class="si">}</span><span class="s2">% MORE STABLE across time periods"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  â†’ Lag features smooth temporal variation â†’ more reliable forecasts"</span><span class="p">)</span>
<span class="k">elif</span> <span class="n">stability_change</span> <span class="o">&lt;</span> <span class="mi">10</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"~ Stability similar to baseline (</span><span class="si">{</span><span class="nb">abs</span><span class="p">(</span><span class="n">stability_change</span><span class="p">)</span><span class="si">:</span><span class="s2">.0f</span><span class="si">}</span><span class="s2">% change)"</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"âš  CONCERN: Experimental model is </span><span class="si">{</span><span class="n">stability_change</span><span class="si">:</span><span class="s2">.0f</span><span class="si">}</span><span class="s2">% LESS STABLE"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  â†’ Added complexity may introduce sensitivity to specific time patterns"</span><span class="p">)</span>

<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"="</span><span class="o">*</span><span class="mi">75</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"FINAL RECOMMENDATION:"</span><span class="p">)</span>
<span class="k">if</span> <span class="n">experimental_mean</span> <span class="o">&gt;</span> <span class="n">baseline_mean</span> <span class="ow">and</span> <span class="n">experimental_std</span> <span class="o">&lt;=</span> <span class="n">baseline_std</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"âœ“ Experimental model DOMINATES: Better performance AND equal/better stability"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"âœ“ Deploy with confidence - improved accuracy without sacrificing reliability"</span><span class="p">)</span>
<span class="k">elif</span> <span class="n">experimental_mean</span> <span class="o">&gt;</span> <span class="n">baseline_mean</span> <span class="ow">and</span> <span class="n">performance_improvement</span> <span class="o">&gt;</span> <span class="mi">3</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"âœ“ Experimental model PREFERRED: Significant performance gain justifies deployment"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"âœ“ </span><span class="si">{</span><span class="n">performance_improvement</span><span class="si">:</span><span class="s2">+.1f</span><span class="si">}</span><span class="s2">% improvement outweighs </span><span class="si">{</span><span class="nb">abs</span><span class="p">(</span><span class="n">stability_change</span><span class="p">)</span><span class="si">:</span><span class="s2">.0f</span><span class="si">}</span><span class="s2">% stability change"</span><span class="p">)</span>
<span class="k">elif</span> <span class="n">experimental_mean</span> <span class="o">&gt;</span> <span class="n">baseline_mean</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"~ Experimental model MARGINAL: Small improvement, evaluate complexity tradeoff"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"~ Consider if added features justify maintenance and computational costs"</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"âœ— Baseline model PREFERRED: No reliable improvement from experimental features"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"âœ— Stick with simpler baseline model for production deployment"</span><span class="p">)</span>
</pre>
                      </div>
                    </details>
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing text_cell rendered"
                id="cell-id=f59cb8c9"
                ><div class="prompt input_prompt"> </div
                ><div class="inner_cell">
                  <div class="text_cell_render border-box-sizing rendered_html">
                    <hr />
                  </div>
                </div>
              </div>
              <div
                class="cell border-box-sizing text_cell rendered"
                id="cell-id=d52bfa0e"
                ><div class="prompt input_prompt"> </div
                ><div class="inner_cell">
                  <div class="text_cell_render border-box-sizing rendered_html">
                    <h2
                      id="Summary:-Production-Grade-Tree-Based-Ensemble-Modeling-for-Competitive-Advantage"
                      >Summary: Production-Grade Tree-Based Ensemble Modeling
                      for Competitive Advantage<a
                        class="anchor-link"
                        href="#Summary:-Production-Grade-Tree-Based-Ensemble-Modeling-for-Competitive-Advantage"
                      ></a></h2
                    ><p><strong>What We've Accomplished:</strong></p>
                    <ul>
                      <li
                        ><strong>Engineered advanced features</strong> including
                        binary indicators (is_rush_hour, is_weekend),
                        categorical encodings (temp_category, weather_severity),
                        and interaction terms (tempÃ—hour, workingdayÃ—hour)
                        exposing 17 features designed for tree-based pattern
                        discovery</li
                      >
                      <li
                        ><strong>Implemented decision trees</strong>
                        demonstrating how unlimited depth leads to severe
                        overfitting (training RÂ² 99%, test RÂ² 61%), revealing
                        why single trees struggle with generalization</li
                      >
                      <li
                        ><strong>Deployed Random Forest ensembles</strong>
                        achieving test RÂ² â‰ˆ68% through bootstrap aggregation and
                        feature randomness, reducing overfitting gap from 39
                        points (single tree) to ~30 points (ensemble)</li
                      >
                      <li
                        ><strong>Analyzed feature importance</strong> using MDI
                        methods, identifying hour, temperature, and workingday
                        interactions as dominant drivers (top 3 features capture
                        ~80% of predictive power)</li
                      >
                    </ul>
                    <p><strong>Key Technical Skills Mastered:</strong></p>
                    <ul>
                      <li
                        ><strong>Feature engineering</strong>: Binary encoding
                        (<code>.astype(int)</code>), categorical binning
                        (<code>pd.cut()</code>), interaction terms (element-wise
                        multiplication), temporal extraction
                        (<code>.dt.hour</code>, <code>.dt.dayofweek</code>)</li
                      >
                      <li
                        ><strong>Decision trees</strong>: DecisionTreeRegressor
                        implementation, tree structure analysis
                        (<code>.get_depth()</code>,
                        <code>.get_n_leaves()</code>), visualization
                        (<code>plot_tree()</code>), overfitting detection
                        (train-test gap calculation)</li
                      >
                      <li
                        ><strong>Random Forest ensembles</strong>:
                        RandomForestRegressor with n_estimators,
                        max_features='sqrt', bootstrap=True; accessing
                        individual estimators (<code>.estimators_[i]</code>),
                        ensemble diversity demonstration</li
                      >
                      <li
                        ><strong>Feature importance</strong>: MDI extraction
                        (<code>.feature_importances_</code>), cumulative
                        importance analysis, business translation of
                        rankings</li
                      >
                    </ul>
                    <p
                      ><strong>Next Steps:</strong> Your Random Forest model
                      transforms Capital City Bikes from linear constraints to
                      non-linear intelligence, achieving 68% RÂ² performance that
                      demonstrates improvement over single decision trees (even
                      more if we consider the model suggested in the solution of
                      Challenge 4). You've demonstrated the advanced ensemble
                      modeling capabilities, interpretable feature importance
                      analysis, and systematic optimization workflows that
                      distinguish senior ML engineers capable of delivering
                      production-grade predictive systems!</p
                    >
                    <p
                      >In the next module, you'll advance to the last step of
                      the machine learning process, which is about model
                      evaluation.</p
                    >
                  </div>
                </div>
              </div>
            </div>
          </div>
        </main>
      </div>
    </div>
  </body>
</html>
