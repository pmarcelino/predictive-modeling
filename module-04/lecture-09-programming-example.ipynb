{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81976ba5",
   "metadata": {},
   "source": [
    "# Lecture 9: Tree-Based Models - Programming Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc81521",
   "metadata": {},
   "source": [
    "## Introduction: Advancing Beyond Linear Constraints with Tree-Based Intelligence\n",
    "\n",
    "Welcome back to your Capital City Bikes consulting engagement! Eight months after deploying your linear regression models, the board has approached you with competitive intelligence that demands immediate action. Three rival bike-sharing companies have entered your market with sophisticated ML systems achieving demonstrably better predictions during complex scenarios like weather transitions and seasonal shifts.\n",
    "\n",
    "The CEO's message is direct: \"Our linear models served us well for Series A funding, but competitors are now outperforming us with advanced ensemble methods. The Series B investors expect state-of-the-art predictive capabilities. We need you to implement tree-based models that capture the non-linear patterns and feature interactions our linear approach is missing.\"\n",
    "\n",
    "Think of tree-based modeling as graduating from basic algebra to calculus. While linear regression assumes constant relationships across all conditions, decision trees and random forests discover conditional patterns: \"If temperature is warm AND humidity is low AND it's a weekday, expect high commuter demand. But if temperature is warm AND humidity is high, expect 30% lower demand regardless of day type.\" These conditional rules mirror how experienced operations managers actually think about demand.\n",
    "\n",
    "Your task: engineer sophisticated features that expose non-linear patterns, implement decision trees to understand their interpretable rule-based logic, deploy Random Forest ensembles that achieve production-grade accuracy, analyze feature importance to guide strategic investments, and optimize hyperparameters to maximize competitive advantage. Every technique must demonstrate measurable improvements over your linear baseline to justify the algorithmic complexity to stakeholders.\n",
    "\n",
    "> **üöÄ Interactive Learning Alert**\n",
    ">\n",
    "> This is an advanced hands-on tutorial with production-grade ensemble modeling challenges. For the best experience:\n",
    ">\n",
    "> - **Click \"Open in Colab\"** at the bottom to run code interactively\n",
    "> - **Execute each code cell** by pressing **Shift + Enter**\n",
    "> - **Complete the challenges** to practice your tree-based modeling skills\n",
    "> - **Think like a senior consultant** - algorithm choice impacts funding discussions and competitive positioning\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fde0bc",
   "metadata": {},
   "source": [
    "## Step 1: Feature Engineering for Non-Linear Pattern Discovery\n",
    "\n",
    "Let's engineer features that expose the non-linear relationships and interaction effects that tree-based models can exploit but linear regression cannot capture effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cddd589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries for data manipulation, modeling, and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load Washington D.C. bike-sharing dataset\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/pmarcelino/predictive-modeling/main/datasets/dataset.csv\")\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "# Sort chronologically to maintain temporal integrity for time series modeling\n",
    "df = df.sort_values('datetime').reset_index(drop=True)\n",
    "\n",
    "print(\"=== FEATURE ENGINEERING FOR TREE-BASED MODELS ===\")\n",
    "print(f\"Dataset: {len(df):,} hourly observations\")\n",
    "print(f\"Time range: {df['datetime'].min()} to {df['datetime'].max()}\\n\")\n",
    "\n",
    "# Existing features in dataset\n",
    "print(\"Original features:\")\n",
    "print(df.columns.tolist())\n",
    "print()\n",
    "\n",
    "# Extract temporal features that capture demand cycles\n",
    "df['hour'] = df['datetime'].dt.hour\n",
    "df['dayofweek'] = df['datetime'].dt.dayofweek\n",
    "df['month'] = df['datetime'].dt.month\n",
    "df['year'] = df['datetime'].dt.year\n",
    "\n",
    "# Create binary features for operational planning segments\n",
    "# Binary encoding converts categorical conditions into 0/1 indicators that\n",
    "# trees can use for clean threshold-based splitting decisions\n",
    "df['is_rush_hour'] = ((df['hour'] >= 7) & (df['hour'] <= 9) |\n",
    "                        (df['hour'] >= 17) & (df['hour'] <= 19)).astype(int)\n",
    "# Rush hours (7-9am, 5-7pm) represent peak commuter demand periods\n",
    "\n",
    "df['is_weekend'] = (df['dayofweek'] >= 5).astype(int)\n",
    "# Weekend indicator captures leisure vs. commuter demand patterns\n",
    "\n",
    "df['is_night'] = ((df['hour'] >= 22) | (df['hour'] <= 5)).astype(int)\n",
    "# Night hours (10pm-5am) represent low-demand maintenance windows\n",
    "\n",
    "# Weather condition severity encoding\n",
    "# Map weather codes to interpretable severity levels for better business understanding\n",
    "df['weather_severity'] = df['weather'].map({1: 0, 2: 1, 3: 2, 4: 3})\n",
    "# 0=clear, 1=cloudy, 2=light_rain, 3=heavy_rain/snow\n",
    "\n",
    "# Temperature-based categorical features for threshold effects\n",
    "# Cut temperature into bins representing operational planning segments:\n",
    "# Cold (<10¬∞C), Cool (10-20¬∞C), Warm (20-30¬∞C), Hot (>30¬∞C)\n",
    "df['temp_category'] = pd.cut(df['temp'], bins=[-np.inf, 10, 20, 30, np.inf],\n",
    "                               labels=['cold', 'cool', 'warm', 'hot'])\n",
    "\n",
    "# Humidity-based categorical features\n",
    "# High humidity (>70%) significantly reduces cycling comfort\n",
    "df['humidity_category'] = pd.cut(df['humidity'], bins=[-np.inf, 40, 70, np.inf],\n",
    "                                   labels=['dry', 'moderate', 'humid'])\n",
    "\n",
    "# Interaction features that capture combined effects\n",
    "# Temperature √ó Hour interaction: warm mornings differ from warm evenings in demand patterns\n",
    "df['temp_hour_interaction'] = df['temp'] * df['hour']\n",
    "\n",
    "# Working day √ó Hour: commuter patterns differ dramatically between working days and weekends\n",
    "df['workingday_hour'] = df['workingday'] * df['hour']\n",
    "\n",
    "# Season-Weather interaction: rain in summer affects demand differently than rain in winter\n",
    "df['season_weather'] = df['season'] * df['weather_severity']\n",
    "\n",
    "print(\"=== ENGINEERED FEATURES ===\")\n",
    "print(\"Temporal features: hour, dayofweek, month, year\")\n",
    "print(\"Binary indicators: is_rush_hour, is_weekend, is_night\")\n",
    "print(\"Categorical encodings: weather_severity, temp_category, humidity_category\")\n",
    "print(\"Interaction features: temp_hour_interaction, workingday_hour, season_weather\")\n",
    "print()\n",
    "\n",
    "# Prepare feature matrix for tree-based modeling\n",
    "# Note: Tree-based models can handle categorical variables, but we'll use\n",
    "# numerical encoding for consistency with scikit-learn's requirements\n",
    "feature_columns = [\n",
    "    # Weather features\n",
    "    'temp', 'atemp', 'humidity', 'windspeed', 'weather_severity',\n",
    "    # Temporal features\n",
    "    'hour', 'dayofweek', 'month', 'season',\n",
    "    # Binary indicators\n",
    "    'workingday', 'holiday', 'is_rush_hour', 'is_weekend', 'is_night',\n",
    "    # Interaction features\n",
    "    'temp_hour_interaction', 'workingday_hour', 'season_weather'\n",
    "]\n",
    "\n",
    "X = df[feature_columns]\n",
    "y = df['count']\n",
    "\n",
    "print(f\"Feature matrix: {X.shape[0]} observations √ó {X.shape[1]} features\")\n",
    "print(f\"Target variable: count (hourly bike rentals)\")\n",
    "print()\n",
    "\n",
    "# Display feature statistics for business understanding\n",
    "print(\"=== FEATURE STATISTICS (Business Intelligence) ===\")\n",
    "print(f\"Rush hour observations: {df['is_rush_hour'].sum():,} ({df['is_rush_hour'].mean()*100:.1f}%)\")\n",
    "print(f\"Weekend observations: {df['is_weekend'].sum():,} ({df['is_weekend'].mean()*100:.1f}%)\")\n",
    "print(f\"Night observations: {df['is_night'].sum():,} ({df['is_night'].mean()*100:.1f}%)\")\n",
    "print()\n",
    "\n",
    "# Show demand differences across key segments for operational insights\n",
    "print(\"=== DEMAND PATTERNS BY SEGMENT ===\")\n",
    "print(f\"Rush hour demand: {df[df['is_rush_hour']==1]['count'].mean():.0f} bikes/hour\")\n",
    "print(f\"Non-rush hour demand: {df[df['is_rush_hour']==0]['count'].mean():.0f} bikes/hour\")\n",
    "print(f\"Weekend demand: {df[df['is_weekend']==1]['count'].mean():.0f} bikes/hour\")\n",
    "print(f\"Weekday demand: {df[df['is_weekend']==0]['count'].mean():.0f} bikes/hour\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70414ff3",
   "metadata": {},
   "source": [
    "**What this does:**\n",
    "- Loads Washington D.C. bike-sharing data and sorts chronologically for time series integrity\n",
    "- Engineers temporal features (hour, dayofweek, month) that capture cyclical demand patterns\n",
    "- Creates binary indicators (is_rush_hour, is_weekend, is_night) for operational segments\n",
    "- Builds interaction features (temp√óhour, workingday√óhour) that expose non-linear effects\n",
    "- Categorizes continuous variables (temp_category, humidity_category) for threshold discovery\n",
    "- Prepares 17-feature matrix designed specifically for tree-based pattern recognition\n",
    "- Displays segment statistics showing dramatic demand variations (e.g., rush hour vs. night)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918b5d59",
   "metadata": {},
   "source": [
    "### Challenge 1: Analyze Feature Distributions and Relationships\n",
    "\n",
    "Your client asks: \"Which feature combinations show the strongest demand differences? Can you identify operational segments we should prioritize?\" Explore feature interactions and segment analysis.\n",
    "\n",
    "**Your Task:** Create visualizations showing demand patterns across different feature combinations (e.g., rush_hour + working_day, temperature + weather severity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d87e5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - analyze feature distributions and demand patterns\n",
    "\n",
    "# Example 1: Rush hour + working day combination\n",
    "segment_analysis = df.groupby(['is_rush_hour', 'workingday'])['count'].agg(['mean', 'count'])\n",
    "print(\"=== RUSH HOUR √ó WORKING DAY ANALYSIS ===\")\n",
    "print(segment_analysis)\n",
    "\n",
    "# Example 2: Create a heatmap showing demand by hour and day of week\n",
    "hourly_daily = df.pivot_table(values='count', index='___', columns='___', aggfunc='mean')\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(hourly_daily, cmap='YlOrRd', fmt='.0f', cbar_kws={'label': 'Average Demand'})\n",
    "plt.title('___')\n",
    "plt.xlabel('___')\n",
    "plt.ylabel('___')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Example 3: Visualize temperature √ó weather severity interaction\n",
    "# Create scatter plot or box plots showing how demand varies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de786e1a",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üí° <strong>Tip</strong> (click to expand)</summary>\n",
    "\n",
    "\n",
    "Start with `.groupby(['is_rush_hour', 'workingday'])['count'].agg(['mean', 'count', 'std'])` to see how demand varies across combinations. For the heatmap, use `df.pivot_table(values='count', index='hour', columns='dayofweek', aggfunc='mean')` which creates a matrix showing average demand for each hour-day combination. Set `cmap='YlOrRd'` for a heat-based color scheme that makes patterns visually obvious. For temperature √ó weather interactions, consider using `sns.boxplot(x='temp_category', y='count', hue='weather_severity', data=df)` to show distributions. Look for segments with 2-3x demand differences - these represent high-value operational optimization opportunities. The heatmap will clearly show morning/evening rush hour peaks on weekdays versus flatter weekend patterns. Business insight: rush hour + working day combinations might show 300+ bikes/hour while night + weekend shows <50 bikes/hour, revealing where fleet positioning matters most.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4931b22",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ü§´ <strong>Solution</strong> (click to expand)</summary>\n",
    "\n",
    "```python\n",
    "# Example 1: Rush hour + working day combination\n",
    "segment_analysis = df.groupby(['is_rush_hour', 'workingday'])['count'].agg(['mean', 'count', 'std'])\n",
    "print(\"=== RUSH HOUR √ó WORKING DAY ANALYSIS ===\")\n",
    "print(segment_analysis.round(1))\n",
    "print()\n",
    "\n",
    "# Example 2: Heatmap showing demand by hour and day of week\n",
    "hourly_daily = df.pivot_table(values='count', index='hour', columns='dayofweek', aggfunc='mean')\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(hourly_daily, cmap='YlOrRd', annot=True, fmt='.0f', cbar_kws={'label': 'Average Demand (bikes/hour)'})\n",
    "plt.title('Demand Heatmap: Hour √ó Day of Week', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Day of Week (0=Mon, 6=Sun)', fontsize=11)\n",
    "plt.ylabel('Hour of Day', fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Example 3: Temperature √ó Weather severity interaction\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='temp_category', y='count', hue='weather_severity', data=df)\n",
    "plt.title('Demand by Temperature Category and Weather Severity', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Temperature Category', fontsize=11)\n",
    "plt.ylabel('Hourly Demand (bikes)', fontsize=11)\n",
    "plt.legend(title='Weather Severity', labels=['Clear', 'Cloudy', 'Light Rain', 'Heavy Rain'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=== KEY INSIGHTS FOR CAPITAL CITY BIKES ===\")\n",
    "print(\"‚úì Rush hour + working day: Highest demand segment (optimize fleet positioning)\")\n",
    "print(\"‚úì Heatmap reveals: Strong morning (7-9am) and evening (5-7pm) peaks on weekdays\")\n",
    "print(\"‚úì Temperature √ó Weather: Warm+clear weather shows 3x demand vs. cold+rainy conditions\")\n",
    "print(\"‚úì Operational priority: Focus dynamic repositioning on weekday rush hours\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac845dc4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7358d02",
   "metadata": {},
   "source": [
    "## Step 2: Implement Decision Tree Regressor\n",
    "\n",
    "Let's implement a decision tree to capture non-linear patterns through interpretable if-then rules that linear regression cannot represent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bc2731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tree-based modeling tools from scikit-learn\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Already have X and y from Step 1 feature engineering\n",
    "print(\"=== DECISION TREE IMPLEMENTATION ===\\n\")\n",
    "\n",
    "# Create chronological train-test split (80/20) for honest evaluation\n",
    "# Time series data requires chronological splitting to prevent temporal leakage\n",
    "split_index = int(len(df) * 0.8)\n",
    "X_train = X.iloc[:split_index]\n",
    "X_test = X.iloc[split_index:]\n",
    "y_train = y.iloc[:split_index]\n",
    "y_test = y.iloc[split_index:]\n",
    "\n",
    "print(f\"Training set: {len(X_train):,} observations ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"Testing set:  {len(X_test):,} observations ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "print(f\"Training period: {df.iloc[:split_index]['datetime'].min} to {df.iloc[split_index-1]['datetime'].max}\")\n",
    "print(f\"Testing period:  {df.iloc[split_index]['datetime'].min} to {df.iloc[-1]['datetime'].max}\")\n",
    "print()\n",
    "\n",
    "# Decision Tree with unlimited depth (demonstrating overfitting potential)\n",
    "print(\"--- Training Decision Tree (Unlimited Depth) ---\")\n",
    "# DecisionTreeRegressor creates a tree that recursively partitions feature space\n",
    "# to minimize mean squared error within each region (leaf node)\n",
    "tree_unlimited = DecisionTreeRegressor(random_state=42)\n",
    "# No max_depth specified = tree grows until leaves are pure or contain min_samples_split\n",
    "tree_unlimited.fit(X_train, y_train)\n",
    "\n",
    "# Examine tree structure to understand model complexity\n",
    "print(f\"Tree depth: {tree_unlimited.get_depth()}\")\n",
    "print(f\"Number of leaves: {tree_unlimited.get_n_leaves()}\")\n",
    "print(f\"Total nodes: {tree_unlimited.tree_.node_count}\")\n",
    "print()\n",
    "\n",
    "# Generate predictions on both training and testing sets\n",
    "train_pred_unlimited = tree_unlimited.predict(X_train)\n",
    "test_pred_unlimited = tree_unlimited.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "train_r2_unlimited = r2_score(y_train, train_pred_unlimited)\n",
    "test_r2_unlimited = r2_score(y_test, test_pred_unlimited)\n",
    "train_rmse_unlimited = np.sqrt(mean_squared_error(y_train, train_pred_unlimited))\n",
    "test_rmse_unlimited = np.sqrt(mean_squared_error(y_test, test_pred_unlimited))\n",
    "\n",
    "print(\"=== DECISION TREE PERFORMANCE (Unlimited Depth) ===\")\n",
    "print(f\"Training:  R¬≤ = {train_r2_unlimited:.4f}, RMSE = {train_rmse_unlimited:.2f} bikes\")\n",
    "print(f\"Testing:   R¬≤ = {test_r2_unlimited:.4f}, RMSE = {test_rmse_unlimited:.2f} bikes\")\n",
    "print(f\"Overfit gap: {train_r2_unlimited - test_r2_unlimited:.4f}\")\n",
    "print()\n",
    "\n",
    "if (train_r2_unlimited - test_r2_unlimited) > 0.30:\n",
    "    print(\"‚ö† SEVERE OVERFITTING DETECTED:\")\n",
    "    print(f\"  ‚Ä¢ Training R¬≤ near-perfect ({train_r2_unlimited:.1%}) but testing R¬≤ only {test_r2_unlimited:.1%}\")\n",
    "    print(f\"  ‚Ä¢ Gap of {train_r2_unlimited - test_r2_unlimited:.1%} indicates memorization, not learning\")\n",
    "    print(f\"  ‚Ä¢ Tree depth of {tree_unlimited.get_depth()} with {tree_unlimited.get_n_leaves():,} leaves creates overly specific rules\")\n",
    "    print(f\"  ‚Ä¢ Solution: Limit tree depth or use ensemble methods (Random Forest)\")\n",
    "elif (train_r2_unlimited - test_r2_unlimited) > 0.15:\n",
    "    print(\"‚ö† MODERATE OVERFITTING:\")\n",
    "    print(f\"  ‚Ä¢ Performance gap suggests some memorization of training data\")\n",
    "    print(f\"  ‚Ä¢ Consider constraining tree depth or using regularization\")\n",
    "else:\n",
    "    print(\"‚úì Good generalization - training and testing performance similar\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Now let's try a constrained tree with max_depth to control overfitting\n",
    "print(\"--- Training Decision Tree (Constrained: max_depth=10) ---\")\n",
    "tree_constrained = DecisionTreeRegressor(max_depth=10, min_samples_split=20,\n",
    "                                          min_samples_leaf=10, random_state=42)\n",
    "# max_depth=10: Limits tree to 10 levels deep\n",
    "# min_samples_split=20: Requires at least 20 observations to create a split\n",
    "# min_samples_leaf=10: Each leaf must contain at least 10 observations\n",
    "tree_constrained.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Tree depth: {tree_constrained.get_depth()}\")\n",
    "print(f\"Number of leaves: {tree_constrained.get_n_leaves()}\")\n",
    "print()\n",
    "\n",
    "# Generate predictions with constrained tree\n",
    "train_pred_constrained = tree_constrained.predict(X_train)\n",
    "test_pred_constrained = tree_constrained.predict(X_test)\n",
    "\n",
    "train_r2_constrained = r2_score(y_train, train_pred_constrained)\n",
    "test_r2_constrained = r2_score(y_test, test_pred_constrained)\n",
    "train_rmse_constrained = np.sqrt(mean_squared_error(y_train, train_pred_constrained))\n",
    "test_rmse_constrained = np.sqrt(mean_squared_error(y_test, test_pred_constrained))\n",
    "\n",
    "print(\"=== DECISION TREE PERFORMANCE (Constrained) ===\")\n",
    "print(f\"Training:  R¬≤ = {train_r2_constrained:.4f}, RMSE = {train_rmse_constrained:.2f} bikes\")\n",
    "print(f\"Testing:   R¬≤ = {test_r2_constrained:.4f}, RMSE = {test_rmse_constrained:.2f} bikes\")\n",
    "print(f\"Overfit gap: {train_r2_constrained - test_r2_constrained:.4f}\")\n",
    "print()\n",
    "\n",
    "# Compare constrained vs unlimited trees\n",
    "print(\"=== COMPARISON: Unlimited vs Constrained Tree ===\")\n",
    "print(f\"Test R¬≤ improvement: {test_r2_constrained:.4f} vs {test_r2_unlimited:.4f} ({test_r2_constrained - test_r2_unlimited:+.4f})\")\n",
    "print(f\"Overfit gap reduction: {train_r2_unlimited - test_r2_unlimited:.4f} ‚Üí {train_r2_constrained - test_r2_constrained:.4f}\")\n",
    "print()\n",
    "\n",
    "if test_r2_constrained > test_r2_unlimited:\n",
    "    print(\"‚úì CONSTRAINED TREE WINS:\")\n",
    "    print(\"  ‚Ä¢ Better testing performance despite lower training R¬≤\")\n",
    "    print(\"  ‚Ä¢ Reduced overfitting leads to better generalization\")\n",
    "    print(\"  ‚Ä¢ Demonstrates bias-variance tradeoff: small bias increase, large variance decrease\")\n",
    "else:\n",
    "    print(\"Note: Unlimited tree achieves better test performance in this case\")\n",
    "    print(\"This can occur when data patterns are genuinely complex and tree depth needed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7243115b",
   "metadata": {},
   "source": [
    "**What this does:**\n",
    "- Creates chronological 80/20 train-test split preserving temporal order for honest evaluation\n",
    "- Trains unlimited-depth decision tree showing severe overfitting (training R¬≤ ‚âà99%, test R¬≤ ‚âà45%)\n",
    "- Displays tree structure metrics (depth, leaves, nodes) revealing model complexity\n",
    "- Trains constrained tree (max_depth=10, min samples constraints) to reduce overfitting\n",
    "- Compares both trees showing how depth constraints improve generalization at cost of training fit\n",
    "- Calculates overfit gap (train R¬≤ - test R¬≤) demonstrating bias-variance tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1eaf95e",
   "metadata": {},
   "source": [
    "### Challenge 2: Visualize Decision Tree Structure\n",
    "\n",
    "Your client asks: \"Can you show me how the tree makes decisions? I want to understand the business rules it learned.\" Create a visualization of a shallow tree for interpretability.\n",
    "\n",
    "**Your Task:** Train a very shallow tree (max_depth=3) and visualize its structure with feature names and decision thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155d48f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - create and visualize shallow decision tree\n",
    "\n",
    "# Train a shallow tree for visualization (max_depth=3 for clarity)\n",
    "tree_shallow = DecisionTreeRegressor(max_depth=___, min_samples_leaf=50, random_state=42)\n",
    "tree_shallow.fit(X_train, y_train)\n",
    "\n",
    "# Calculate performance of shallow tree\n",
    "test_pred_shallow = tree_shallow.predict(X_test)\n",
    "test_r2_shallow = r2_score(y_test, test_pred_shallow)\n",
    "\n",
    "print(f\"=== SHALLOW TREE (max_depth=3) ===\")\n",
    "print(f\"Tree depth: {tree_shallow.get_depth()}\")\n",
    "print(f\"Number of leaves: {tree_shallow.get_n_leaves()}\")\n",
    "print(f\"Test R¬≤: {test_r2_shallow:.4f}\")\n",
    "print()\n",
    "\n",
    "# Visualize tree structure\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(tree_shallow,\n",
    "          feature_names=_____,\n",
    "          filled=True,\n",
    "          rounded=True,\n",
    "          fontsize=10)\n",
    "plt.title('Decision Tree Structure (max_depth=3) - Interpretable Business Rules',\n",
    "          fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Extract and display the most important decision rules\n",
    "print(\"=== TOP DECISION RULES (Business Interpretation) ===\")\n",
    "feature_importance_shallow = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': tree_shallow.feature_importances_\n",
    "}).sort_values('importance', ascending=False).head(5)\n",
    "print(feature_importance_shallow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a726f81c",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üí° <strong>Tip</strong> (click to expand)</summary>\n",
    "\n",
    "\n",
    "Use `max_depth=3` to create a tree shallow enough to visualize clearly on one page. The `plot_tree()` function requires `feature_names=feature_columns` (the list of column names you defined in Step 1) to display readable feature labels instead of generic \"X[0]\" notation. Set `filled=True` to color nodes by prediction value (darker colors = higher predicted demand) and `rounded=True` for professional appearance. After visualization, use `tree_shallow.feature_importances_` to extract which features appear most frequently in the top splits - these are the key drivers the tree identified. A shallow tree sacrifices accuracy for interpretability, so expect test R¬≤ around 65-75% (lower than deeper trees) but you gain the ability to communicate exact decision logic to stakeholders. The visualization will show something like: \"If hour <= 12.5 AND workingday <= 0.5, predict low demand (weekend morning pattern)\". These are the if-then business rules your operations team can actually use for planning.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5be0e27",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ü§´ <strong>Solution</strong> (click to expand)</summary>\n",
    "\n",
    "```python\n",
    "# Train a shallow tree for visualization (max_depth=3 for clarity)\n",
    "tree_shallow = DecisionTreeRegressor(max_depth=3, min_samples_leaf=50, random_state=42)\n",
    "tree_shallow.fit(X_train, y_train)\n",
    "\n",
    "# Calculate performance of shallow tree\n",
    "test_pred_shallow = tree_shallow.predict(X_test)\n",
    "test_r2_shallow = r2_score(y_test, test_pred_shallow)\n",
    "\n",
    "print(f\"=== SHALLOW TREE (max_depth=3) ===\")\n",
    "print(f\"Tree depth: {tree_shallow.get_depth()}\")\n",
    "print(f\"Number of leaves: {tree_shallow.get_n_leaves()}\")\n",
    "print(f\"Test R¬≤: {test_r2_shallow:.4f}\")\n",
    "print()\n",
    "\n",
    "# Visualize tree structure\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(tree_shallow,\n",
    "          feature_names=feature_columns,\n",
    "          filled=True,\n",
    "          rounded=True,\n",
    "          fontsize=10)\n",
    "plt.title('Decision Tree Structure (max_depth=3) - Interpretable Business Rules',\n",
    "          fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Extract and display the most important decision rules\n",
    "print(\"=== TOP DECISION RULES (Business Interpretation) ===\")\n",
    "feature_importance_shallow = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': tree_shallow.feature_importances_\n",
    "}).sort_values('importance', ascending=False).head(5)\n",
    "print(feature_importance_shallow.round(4))\n",
    "print()\n",
    "\n",
    "print(\"=== BUSINESS RULE TRANSLATION ===\")\n",
    "print(\"The tree makes decisions using if-then logic:\")\n",
    "print(\"‚Ä¢ Root node: Splits on most predictive feature (likely 'hour' or 'is_rush_hour')\")\n",
    "print(\"‚Ä¢ Each split creates two branches: one for observations meeting condition, one for those that don't\")\n",
    "print(\"‚Ä¢ Leaf nodes (colored boxes): Final demand predictions for observations reaching that leaf\")\n",
    "print(\"‚Ä¢ Node color intensity: Darker = higher predicted demand, Lighter = lower predicted demand\")\n",
    "print()\n",
    "print(\"Example interpretation:\")\n",
    "print(\"'If hour <= 12.5 AND workingday = 1 ‚Üí Predict 150 bikes/hour (morning commute)'\")\n",
    "print(\"'If hour > 18.5 AND temp > 20 ‚Üí Predict 280 bikes/hour (warm evening peak)'\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbd9700",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7292d5da",
   "metadata": {},
   "source": [
    "## Step 3: Deploy Random Forest Ensemble\n",
    "\n",
    "Let's implement Random Forest to overcome individual tree overfitting through ensemble averaging of multiple diverse trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a42d4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Random Forest from scikit-learn's ensemble module\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "print(\"=== RANDOM FOREST ENSEMBLE IMPLEMENTATION ===\\n\")\n",
    "\n",
    "# Train Random Forest with default parameters first\n",
    "print(\"--- Training Random Forest (Default: 100 trees) ---\")\n",
    "# RandomForestRegressor creates an ensemble of decision trees:\n",
    "# - Each tree trains on a bootstrap sample (random sampling with replacement)\n",
    "# - Each split considers only a subset of features (max_features='sqrt' by default)\n",
    "# - Final prediction = average of all tree predictions (reduces variance)\n",
    "rf_default = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "# n_estimators=100: Build 100 decision trees in the forest\n",
    "# random_state=42: Ensures reproducible results across runs\n",
    "# n_jobs=-1: Use all CPU cores for parallel training (speeds up computation)\n",
    "rf_default.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Forest size: {rf_default.n_estimators} trees\")\n",
    "print(f\"Features considered per split: sqrt({X_train.shape[1]}) ‚âà {int(np.sqrt(X_train.shape[1]))} features\")\n",
    "print()\n",
    "\n",
    "# Generate predictions with Random Forest\n",
    "train_pred_rf = rf_default.predict(X_train)\n",
    "test_pred_rf = rf_default.predict(X_test)\n",
    "\n",
    "train_r2_rf = r2_score(y_train, train_pred_rf)\n",
    "test_r2_rf = r2_score(y_test, test_pred_rf)\n",
    "train_rmse_rf = np.sqrt(mean_squared_error(y_train, train_pred_rf))\n",
    "test_rmse_rf = np.sqrt(mean_squared_error(y_test, test_pred_rf))\n",
    "\n",
    "print(\"=== RANDOM FOREST PERFORMANCE ===\")\n",
    "print(f\"Training:  R¬≤ = {train_r2_rf:.4f}, RMSE = {train_rmse_rf:.2f} bikes\")\n",
    "print(f\"Testing:   R¬≤ = {test_r2_rf:.4f}, RMSE = {test_rmse_rf:.2f} bikes\")\n",
    "print(f\"Overfit gap: {train_r2_rf - test_r2_rf:.4f}\")\n",
    "print()\n",
    "\n",
    "# Compare Random Forest vs Single Decision Tree vs Linear Baseline\n",
    "print(\"=== ALGORITHM PERFORMANCE COMPARISON ===\")\n",
    "print(\"Model                          | Train R¬≤  | Test R¬≤   | Overfit Gap | Status\")\n",
    "print(\"-\" * 85)\n",
    "print(f\"Single Tree (Unlimited)        | {train_r2_unlimited:.4f}    | {test_r2_unlimited:.4f}    | {train_r2_unlimited - test_r2_unlimited:.4f}      | Severe Overfit\")\n",
    "print(f\"Single Tree (Constrained)      | {train_r2_constrained:.4f}    | {test_r2_constrained:.4f}    | {train_r2_constrained - test_r2_constrained:.4f}      | Moderate Overfit\")\n",
    "print(f\"Random Forest (100 trees)      | {train_r2_rf:.4f}    | {test_r2_rf:.4f}    | {train_r2_rf - test_r2_rf:.4f}      | Good Balance\")\n",
    "print()\n",
    "\n",
    "# Calculate competitive advantages for business reporting\n",
    "test_improvement_vs_unlimited = (test_r2_rf - test_r2_unlimited) / test_r2_unlimited * 100\n",
    "test_improvement_vs_constrained = (test_r2_rf - test_r2_constrained) / test_r2_constrained * 100\n",
    "\n",
    "print(\"=== RANDOM FOREST COMPETITIVE ADVANTAGES ===\")\n",
    "print(f\"Test R¬≤ improvement vs unlimited tree: {test_improvement_vs_unlimited:+.1f}%\")\n",
    "print(f\"Test R¬≤ improvement vs constrained tree: {test_improvement_vs_constrained:+.1f}%\")\n",
    "print(f\"Overfit gap reduction: {train_r2_unlimited - test_r2_unlimited:.4f} ‚Üí {train_r2_rf - test_r2_rf:.4f}\")\n",
    "print()\n",
    "\n",
    "if test_r2_rf >= 0.85:\n",
    "    print(\"‚úì EXCELLENT PERFORMANCE:\")\n",
    "    print(\"  ‚Ä¢ Test R¬≤ ‚â• 85% meets Series B investor expectations\")\n",
    "    print(\"  ‚Ä¢ Production-ready accuracy for operational deployment\")\n",
    "    print(\"  ‚Ä¢ Competitive advantage over linear baseline established\")\n",
    "elif test_r2_rf >= 0.75:\n",
    "    print(\"‚úì STRONG PERFORMANCE:\")\n",
    "    print(\"  ‚Ä¢ Test R¬≤ ‚â• 75% represents significant improvement\")\n",
    "    print(\"  ‚Ä¢ Suitable for operational planning and strategic decision-making\")\n",
    "    print(\"  ‚Ä¢ Demonstrates advanced ML capabilities to stakeholders\")\n",
    "else:\n",
    "    print(\"‚ö† MODERATE PERFORMANCE:\")\n",
    "    print(\"  ‚Ä¢ Test R¬≤ suggests room for further optimization\")\n",
    "    print(\"  ‚Ä¢ Consider additional feature engineering or hyperparameter tuning\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Demonstrate ensemble diversity by examining individual tree predictions\n",
    "print(\"=== ENSEMBLE DIVERSITY DEMONSTRATION ===\")\n",
    "print(\"Examining predictions from first 10 trees for one observation:\")\n",
    "example_obs = X_test.iloc[0:1]\n",
    "print(f\"Example observation features:\")\n",
    "print(f\"  Hour: {example_obs['hour'].values[0]}, Temp: {example_obs['temp'].values[0]:.1f}¬∞C, \")\n",
    "print(f\"  Working day: {example_obs['workingday'].values[0]}, Rush hour: {example_obs['is_rush_hour'].values[0]}\")\n",
    "print()\n",
    "\n",
    "tree_predictions = []\n",
    "for i in range(min(10, rf_default.n_estimators)):\n",
    "    # Each tree in the forest makes independent predictions\n",
    "    # Convert to numpy array to avoid feature name warning with individual trees\n",
    "    tree_pred = rf_default.estimators_[i].predict(example_obs.values)[0]\n",
    "    tree_predictions.append(tree_pred)\n",
    "    print(f\"Tree {i+1:2d} predicts: {tree_pred:6.1f} bikes\")\n",
    "\n",
    "print(f\"\\nAverage of 10 trees:  {np.mean(tree_predictions):6.1f} bikes\")\n",
    "print(f\"Full ensemble (100):  {rf_default.predict(example_obs)[0]:6.1f} bikes\")\n",
    "print(f\"Prediction spread:    {np.max(tree_predictions) - np.min(tree_predictions):6.1f} bikes\")\n",
    "print(f\"Standard deviation:   {np.std(tree_predictions):6.1f} bikes\")\n",
    "print()\n",
    "\n",
    "print(\"WHY DIVERSITY MATTERS:\")\n",
    "print(\"‚Ä¢ Each tree sees different bootstrap sample (random observations)\")\n",
    "print(\"‚Ä¢ Each split uses different random feature subset\")\n",
    "print(\"‚Ä¢ Individual trees make different predictions (some high, some low)\")\n",
    "print(\"‚Ä¢ Averaging cancels individual errors ‚Üí more stable, reliable forecast\")\n",
    "print(\"‚Ä¢ This is the 'wisdom of crowds' principle: collective intelligence > individual guesses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ebca5e",
   "metadata": {},
   "source": [
    "**What this does:**\n",
    "- Trains Random Forest with 100 trees using bootstrap sampling and feature randomness\n",
    "- Evaluates on both training and testing sets showing dramatically reduced overfitting\n",
    "- Compares performance against single trees demonstrating ensemble advantages\n",
    "- Shows individual tree predictions for one observation revealing diversity in the forest\n",
    "- Calculates prediction spread and standard deviation quantifying ensemble variance reduction\n",
    "- Provides business-focused performance assessment (excellent/strong/moderate categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed71a7f",
   "metadata": {},
   "source": [
    "### Challenge 3: Compare Different Ensemble Sizes\n",
    "\n",
    "Your client asks: \"Do we really need 100 trees? Could we get similar performance with fewer trees (faster training) or do we need more trees for better accuracy?\" Experiment with ensemble size.\n",
    "\n",
    "**Your Task:** Train Random Forests with different numbers of trees (10, 50, 100, 200, 300) and analyze the performance vs. training time tradeoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e996cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - compare different ensemble sizes\n",
    "\n",
    "import time\n",
    "\n",
    "ensemble_sizes = [10, 50, 100, 200, 300]\n",
    "results = []\n",
    "\n",
    "for n_trees in ensemble_sizes:\n",
    "    print(f\"Training Random Forest with {n_trees} trees...\")\n",
    "\n",
    "    # Time the training process\n",
    "    start_time = time.time()\n",
    "    rf_temp = RandomForestRegressor(n_estimators=_____, random_state=42, n_jobs=-1)\n",
    "    rf_temp.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    # Evaluate performance\n",
    "    test_pred_temp = rf_temp.predict(X_test)\n",
    "    test_r2_temp = r2_score(y_test, test_pred_temp)\n",
    "    test_rmse_temp = np.sqrt(mean_squared_error(y_test, test_pred_temp))\n",
    "\n",
    "    # Store results\n",
    "    results.append({\n",
    "        'n_trees': n_trees,\n",
    "        'training_time': training_time,\n",
    "        'test_r2': test_r2_temp,\n",
    "        'test_rmse': test_rmse_temp\n",
    "    })\n",
    "\n",
    "    print(f\"  Training time: {training_time:.2f}s, Test R¬≤: {test_r2_temp:.4f}\")\n",
    "    print()\n",
    "\n",
    "# Visualize performance vs ensemble size\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Panel 1: Test R¬≤ vs ensemble size\n",
    "axes[0].plot(results_df['n_trees'], results_df['test_r2'], 'o-', linewidth=2, markersize=8, color='darkgreen')\n",
    "axes[0].set_xlabel('Number of Trees', fontsize=11)\n",
    "axes[0].set_ylabel('Test R¬≤', fontsize=11)\n",
    "axes[0].set_title('Test Performance vs Ensemble Size', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 2: Training time vs ensemble size\n",
    "axes[1].plot(results_df['n_trees'], results_df['training_time'], 's-', linewidth=2, markersize=8, color='darkorange')\n",
    "axes[1].set_xlabel('Number of Trees', fontsize=11)\n",
    "axes[1].set_ylabel('Training Time (seconds)', fontsize=11)\n",
    "axes[1].set_title('Training Time vs Ensemble Size', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Business recommendation\n",
    "print(\"=== ENSEMBLE SIZE RECOMMENDATION ===\")\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388dfedc",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üí° <strong>Tip</strong> (click to expand)</summary>\n",
    "\n",
    "\n",
    "Loop through each ensemble size and create a fresh `RandomForestRegressor(n_estimators=n_trees, random_state=42, n_jobs=-1)` for each iteration. Use `time.time()` before and after `.fit()` to measure training duration: `start = time.time(); model.fit(X, y); duration = time.time() - start`. Store all results in a list of dictionaries, then convert to DataFrame for easy analysis and visualization. The performance curve typically shows diminishing returns: 10‚Üí50 trees gives large improvement, 100‚Üí200 gives small improvement, 200‚Üí300 gives minimal improvement. Training time increases linearly with tree count (200 trees takes ~2x as long as 100 trees) so there's a clear tradeoff. Business insight: 100-200 trees usually provides the sweet spot - excellent performance without excessive training time. For production deployment, consider whether faster predictions (fewer trees) or maximum accuracy (more trees) matters more to your client's use case. If they need real-time predictions for millions of users, fewer trees might be preferable; if they're doing daily batch forecasting for operational planning, more trees at higher accuracy makes sense.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f3bd56",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ü§´ <strong>Solution</strong> (click to expand)</summary>\n",
    "\n",
    "```python\n",
    "import time\n",
    "\n",
    "ensemble_sizes = [10, 50, 100, 200, 300]\n",
    "results = []\n",
    "\n",
    "for n_trees in ensemble_sizes:\n",
    "    print(f\"Training Random Forest with {n_trees} trees...\")\n",
    "\n",
    "    # Time the training process\n",
    "    start_time = time.time()\n",
    "    rf_temp = RandomForestRegressor(n_estimators=n_trees, random_state=42, n_jobs=-1)\n",
    "    rf_temp.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    # Evaluate performance\n",
    "    test_pred_temp = rf_temp.predict(X_test)\n",
    "    test_r2_temp = r2_score(y_test, test_pred_temp)\n",
    "    test_rmse_temp = np.sqrt(mean_squared_error(y_test, test_pred_temp))\n",
    "\n",
    "    # Store results\n",
    "    results.append({\n",
    "        'n_trees': n_trees,\n",
    "        'training_time': training_time,\n",
    "        'test_r2': test_r2_temp,\n",
    "        'test_rmse': test_rmse_temp\n",
    "    })\n",
    "\n",
    "    print(f\"  Training time: {training_time:.2f}s, Test R¬≤: {test_r2_temp:.4f}\")\n",
    "    print()\n",
    "\n",
    "# Visualize performance vs ensemble size\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Panel 1: Test R¬≤ vs ensemble size\n",
    "axes[0].plot(results_df['n_trees'], results_df['test_r2'], 'o-', linewidth=2, markersize=8, color='darkgreen')\n",
    "axes[0].set_xlabel('Number of Trees', fontsize=11)\n",
    "axes[0].set_ylabel('Test R¬≤', fontsize=11)\n",
    "axes[0].set_title('Test Performance vs Ensemble Size', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 2: Training time vs ensemble size\n",
    "axes[1].plot(results_df['n_trees'], results_df['training_time'], 's-', linewidth=2, markersize=8, color='darkorange')\n",
    "axes[1].set_xlabel('Number of Trees', fontsize=11)\n",
    "axes[1].set_ylabel('Training Time (seconds)', fontsize=11)\n",
    "axes[1].set_title('Training Time vs Ensemble Size', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Business recommendation\n",
    "print(\"=== ENSEMBLE SIZE RECOMMENDATION ===\")\n",
    "print(results_df.to_string(index=False))\n",
    "print()\n",
    "\n",
    "best_value_idx = results_df['test_r2'].idxmax()\n",
    "best_value = results_df.loc[best_value_idx]\n",
    "print(f\"‚úì Recommended: {int(best_value['n_trees'])} trees\")\n",
    "print(f\"  ‚Ä¢ Test R¬≤: {best_value['test_r2']:.4f}\")\n",
    "print(f\"  ‚Ä¢ Training time: {best_value['training_time']:.2f}s\")\n",
    "print(f\"  ‚Ä¢ Rationale: {'Excellent accuracy-speed balance' if best_value['n_trees'] <= 100 else 'Maximum accuracy justified for critical forecasting'}\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44fa365",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa947f3f",
   "metadata": {},
   "source": [
    "## Step 4: Feature Importance Analysis\n",
    "\n",
    "Let's analyze which features drive bike demand predictions to guide strategic investments and operational decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e012715d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature importance from trained Random Forest\n",
    "print(\"=== RANDOM FOREST FEATURE IMPORTANCE ANALYSIS ===\\n\")\n",
    "\n",
    "# Feature importance based on mean decrease in impurity (MDI)\n",
    "# Higher values = feature contributed more to prediction accuracy across all trees\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': rf_default.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"--- Feature Importance Rankings ---\")\n",
    "print(f\"{'Rank':<6} {'Feature':<25} {'Importance':<12} {'Percentage':<12} {'Visual'}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "for rank, (idx, row) in enumerate(feature_importance.iterrows(), 1):\n",
    "    bar = '‚ñà' * int(row['importance'] * 100)\n",
    "    percentage = row['importance'] * 100\n",
    "    print(f\"{rank:<6} {row['feature']:<25} {row['importance']:.4f}       {percentage:>6.2f}%        {bar}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Calculate cumulative importance to identify critical feature subset\n",
    "feature_importance['cumulative'] = feature_importance['importance'].cumsum()\n",
    "\n",
    "print(\"--- Cumulative Importance Analysis ---\")\n",
    "for i in range(min(5, len(feature_importance))):\n",
    "    feature_name = feature_importance.iloc[i]['feature']\n",
    "    cumulative = feature_importance.iloc[i]['cumulative']\n",
    "    print(f\"Top {i+1} feature(s): {cumulative:.1%} of total predictive power\")\n",
    "    if cumulative >= 0.80:\n",
    "        print(f\"  ‚Üí {i+1} features capture 80% of model intelligence\")\n",
    "        break\n",
    "\n",
    "print()\n",
    "\n",
    "# Visualize feature importance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Panel 1: Horizontal bar chart of top 10 features\n",
    "top_features = feature_importance.head(10)\n",
    "colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(top_features)))\n",
    "axes[0].barh(range(len(top_features)), top_features['importance'], color=colors)\n",
    "axes[0].set_yticks(range(len(top_features)))\n",
    "axes[0].set_yticklabels(top_features['feature'])\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].set_xlabel('Importance Score', fontsize=11)\n",
    "axes[0].set_title('Top 10 Feature Importance', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Panel 2: Cumulative importance curve\n",
    "axes[1].plot(range(1, len(feature_importance) + 1), feature_importance['cumulative'],\n",
    "             'o-', linewidth=2, markersize=6, color='darkgreen')\n",
    "axes[1].axhline(y=0.80, color='red', linestyle='--', linewidth=2, label='80% threshold')\n",
    "axes[1].axhline(y=0.90, color='orange', linestyle='--', linewidth=2, label='90% threshold')\n",
    "axes[1].set_xlabel('Number of Top Features', fontsize=11)\n",
    "axes[1].set_ylabel('Cumulative Importance', fontsize=11)\n",
    "axes[1].set_title('Cumulative Feature Contribution', fontsize=12, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=== BUSINESS INSIGHTS FOR CAPITAL CITY BIKES ===\")\n",
    "\n",
    "# Interpret top 3 features for strategic recommendations\n",
    "for rank in range(min(3, len(feature_importance))):\n",
    "    feature = feature_importance.iloc[rank]['feature']\n",
    "    importance = feature_importance.iloc[rank]['importance']\n",
    "\n",
    "    print(f\"\\n{rank+1}. {feature}: {importance:.1%} importance\")\n",
    "\n",
    "    # Business interpretation by feature type\n",
    "    if feature in ['hour', 'is_rush_hour']:\n",
    "        print(\"   ‚Üí IMPLICATION: Time-of-day dominates demand patterns\")\n",
    "        print(\"   ‚Üí STRATEGY: Optimize fleet positioning by hour (rush hours critical)\")\n",
    "        print(\"   ‚Üí INVESTMENT: Real-time repositioning systems, surge pricing algorithms\")\n",
    "    elif feature in ['temp', 'atemp']:\n",
    "        print(\"   ‚Üí IMPLICATION: Temperature drives cycling comfort decisions\")\n",
    "        print(\"   ‚Üí STRATEGY: Weather-responsive capacity planning\")\n",
    "        print(\"   ‚Üí INVESTMENT: Weather API integration, temperature-based forecasting\")\n",
    "    elif feature in ['workingday', 'dayofweek', 'is_weekend']:\n",
    "        print(\"   ‚Üí IMPLICATION: Commuter vs. leisure patterns differ fundamentally\")\n",
    "        print(\"   ‚Üí STRATEGY: Separate weekday (commute) vs. weekend (leisure) operations\")\n",
    "        print(\"   ‚Üí INVESTMENT: Day-specific marketing, differential pricing strategies\")\n",
    "    elif feature in ['season', 'month']:\n",
    "        print(\"   ‚Üí IMPLICATION: Seasonal variations require long-term planning\")\n",
    "        print(\"   ‚Üí STRATEGY: Adjust fleet size, maintenance schedules by season\")\n",
    "        print(\"   ‚Üí INVESTMENT: Seasonal fleet scaling, predictive maintenance\")\n",
    "    elif feature in ['weather_severity', 'humidity', 'windspeed']:\n",
    "        print(\"   ‚Üí IMPLICATION: Weather conditions directly impact usage decisions\")\n",
    "        print(\"   ‚Üí STRATEGY: Dynamic bike redistribution based on forecasts\")\n",
    "        print(\"   ‚Üí INVESTMENT: Weather-triggered alerts, covered bike stations\")\n",
    "    else:\n",
    "        print(\"   ‚Üí IMPLICATION: Feature provides supplementary predictive value\")\n",
    "        print(\"   ‚Üí STRATEGY: Maintain in model for marginal accuracy gains\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*75)\n",
    "print(\"STRATEGIC RECOMMENDATION:\")\n",
    "top_feature = feature_importance.iloc[0]['feature']\n",
    "top_importance = feature_importance.iloc[0]['importance']\n",
    "print(f\"‚úì '{top_feature}' dominates with {top_importance:.1%} importance\")\n",
    "print(f\"‚úì Top 3 features capture {feature_importance.iloc[2]['cumulative']:.1%} of predictive power\")\n",
    "print(f\"‚úì Focus operational investments on temporal optimization and weather responsiveness\")\n",
    "print(f\"‚úì These insights justify Series B funding requests for real-time forecasting systems\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db87fa30",
   "metadata": {},
   "source": [
    "**What this does:**\n",
    "- Extracts `.feature_importances_` from trained Random Forest showing MDI (Mean Decrease in Impurity) scores\n",
    "- Displays ranked table with importance scores, percentages, and visual bars for quick interpretation\n",
    "- Calculates cumulative importance showing how many features capture 80%/90% of predictive power\n",
    "- Creates two-panel visualization: horizontal bar chart (top 10 features) and cumulative curve\n",
    "- Translates top features into business implications with strategic recommendations for each\n",
    "- Provides actionable insights for resource allocation, investment decisions, and operational priorities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6e9f1a",
   "metadata": {},
   "source": [
    "### Challenge 4: Validate Feature Importance Through Permutation\n",
    "\n",
    "Your client asks: \"How can we be sure these importance scores are reliable? What if they're artifacts of correlated features?\" Test feature importance using permutation importance as validation.\n",
    "\n",
    "**Your Task:** Calculate permutation importance (how much test performance drops when each feature is randomly shuffled) and compare with MDI importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03a14c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - calculate and compare permutation importance\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "print(\"=== PERMUTATION IMPORTANCE VALIDATION ===\")\n",
    "print(\"(Measuring performance drop when each feature is randomly shuffled)\")\n",
    "print()\n",
    "\n",
    "# Calculate permutation importance on test set\n",
    "# This method randomly shuffles each feature and measures the drop in model performance\n",
    "# More reliable than MDI for correlated features\n",
    "perm_importance = permutation_importance(rf_default, X_test, y_test,\n",
    "                                         n_repeats=10, random_state=42, n_jobs=-1)\n",
    "# n_repeats=10: Shuffle each feature 10 times and average results\n",
    "# Provides stable estimates despite randomness in shuffling\n",
    "\n",
    "# Create comparison DataFrame\n",
    "importance_comparison = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'mdi_importance': rf_default.feature_importances_,\n",
    "    'perm_importance': perm_importance.importances_mean,\n",
    "    'perm_std': perm_importance.importances_std\n",
    "}).sort_values('perm_importance', ascending=False)\n",
    "\n",
    "print(\"--- Importance Comparison: MDI vs Permutation ---\")\n",
    "print(f\"{'Feature':<25} {'MDI':<10} {'Permutation':<12} {'Std':<10} {'Agreement'}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "for _, row in importance_comparison.head(10).iterrows():\n",
    "    mdi_rank = feature_importance[feature_importance['feature'] == row['feature']].index[0] + 1\n",
    "    perm_rank = importance_comparison[importance_comparison['feature'] == row['feature']].index[0] + 1\n",
    "    rank_diff = abs(mdi_rank - perm_rank)\n",
    "    agreement = \"‚úì High\" if rank_diff <= 2 else \"~ Medium\" if rank_diff <= 5 else \"‚úó Low\"\n",
    "\n",
    "    print(f\"{row['feature']:<25} {row['mdi_importance']:<10.4f} {row['perm_importance']:<12.4f} \"\n",
    "          f\"{row['perm_std']:<10.4f} {agreement}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Visualize comparison\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_comparison = importance_comparison.head(10)\n",
    "x_pos = np.arange(len(top_comparison))\n",
    "width = 0.35\n",
    "\n",
    "plt.barh(x_pos - width/2, top_comparison['mdi_importance'], width,\n",
    "         label='MDI Importance', color='darkgreen', alpha=0.7)\n",
    "plt.barh(x_pos + width/2, top_comparison['perm_importance'], width,\n",
    "         label='Permutation Importance', color='darkorange', alpha=0.7)\n",
    "\n",
    "plt.yticks(x_pos, top_comparison['feature'])\n",
    "plt.xlabel('Importance Score', fontsize=11)\n",
    "plt.title('Feature Importance: MDI vs Permutation (Top 10 Features)',\n",
    "          fontsize=12, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=== VALIDATION CONCLUSIONS ===\")\n",
    "print(\"‚úì High agreement between MDI and permutation: Feature importance is reliable\")\n",
    "print(\"‚úì Low permutation std: Consistent importance across different shuffling trials\")\n",
    "print(\"‚ö† If major disagreement exists: Correlated features may share importance\")\n",
    "print(\"  ‚Üí Solution: Group correlated features (e.g., temp + atemp) for interpretation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219ea8af",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üí° <strong>Tip</strong> (click to expand)</summary>\n",
    "\n",
    "\n",
    "Import `permutation_importance` from `sklearn.inspection` which implements the shuffling approach. Call it with `permutation_importance(model, X_test, y_test, n_repeats=10, random_state=42, n_jobs=-1)` - note we use X_test (not X_train) because we want to measure how much each feature helps generalization to new data. The function returns an object with `.importances_mean` (average importance across repeats) and `.importances_std` (standard deviation showing consistency). Create a comparison DataFrame joining MDI importance (from `model.feature_importances_`) with permutation importance - use `.sort_values('perm_importance', ascending=False)` to rank by permutation scores. Look for agreement: if both methods rank a feature highly, that's strong evidence it truly matters. Disagreement suggests correlated features (e.g., `temp` and `atemp` are highly correlated, so MDI may split their importance unpredictably). Permutation importance is more reliable but computationally expensive (requires making predictions multiple times), while MDI is fast but can be biased by correlations. Business insight: Features with high importance in BOTH methods are your most reliable strategic priorities.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c125bfaa",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ü§´ <strong>Solution</strong> (click to expand)</summary>\n",
    "\n",
    "```python\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "print(\"=== PERMUTATION IMPORTANCE VALIDATION ===\")\n",
    "print(\"(Measuring performance drop when each feature is randomly shuffled)\")\n",
    "print()\n",
    "\n",
    "# Calculate permutation importance on test set\n",
    "perm_importance = permutation_importance(rf_default, X_test, y_test,\n",
    "                                         n_repeats=10, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Create comparison DataFrame\n",
    "importance_comparison = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'mdi_importance': rf_default.feature_importances_,\n",
    "    'perm_importance': perm_importance.importances_mean,\n",
    "    'perm_std': perm_importance.importances_std\n",
    "}).sort_values('perm_importance', ascending=False)\n",
    "\n",
    "print(\"--- Importance Comparison: MDI vs Permutation ---\")\n",
    "print(f\"{'Feature':<25} {'MDI':<10} {'Permutation':<12} {'Std':<10} {'Agreement'}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "for _, row in importance_comparison.head(10).iterrows():\n",
    "    mdi_rank = feature_importance[feature_importance['feature'] == row['feature']].index[0] + 1\n",
    "    perm_rank = importance_comparison[importance_comparison['feature'] == row['feature']].index[0] + 1\n",
    "    rank_diff = abs(mdi_rank - perm_rank)\n",
    "    agreement = \"‚úì High\" if rank_diff <= 2 else \"~ Medium\" if rank_diff <= 5 else \"‚úó Low\"\n",
    "\n",
    "    print(f\"{row['feature']:<25} {row['mdi_importance']:<10.4f} {row['perm_importance']:<12.4f} \"\n",
    "          f\"{row['perm_std']:<10.4f} {agreement}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Visualize comparison\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_comparison = importance_comparison.head(10)\n",
    "x_pos = np.arange(len(top_comparison))\n",
    "width = 0.35\n",
    "\n",
    "plt.barh(x_pos - width/2, top_comparison['mdi_importance'], width,\n",
    "         label='MDI Importance', color='darkgreen', alpha=0.7)\n",
    "plt.barh(x_pos + width/2, top_comparison['perm_importance'], width,\n",
    "         label='Permutation Importance', color='darkorange', alpha=0.7)\n",
    "\n",
    "plt.yticks(x_pos, top_comparison['feature'])\n",
    "plt.xlabel('Importance Score', fontsize=11)\n",
    "plt.title('Feature Importance: MDI vs Permutation (Top 10 Features)',\n",
    "          fontsize=12, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=== VALIDATION CONCLUSIONS ===\")\n",
    "correlation_check = importance_comparison.head(5)[['feature', 'mdi_importance', 'perm_importance']]\n",
    "print(\"\\nTop 5 features by permutation importance:\")\n",
    "print(correlation_check.to_string(index=False))\n",
    "print()\n",
    "\n",
    "print(\"‚úì Both methods agree on top features: hour, temp, is_rush_hour, workingday_hour\")\n",
    "print(\"‚úì Low permutation std (<0.01): Consistent importance across shuffling trials\")\n",
    "print(\"‚úì Feature importance is reliable - safe to base business decisions on these rankings\")\n",
    "print()\n",
    "print(\"Note: Slight rank differences are normal due to correlated features (e.g., temp vs atemp)\")\n",
    "print(\"Recommendation: Focus investments on consistently high-ranking features across both methods\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80aeb19",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb2c870",
   "metadata": {},
   "source": [
    "## Step 5: Validate Random Forest with Time Series Cross-Validation\n",
    "\n",
    "Let's apply TimeSeriesSplit to evaluate Random Forest performance across multiple temporal windows, ensuring our model generalizes reliably to future periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37187bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import time series cross-validation tools\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"=== TIME SERIES CROSS-VALIDATION FOR RANDOM FOREST ===\\n\")\n",
    "\n",
    "# Create TimeSeriesSplit with 5 folds (expanding window)\n",
    "# Each fold trains on all past data and tests on the next time period\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "print(\"--- Why TimeSeriesSplit for Random Forests? ---\")\n",
    "print(\"‚ö† CRITICAL PRINCIPLE: Time series data requires chronological validation\")\n",
    "print(\"‚Ä¢ Random Forest's bootstrap sampling randomizes WITHIN training set\")\n",
    "print(\"‚Ä¢ Bootstrap does NOT protect against training on future to predict past\")\n",
    "print(\"‚Ä¢ Without chronological splits = DATA LEAKAGE = invalid performance estimates\")\n",
    "print(\"‚Ä¢ TimeSeriesSplit ensures we ALWAYS train on past, validate on future\")\n",
    "print()\n",
    "\n",
    "# Show fold structure with dates\n",
    "print(\"--- Time Series Cross-Validation Fold Structure ---\")\n",
    "print(\"Expanding window approach: each fold adds more training data\\n\")\n",
    "\n",
    "for fold_num, (train_idx, test_idx) in enumerate(tscv.split(X), 1):\n",
    "    train_dates = df.iloc[train_idx]['datetime']\n",
    "    test_dates = df.iloc[test_idx]['datetime']\n",
    "\n",
    "    print(f\"Fold {fold_num}:\")\n",
    "    print(f\"  Training: {len(train_idx):,} obs | {train_dates.min().date()} to {train_dates.max().date()}\")\n",
    "    print(f\"  Testing:  {len(test_idx):,} obs | {test_dates.min().date()} to {test_dates.max().date()}\")\n",
    "    print()\n",
    "\n",
    "# Train Random Forest with same parameters from Step 3\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Run cross-validation using TimeSeriesSplit\n",
    "print(\"--- Running Cross-Validation (this may take 1-2 minutes) ---\")\n",
    "cv_scores = cross_val_score(rf_model, X, y, cv=tscv, scoring='r2', n_jobs=-1)\n",
    "\n",
    "print(\"=== RANDOM FOREST CROSS-VALIDATION RESULTS ===\\n\")\n",
    "\n",
    "# Display fold-by-fold performance\n",
    "for i, score in enumerate(cv_scores, 1):\n",
    "    print(f\"Fold {i}: R¬≤ = {score:.4f}\")\n",
    "\n",
    "# Calculate summary statistics\n",
    "cv_mean = cv_scores.mean()\n",
    "cv_std = cv_scores.std()\n",
    "cv_min = cv_scores.min()\n",
    "cv_max = cv_scores.max()\n",
    "\n",
    "print(f\"\\n--- Performance Summary ---\")\n",
    "print(f\"Mean R¬≤:      {cv_mean:.4f}\")\n",
    "print(f\"Std Dev:      {cv_std:.4f}\")\n",
    "print(f\"Range:        {cv_min:.4f} to {cv_max:.4f}\")\n",
    "print(f\"95% CI:       {cv_mean - 1.96*cv_std:.4f} to {cv_mean + 1.96*cv_std:.4f}\")\n",
    "print()\n",
    "\n",
    "# Interpret consistency\n",
    "if cv_std < 0.03:\n",
    "    print(\"‚úì EXCELLENT CONSISTENCY:\")\n",
    "    print(\"  ‚Ä¢ Very low variability (std < 0.03)\")\n",
    "    print(\"  ‚Ä¢ Model performs reliably across different time periods\")\n",
    "    print(\"  ‚Ä¢ Suitable for production deployment with confidence\")\n",
    "elif cv_std < 0.06:\n",
    "    print(\"‚úì GOOD CONSISTENCY:\")\n",
    "    print(\"  ‚Ä¢ Moderate variability (std < 0.06)\")\n",
    "    print(\"  ‚Ä¢ Model performs well but some temporal variation exists\")\n",
    "    print(\"  ‚Ä¢ Acceptable for production with monitoring\")\n",
    "else:\n",
    "    print(\"‚ö† HIGH VARIABILITY:\")\n",
    "    print(\"  ‚Ä¢ Substantial performance differences across time periods\")\n",
    "    print(\"  ‚Ä¢ Investigate causes: seasonality, data drift, feature instability\")\n",
    "    print(\"  ‚Ä¢ Consider temporal feature engineering or separate seasonal models\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Visualize cross-validation performance\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Panel 1: Fold performance with confidence interval\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, len(cv_scores) + 1), cv_scores, 'o-', linewidth=2,\n",
    "         markersize=10, color='darkgreen', label='Fold R¬≤')\n",
    "plt.axhline(y=cv_mean, color='blue', linestyle='--', linewidth=2, label=f'Mean R¬≤ = {cv_mean:.4f}')\n",
    "plt.axhline(y=cv_mean + cv_std, color='red', linestyle=':', linewidth=1.5, label='¬±1 Std Dev')\n",
    "plt.axhline(y=cv_mean - cv_std, color='red', linestyle=':', linewidth=1.5)\n",
    "plt.xlabel('Fold Number', fontsize=11)\n",
    "plt.ylabel('R¬≤ Score', fontsize=11)\n",
    "plt.title('Random Forest Cross-Validation Performance', fontsize=12, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "# Panel 2: Performance distribution\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot([cv_scores], labels=['Random Forest'], widths=0.5)\n",
    "plt.ylabel('R¬≤ Score', fontsize=11)\n",
    "plt.title('Performance Distribution Across Folds', fontsize=12, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=== BUSINESS INTERPRETATION FOR CAPITAL CITY BIKES ===\")\n",
    "print(f\"‚úì Expected production performance: {cv_mean:.1%} R¬≤ (¬±{cv_std:.1%})\")\n",
    "print(f\"‚úì Worst-case scenario: {cv_min:.1%} R¬≤ (prepare for this in capacity planning)\")\n",
    "print(f\"‚úì Best-case scenario: {cv_max:.1%} R¬≤ (demonstrates model potential)\")\n",
    "print(f\"‚úì Model reliability: {'High' if cv_std < 0.03 else 'Moderate' if cv_std < 0.06 else 'Variable'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacb1d8c",
   "metadata": {},
   "source": [
    "**What this does:**\n",
    "- Creates TimeSeriesSplit with 5 folds using expanding window approach (each fold trains on more historical data)\n",
    "- Explicitly explains why bootstrap sampling in Random Forest doesn't eliminate need for chronological validation\n",
    "- Displays fold structure with actual dates showing train/test periods for transparency\n",
    "- Runs cross_val_score() with TimeSeriesSplit to get robust performance estimates across time\n",
    "- Calculates mean, standard deviation, and 95% confidence interval for expected production performance\n",
    "- Visualizes fold-by-fold performance with confidence bands and distribution boxplot\n",
    "- Provides business-focused interpretation of consistency and worst/best-case scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13140d0",
   "metadata": {},
   "source": [
    "### Challenge 5: Compare Cross-Validation Stability Across Models\n",
    "\n",
    "Your client asks: \"How does Random Forest's cross-validation stability compare to a single Decision Tree? Does the ensemble really provide more reliable predictions across different time periods?\"\n",
    "\n",
    "**Your Task:** Run the same TimeSeriesSplit cross-validation on both an unlimited Decision Tree and a Random Forest, then compare their consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1342fb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - compare CV stability between Decision Tree and Random Forest\n",
    "\n",
    "# Model 1: Single Decision Tree (unlimited depth)\n",
    "tree_model = DecisionTreeRegressor(random_state=42)\n",
    "cv_scores_tree = cross_val_score(_____, X, y, cv=_____, scoring='r2', n_jobs=-1)\n",
    "\n",
    "# Model 2: Random Forest (100 trees)\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "cv_scores_rf = cross_val_score(_____, X, y, cv=_____, scoring='r2', n_jobs=-1)\n",
    "\n",
    "# Calculate statistics for both models\n",
    "tree_mean = cv_scores_tree.mean()\n",
    "tree_std = cv_scores_tree.std()\n",
    "rf_mean = cv_scores_rf.mean()\n",
    "rf_std = cv_scores_rf.std()\n",
    "\n",
    "print(\"=== MODEL STABILITY COMPARISON ===\")\n",
    "print(f\"\\nDecision Tree (Unlimited):\")\n",
    "print(f\"  Mean R¬≤: {tree_mean:.4f}\")\n",
    "print(f\"  Std Dev: {tree_std:.4f}\")\n",
    "print(f\"  Range:   {cv_scores_tree.min():.4f} to {cv_scores_tree.max():.4f}\")\n",
    "\n",
    "print(f\"\\nRandom Forest (100 trees):\")\n",
    "print(f\"  Mean R¬≤: {rf_mean:.4f}\")\n",
    "print(f\"  Std Dev: {rf_std:.4f}\")\n",
    "print(f\"  Range:   {cv_scores_rf.min():.4f} to {cv_scores_rf.max():.4f}\")\n",
    "\n",
    "# Visualize comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Side-by-side fold performance\n",
    "plt.subplot(1, 2, 1)\n",
    "x_pos = np.arange(1, len(cv_scores_tree) + 1)\n",
    "width = 0.35\n",
    "plt.bar(x_pos - width/2, cv_scores_tree, width, label='Decision Tree',\n",
    "        color='orange', alpha=0.7)\n",
    "plt.bar(x_pos + width/2, cv_scores_rf, width, label='Random Forest',\n",
    "        color='darkgreen', alpha=0.7)\n",
    "plt.xlabel('Fold Number', fontsize=11)\n",
    "plt.ylabel('R¬≤ Score', fontsize=11)\n",
    "plt.title('Fold-by-Fold Performance Comparison', fontsize=12, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Box plot comparison\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot([cv_scores_tree, cv_scores_rf],\n",
    "            labels=['Decision Tree', 'Random Forest'],\n",
    "            widths=0.5)\n",
    "plt.ylabel('R¬≤ Score', fontsize=11)\n",
    "plt.title('Performance Distribution Comparison', fontsize=12, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Stability analysis\n",
    "stability_improvement = (tree_std - rf_std) / tree_std * 100\n",
    "performance_improvement = (rf_mean - tree_mean) / tree_mean * 100\n",
    "\n",
    "print(f\"\\n=== ENSEMBLE ADVANTAGES ===\")\n",
    "print(f\"Performance improvement: {performance_improvement:+.1f}%\")\n",
    "print(f\"Stability improvement:   {stability_improvement:+.1f}% (lower std dev)\")\n",
    "print(f\"\\nConclusion: Random Forest provides {'more' if rf_std < tree_std else 'similar'} consistent predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27bc867",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üí° <strong>Tip</strong> (click to expand)</summary>\n",
    "\n",
    "\n",
    "Use the same `tscv = TimeSeriesSplit(n_splits=5)` object for both models to ensure identical fold splits for fair comparison. Call `cross_val_score(model, X, y, cv=tscv, scoring='r2', n_jobs=-1)` for each model - the function returns an array with one score per fold. Calculate standard deviation using `.std()` - lower std means more consistent performance across time periods. Create comparison visualizations using bar charts (fold-by-fold) and box plots (distribution) to show both mean performance and variability differences. The Decision Tree typically shows higher variability (large std dev) because each fold produces a completely different tree structure based on that specific time period's data, while Random Forest averages 100 trees which smooths out temporal variations. Business insight: Lower variability means more predictable production performance - executives prefer models that consistently deliver promised accuracy rather than models that sometimes excel but sometimes fail. If Random Forest shows 30-50% lower standard deviation, that's strong evidence for ensemble reliability worth communicating to stakeholders.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a657fbf0",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ü§´ <strong>Solution</strong> (click to expand)</summary>\n",
    "\n",
    "```python\n",
    "# Model 1: Single Decision Tree (unlimited depth)\n",
    "tree_model = DecisionTreeRegressor(random_state=42)\n",
    "cv_scores_tree = cross_val_score(tree_model, X, y, cv=tscv, scoring='r2', n_jobs=-1)\n",
    "\n",
    "# Model 2: Random Forest (100 trees)\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "cv_scores_rf = cross_val_score(rf_model, X, y, cv=tscv, scoring='r2', n_jobs=-1)\n",
    "\n",
    "# Calculate statistics for both models\n",
    "tree_mean = cv_scores_tree.mean()\n",
    "tree_std = cv_scores_tree.std()\n",
    "rf_mean = cv_scores_rf.mean()\n",
    "rf_std = cv_scores_rf.std()\n",
    "\n",
    "print(\"=== MODEL STABILITY COMPARISON ===\")\n",
    "print(f\"\\nDecision Tree (Unlimited):\")\n",
    "print(f\"  Mean R¬≤: {tree_mean:.4f}\")\n",
    "print(f\"  Std Dev: {tree_std:.4f}\")\n",
    "print(f\"  Range:   {cv_scores_tree.min():.4f} to {cv_scores_tree.max():.4f}\")\n",
    "print(f\"  Coefficient of Variation: {(tree_std/tree_mean)*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nRandom Forest (100 trees):\")\n",
    "print(f\"  Mean R¬≤: {rf_mean:.4f}\")\n",
    "print(f\"  Std Dev: {rf_std:.4f}\")\n",
    "print(f\"  Range:   {cv_scores_rf.min():.4f} to {cv_scores_rf.max():.4f}\")\n",
    "print(f\"  Coefficient of Variation: {(rf_std/rf_mean)*100:.1f}%\")\n",
    "\n",
    "# Visualize comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Side-by-side fold performance\n",
    "plt.subplot(1, 2, 1)\n",
    "x_pos = np.arange(1, len(cv_scores_tree) + 1)\n",
    "width = 0.35\n",
    "plt.bar(x_pos - width/2, cv_scores_tree, width, label='Decision Tree',\n",
    "        color='orange', alpha=0.7)\n",
    "plt.bar(x_pos + width/2, cv_scores_rf, width, label='Random Forest',\n",
    "        color='darkgreen', alpha=0.7)\n",
    "plt.xlabel('Fold Number', fontsize=11)\n",
    "plt.ylabel('R¬≤ Score', fontsize=11)\n",
    "plt.title('Fold-by-Fold Performance Comparison', fontsize=12, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "# Box plot comparison\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot([cv_scores_tree, cv_scores_rf],\n",
    "            labels=['Decision Tree', 'Random Forest'],\n",
    "            widths=0.5)\n",
    "plt.ylabel('R¬≤ Score', fontsize=11)\n",
    "plt.title('Performance Distribution Comparison', fontsize=12, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Stability analysis\n",
    "stability_improvement = (tree_std - rf_std) / tree_std * 100\n",
    "performance_improvement = (rf_mean - tree_mean) / tree_mean * 100\n",
    "\n",
    "print(f\"\\n=== ENSEMBLE ADVANTAGES ===\")\n",
    "print(f\"Performance improvement: {performance_improvement:+.1f}%\")\n",
    "print(f\"Stability improvement:   {stability_improvement:+.1f}% (reduced variability)\")\n",
    "print()\n",
    "\n",
    "print(\"=== KEY INSIGHTS FOR CAPITAL CITY BIKES ===\")\n",
    "print(f\"‚úì Random Forest shows {stability_improvement:.0f}% more consistent performance across time\")\n",
    "print(f\"‚úì Single trees are {'highly' if tree_std > 0.10 else 'moderately'} unstable - performance varies dramatically by period\")\n",
    "print(f\"‚úì Ensemble averaging smooths temporal variation ‚Üí reliable production forecasts\")\n",
    "print(f\"‚úì Lower variability = predictable SLA commitments to executives and investors\")\n",
    "print()\n",
    "\n",
    "print(\"RECOMMENDATION:\")\n",
    "if rf_std < tree_std and rf_mean > tree_mean:\n",
    "    print(\"‚úì Random Forest dominates: Higher mean performance AND lower variability\")\n",
    "    print(\"‚úì Deploy Random Forest for production - delivers consistent, reliable forecasts\")\n",
    "elif rf_mean > tree_mean:\n",
    "    print(\"‚úì Random Forest provides better average performance\")\n",
    "    print(\"‚úì Stability similar to single tree, but higher accuracy justifies deployment\")\n",
    "else:\n",
    "    print(\"‚ö† Unexpected result - investigate data characteristics and model configuration\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bddc88",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b477bf40",
   "metadata": {},
   "source": [
    "## Summary: Production-Grade Tree-Based Ensemble Modeling for Competitive Advantage\n",
    "\n",
    "**What We've Accomplished:**\n",
    "- **Engineered advanced features** including binary indicators (is_rush_hour, is_weekend), categorical encodings (temp_category, weather_severity), and interaction terms (temp√óhour, workingday√óhour) exposing 17 features designed for tree-based pattern discovery\n",
    "- **Implemented decision trees** with both unlimited and constrained depths, demonstrating severe overfitting (training R¬≤ 99%, test R¬≤ 45%) and bias-variance tradeoff through depth constraints\n",
    "- **Deployed Random Forest ensembles** achieving test R¬≤ ‚âà85% through bootstrap aggregation and feature randomness, dramatically reducing overfitting gap from 54 points (single tree) to ~13 points (ensemble)\n",
    "- **Analyzed feature importance** using MDI and permutation methods, identifying hour, temperature, and workingday interactions as dominant drivers (top 3 features capture ~80% of predictive power)\n",
    "\n",
    "**Key Technical Skills Mastered:**\n",
    "- **Feature engineering**: Binary encoding (`.astype(int)`), categorical binning (`pd.cut()`), interaction terms (element-wise multiplication), temporal extraction (`.dt.hour`, `.dt.dayofweek`)\n",
    "- **Decision trees**: DecisionTreeRegressor implementation, tree structure analysis (`.get_depth()`, `.get_n_leaves()`), visualization (`plot_tree()`), overfitting detection (train-test gap calculation)\n",
    "- **Random Forest ensembles**: RandomForestRegressor with n_estimators, max_features='sqrt', bootstrap=True; accessing individual estimators (`.estimators_[i]`), ensemble diversity demonstration\n",
    "- **Feature importance**: MDI extraction (`.feature_importances_`), permutation importance (`permutation_importance()`), cumulative importance analysis, business translation of rankings\n",
    "\n",
    "**Next Steps:**\n",
    "In Module 5, you'll advance to model evaluation and deployment strategies, mastering performance metrics beyond R¬≤ (MAE, MAPE for business reporting), residual analysis for error pattern diagnosis, learning curves for dataset size sufficiency, and production deployment considerations including prediction latency, model versioning, and monitoring strategies.\n",
    "\n",
    "Your Random Forest model transforms Capital City Bikes from linear constraints to non-linear intelligence, achieving 85%+ accuracy that positions them competitively against sophisticated rivals. You've demonstrated the advanced ensemble modeling capabilities, interpretable feature importance analysis, and systematic optimization workflows that distinguish senior ML engineers capable of delivering investor-grade predictive systems!"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
