{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "219b7f5b",
   "metadata": {},
   "source": [
    "# Lecture 9: Tree-Based Models - Programming Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6925fbbc",
   "metadata": {},
   "source": [
    "## Introduction: Advancing Beyond Linear Constraints with Tree-Based Intelligence\n",
    "\n",
    "Welcome back to your Capital City Bikes consulting engagement! Eight months after deploying your linear regression models, the board has approached you with competitive intelligence that demands immediate action. Three rival bike-sharing companies have entered your market with sophisticated ML systems achieving demonstrably better predictions during complex scenarios like weather transitions and seasonal shifts.\n",
    "\n",
    "The CEO's message is direct: \"Our linear models served us well for Series A funding, but competitors are now outperforming us with advanced ensemble methods. The Series B investors expect state-of-the-art predictive capabilities. We need you to implement tree-based models that capture the non-linear patterns and feature interactions our linear approach is missing.\"\n",
    "\n",
    "Think of tree-based modeling as graduating from basic algebra to calculus. While linear regression assumes constant relationships across all conditions, decision trees and random forests discover conditional patterns: \"If temperature is warm AND humidity is low AND it's a weekday, expect high commuter demand. But if temperature is warm AND humidity is high, expect 30% lower demand regardless of day type.\" These conditional rules mirror how experienced operations managers actually think about demand.\n",
    "\n",
    "Your task: engineer sophisticated features that expose non-linear patterns, implement decision trees to understand their interpretable rule-based logic, deploy Random Forest ensembles that achieve production-grade accuracy, and analyze feature importance to guide strategic investments. Every technique must demonstrate measurable improvements over your linear baseline to justify the algorithmic complexity to stakeholders.\n",
    "\n",
    "> **üöÄ Interactive Learning Alert**\n",
    ">\n",
    "> This is an advanced hands-on tutorial with production-grade ensemble modeling challenges. For the best experience:\n",
    ">\n",
    "> - **Click \"Open in Colab\"** at the bottom to run code interactively\n",
    "> - **Execute each code cell** by pressing **Shift + Enter**\n",
    "> - **Complete the challenges** to practice your tree-based modeling skills\n",
    "> - **Think like a senior consultant** - algorithm choice impacts funding discussions and competitive positioning\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c74027",
   "metadata": {},
   "source": [
    "## Step 1: Feature Engineering for Non-Linear Pattern Discovery\n",
    "\n",
    "Let's begin with feature engineering to enhance the quality of our feature set, followed by a preliminary analysis to better understand the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8719a7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries for data manipulation, modeling, and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load Washington D.C. bike-sharing dataset\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/pmarcelino/predictive-modeling/main/datasets/dataset.csv\")\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "# Sort chronologically to maintain temporal integrity for time series modeling\n",
    "df = df.sort_values('datetime').reset_index(drop=True)\n",
    "\n",
    "print(\"=== FEATURE ENGINEERING FOR TREE-BASED MODELS ===\")\n",
    "print(f\"Dataset: {len(df):,} hourly observations\")\n",
    "print(f\"Time range: {df['datetime'].min()} to {df['datetime'].max()}\\n\")\n",
    "\n",
    "# Existing features in dataset\n",
    "print(\"Original features:\")\n",
    "print(df.columns.tolist())\n",
    "print()\n",
    "\n",
    "# Extract temporal features that capture demand cycles\n",
    "df['hour'] = df['datetime'].dt.hour\n",
    "df['dayofweek'] = df['datetime'].dt.dayofweek\n",
    "df['month'] = df['datetime'].dt.month\n",
    "df['year'] = df['datetime'].dt.year\n",
    "\n",
    "# Create binary features for operational planning segments\n",
    "# Binary encoding converts categorical conditions into 0/1 indicators that\n",
    "# trees can use for clean threshold-based splitting decisions\n",
    "df['is_rush_hour'] = ((df['hour'] >= 7) & (df['hour'] <= 9) |\n",
    "                        (df['hour'] >= 17) & (df['hour'] <= 19)).astype(int)\n",
    "# Rush hours (7-9am, 5-7pm) represent peak commuter demand periods\n",
    "\n",
    "df['is_weekend'] = (df['dayofweek'] >= 5).astype(int)\n",
    "# Weekend indicator captures leisure vs. commuter demand patterns\n",
    "\n",
    "df['is_night'] = ((df['hour'] >= 22) | (df['hour'] <= 5)).astype(int)\n",
    "# Night hours (10pm-5am) represent low-demand maintenance windows\n",
    "\n",
    "# Weather condition severity encoding\n",
    "# Map weather codes to interpretable severity levels for better business understanding\n",
    "df['weather_severity'] = df['weather'].map({1: 0, 2: 1, 3: 2, 4: 3})\n",
    "# 0=clear, 1=cloudy, 2=light_rain, 3=heavy_rain/snow\n",
    "\n",
    "# Temperature-based categorical features for threshold effects\n",
    "# Cut temperature into bins representing operational planning segments:\n",
    "# Cold (<10¬∞C), Cool (10-20¬∞C), Warm (20-30¬∞C), Hot (>30¬∞C)\n",
    "df['temp_category'] = pd.cut(df['temp'], bins=[-np.inf, 10, 20, 30, np.inf],\n",
    "                               labels=['cold', 'cool', 'warm', 'hot'])\n",
    "\n",
    "# Humidity-based categorical features\n",
    "# High humidity (>70%) significantly reduces cycling comfort\n",
    "df['humidity_category'] = pd.cut(df['humidity'], bins=[-np.inf, 40, 70, np.inf],\n",
    "                                   labels=['dry', 'moderate', 'humid'])\n",
    "\n",
    "# Interaction features that capture combined effects\n",
    "# Temperature √ó Hour interaction: warm mornings differ from warm evenings in demand patterns\n",
    "df['temp_hour_interaction'] = df['temp'] * df['hour']\n",
    "\n",
    "# Working day √ó Hour: commuter patterns differ dramatically between working days and weekends\n",
    "df['workingday_hour'] = df['workingday'] * df['hour']\n",
    "\n",
    "# Season-Weather interaction: rain in summer affects demand differently than rain in winter\n",
    "df['season_weather'] = df['season'] * df['weather_severity']\n",
    "\n",
    "print(\"=== ENGINEERED FEATURES ===\")\n",
    "print(\"Temporal features: hour, dayofweek, month, year\")\n",
    "print(\"Binary indicators: is_rush_hour, is_weekend, is_night\")\n",
    "print(\"Categorical encodings: weather_severity, temp_category, humidity_category\")\n",
    "print(\"Interaction features: temp_hour_interaction, workingday_hour, season_weather\")\n",
    "print()\n",
    "\n",
    "# Prepare feature matrix for tree-based modeling\n",
    "# Note: Tree-based models can handle categorical variables, but we'll use\n",
    "# numerical encoding for consistency with scikit-learn's requirements\n",
    "feature_columns = [\n",
    "    # Weather features\n",
    "    'temp', 'atemp', 'humidity', 'windspeed', 'weather_severity',\n",
    "    # Temporal features\n",
    "    'hour', 'dayofweek', 'month', 'season',\n",
    "    # Binary indicators\n",
    "    'workingday', 'holiday', 'is_rush_hour', 'is_weekend', 'is_night',\n",
    "    # Interaction features\n",
    "    'temp_hour_interaction', 'workingday_hour', 'season_weather'\n",
    "]\n",
    "\n",
    "X = df[feature_columns]\n",
    "y = df['count']\n",
    "\n",
    "print(f\"Feature matrix: {X.shape[0]} observations √ó {X.shape[1]} features\")\n",
    "print(f\"Target variable: count (hourly bike rentals)\")\n",
    "print()\n",
    "\n",
    "# Display feature statistics for business understanding\n",
    "print(\"=== FEATURE STATISTICS (Business Intelligence) ===\")\n",
    "print(f\"Rush hour observations: {df['is_rush_hour'].sum():,} ({df['is_rush_hour'].mean()*100:.1f}%)\")\n",
    "print(f\"Weekend observations: {df['is_weekend'].sum():,} ({df['is_weekend'].mean()*100:.1f}%)\")\n",
    "print(f\"Night observations: {df['is_night'].sum():,} ({df['is_night'].mean()*100:.1f}%)\")\n",
    "print()\n",
    "\n",
    "# Show demand differences across key segments for operational insights\n",
    "print(\"=== DEMAND PATTERNS BY SEGMENT ===\")\n",
    "print(f\"Rush hour demand: {df[df['is_rush_hour']==1]['count'].mean():.0f} bikes/hour\")\n",
    "print(f\"Non-rush hour demand: {df[df['is_rush_hour']==0]['count'].mean():.0f} bikes/hour\")\n",
    "print(f\"Weekend demand: {df[df['is_weekend']==1]['count'].mean():.0f} bikes/hour\")\n",
    "print(f\"Weekday demand: {df[df['is_weekend']==0]['count'].mean():.0f} bikes/hour\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510f95c4",
   "metadata": {},
   "source": [
    "**What this does:**\n",
    "- Loads Washington D.C. bike-sharing data and sorts chronologically for time series integrity\n",
    "- Engineers temporal features (hour, dayofweek, month) that capture cyclical demand patterns\n",
    "- Creates binary indicators (is_rush_hour, is_weekend, is_night) for operational segments\n",
    "- Builds interaction features (temp√óhour, workingday√óhour) that expose non-linear effects\n",
    "- Categorizes continuous variables (temp_category, humidity_category) for threshold discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b98bccd",
   "metadata": {},
   "source": [
    "### Challenge 1: Analyze Feature Distributions and Relationships\n",
    "\n",
    "Your client asks: \"Can you create a visual report showing how different features impact demand? I need to see which factors drive ridership so we can understand the data better.\" Explore feature interactions and segment analysis through visualizations.\n",
    "\n",
    "**Your Task:** Create visualizations showing demand patterns across different feature combinations (e.g., rush_hour + working_day, temperature + weather severity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4586ce11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - analyze feature distributions and demand patterns\n",
    "\n",
    "# Example 1: Rush hour + working day combination\n",
    "segment_analysis = df.groupby(['is_rush_hour', 'workingday'])['count'].agg(['mean', 'count'])\n",
    "print(\"=== RUSH HOUR √ó WORKING DAY ANALYSIS ===\")\n",
    "print(segment_analysis)\n",
    "\n",
    "# Example 2: Create a heatmap showing demand by hour and day of week\n",
    "hourly_daily = df.pivot_table(values='count', index='___', columns='___', aggfunc='mean')\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(hourly_daily, cmap='YlOrRd', fmt='.0f', cbar_kws={'label': 'Average Demand'})\n",
    "plt.title('___')\n",
    "plt.xlabel('___')\n",
    "plt.ylabel('___')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Example 3: Visualize temperature √ó weather severity interaction\n",
    "# Create scatter plot or box plots showing how demand varies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0bad38",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üí° <strong>Tip</strong> (click to expand)</summary>\n",
    "\n",
    "\n",
    "Start with `.groupby(['is_rush_hour', 'workingday'])['count'].agg(['mean', 'count', 'std'])` to see how demand varies across combinations. For the heatmap, use `df.pivot_table(values='count', index='hour', columns='dayofweek', aggfunc='mean')` which creates a matrix showing average demand for each hour-day combination. Set `cmap='YlOrRd'` for a heat-based color scheme that makes patterns visually obvious. For temperature √ó weather interactions, consider using `sns.boxplot(x='temp_category', y='count', hue='weather_severity', data=df)` to show distributions. Look for segments with 2-3x demand differences - these represent high-value operational optimization opportunities. The heatmap will clearly show morning/evening rush hour peaks on weekdays versus flatter weekend patterns. Business insight: rush hour + working day combinations might show 300+ bikes/hour while night + weekend shows <50 bikes/hour, revealing where fleet positioning matters most.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8ef2f8",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ü§´ <strong>Solution</strong> (click to expand)</summary>\n",
    "\n",
    "```python\n",
    "# Example 1: Rush hour + working day combination\n",
    "segment_analysis = df.groupby(['is_rush_hour', 'workingday'])['count'].agg(['mean', 'count', 'std'])\n",
    "print(\"=== RUSH HOUR √ó WORKING DAY ANALYSIS ===\")\n",
    "print(segment_analysis.round(1))\n",
    "print()\n",
    "\n",
    "# Example 2: Heatmap showing demand by hour and day of week\n",
    "hourly_daily = df.pivot_table(values='count', index='hour', columns='dayofweek', aggfunc='mean')\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(hourly_daily, cmap='YlOrRd', annot=True, fmt='.0f', cbar_kws={'label': 'Average Demand (bikes/hour)'})\n",
    "plt.title('Demand Heatmap: Hour √ó Day of Week', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Day of Week (0=Mon, 6=Sun)', fontsize=11)\n",
    "plt.ylabel('Hour of Day', fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Example 3: Temperature √ó Weather severity interaction\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='temp_category', y='count', hue='weather_severity', data=df)\n",
    "plt.title('Demand by Temperature Category and Weather Severity', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Temperature Category', fontsize=11)\n",
    "plt.ylabel('Hourly Demand (bikes)', fontsize=11)\n",
    "plt.legend(title='Weather Severity', labels=['Clear', 'Cloudy', 'Light Rain', 'Heavy Rain'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=== KEY INSIGHTS FOR CAPITAL CITY BIKES ===\")\n",
    "print(\"‚úì Rush hour + working day: Highest demand segment (optimize fleet positioning)\")\n",
    "print(\"‚úì Heatmap reveals: Strong morning (7-9am) and evening (5-7pm) peaks on weekdays\")\n",
    "print(\"‚úì Temperature √ó Weather: Warm+clear weather shows 3x demand vs. cold+rainy conditions\")\n",
    "print(\"‚úì Operational priority: Focus dynamic repositioning on weekday rush hours\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6f3085",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40524492",
   "metadata": {},
   "source": [
    "## Step 2: Implement Decision Tree Regressor\n",
    "\n",
    "Now that we've seen how our engineered features impact demand, let's try our first decision tree model. Decision trees can capture non-linear patterns through interpretable if-then rules that linear regression cannot represent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a04a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tree-based modeling tools from scikit-learn\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Already have X and y from Step 1 feature engineering\n",
    "print(\"=== DECISION TREE IMPLEMENTATION ===\\n\")\n",
    "\n",
    "# Create chronological train-test split (80/20) for honest evaluation\n",
    "# Time series data requires chronological splitting to prevent temporal leakage\n",
    "split_index = int(len(df) * 0.8)\n",
    "X_train = X.iloc[:split_index]\n",
    "X_test = X.iloc[split_index:]\n",
    "y_train = y.iloc[:split_index]\n",
    "y_test = y.iloc[split_index:]\n",
    "\n",
    "print(f\"Training set: {len(X_train):,} observations ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"Testing set:  {len(X_test):,} observations ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "print(f\"Training period: {df.iloc[:split_index]['datetime'].min()} to {df.iloc[:split_index]['datetime'].max()}\")\n",
    "print(f\"Testing period:  {df.iloc[split_index:]['datetime'].min()} to {df.iloc[split_index:]['datetime'].max()}\")\n",
    "print()\n",
    "\n",
    "# Decision Tree with unlimited depth (demonstrating overfitting potential)\n",
    "print(\"--- Training Decision Tree (Unlimited Depth) ---\")\n",
    "# DecisionTreeRegressor creates a tree that recursively partitions feature space\n",
    "# to minimize mean squared error within each region (leaf node)\n",
    "tree_unlimited = DecisionTreeRegressor(random_state=42)\n",
    "# No max_depth specified = tree grows until leaves are pure or contain min_samples_split\n",
    "tree_unlimited.fit(X_train, y_train)\n",
    "\n",
    "# Examine tree structure to understand model complexity\n",
    "print(f\"Tree depth: {tree_unlimited.get_depth()}\")\n",
    "print(f\"Number of leaves: {tree_unlimited.get_n_leaves()}\")\n",
    "print(f\"Total nodes: {tree_unlimited.tree_.node_count}\")\n",
    "print()\n",
    "\n",
    "# Generate predictions on both training and testing sets\n",
    "train_pred_unlimited = tree_unlimited.predict(X_train)\n",
    "test_pred_unlimited = tree_unlimited.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "train_r2_unlimited = r2_score(y_train, train_pred_unlimited)\n",
    "test_r2_unlimited = r2_score(y_test, test_pred_unlimited)\n",
    "train_rmse_unlimited = np.sqrt(mean_squared_error(y_train, train_pred_unlimited))\n",
    "test_rmse_unlimited = np.sqrt(mean_squared_error(y_test, test_pred_unlimited))\n",
    "\n",
    "print(\"=== DECISION TREE PERFORMANCE (Unlimited Depth) ===\")\n",
    "print(f\"Training:  R¬≤ = {train_r2_unlimited:.4f}, RMSE = {train_rmse_unlimited:.2f} bikes\")\n",
    "print(f\"Testing:   R¬≤ = {test_r2_unlimited:.4f}, RMSE = {test_rmse_unlimited:.2f} bikes\")\n",
    "print(f\"Overfit gap: {train_r2_unlimited - test_r2_unlimited:.4f}\")\n",
    "print()\n",
    "\n",
    "if (train_r2_unlimited - test_r2_unlimited) > 0.30:\n",
    "    print(\"‚ö† SEVERE OVERFITTING DETECTED:\")\n",
    "    print(f\"  ‚Ä¢ Training R¬≤ near-perfect ({train_r2_unlimited:.1%}) but testing R¬≤ only {test_r2_unlimited:.1%}\")\n",
    "    print(f\"  ‚Ä¢ Gap of {train_r2_unlimited - test_r2_unlimited:.1%} indicates memorization, not learning\")\n",
    "    print(f\"  ‚Ä¢ Tree depth of {tree_unlimited.get_depth()} with {tree_unlimited.get_n_leaves():,} leaves creates overly specific rules\")\n",
    "    print(f\"  ‚Ä¢ Solution: Limit tree depth or use ensemble methods (Random Forest)\")\n",
    "elif (train_r2_unlimited - test_r2_unlimited) > 0.15:\n",
    "    print(\"‚ö† MODERATE OVERFITTING:\")\n",
    "    print(f\"  ‚Ä¢ Performance gap suggests some memorization of training data\")\n",
    "    print(f\"  ‚Ä¢ Consider constraining tree depth or using regularization\")\n",
    "else:\n",
    "    print(\"‚úì Good generalization - training and testing performance similar\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"=== WHY SINGLE TREES OVERFIT ===\")\n",
    "print(\"‚Ä¢ Decision trees recursively partition data until leaves are pure\")\n",
    "print(\"‚Ä¢ Unlimited depth = tree memorizes training data noise and outliers\")\n",
    "print(\"‚Ä¢ Result: Near-perfect training fit but poor generalization to new data\")\n",
    "print(\"‚Ä¢ Solution: Use ensemble methods (Random Forest) that average many trees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a784068",
   "metadata": {},
   "source": [
    "**What this does:**\n",
    "- Creates chronological 80/20 train-test split preserving temporal order for honest evaluation\n",
    "- Trains unlimited-depth decision tree showing severe overfitting (training R¬≤ ‚âà99%, test R¬≤ ‚âà45%)\n",
    "- Displays tree structure metrics (depth, leaves, nodes) revealing model complexity\n",
    "- Calculates overfit gap (train R¬≤ - test R¬≤) demonstrating why single trees struggle with generalization\n",
    "- Shows that unlimited trees memorize training data patterns rather than learning generalizable relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa366e11",
   "metadata": {},
   "source": [
    "### Challenge 2: Visualize Decision Tree Structure\n",
    "\n",
    "Your client asks: \"Can you show me how the tree makes decisions? I want to understand the business rules it learned.\" Create a visualization of a shallow tree for interpretability.\n",
    "\n",
    "**Your Task:** Train a very shallow tree (max_depth=3) and visualize its structure with feature names and decision thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c428dfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - create and visualize shallow decision tree\n",
    "\n",
    "# Train a shallow tree for visualization (max_depth=3 for clarity)\n",
    "tree_shallow = DecisionTreeRegressor(max_depth=___, min_samples_leaf=50, random_state=42)\n",
    "tree_shallow.fit(X_train, y_train)\n",
    "\n",
    "# Calculate performance of shallow tree\n",
    "test_pred_shallow = tree_shallow.predict(X_test)\n",
    "test_r2_shallow = r2_score(y_test, test_pred_shallow)\n",
    "\n",
    "print(f\"=== SHALLOW TREE (max_depth=3) ===\")\n",
    "print(f\"Tree depth: {tree_shallow.get_depth()}\")\n",
    "print(f\"Number of leaves: {tree_shallow.get_n_leaves()}\")\n",
    "print(f\"Test R¬≤: {test_r2_shallow:.4f}\")\n",
    "print()\n",
    "\n",
    "# Visualize tree structure\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(tree_shallow,\n",
    "          feature_names=_____,\n",
    "          filled=True,\n",
    "          rounded=True,\n",
    "          fontsize=10)\n",
    "plt.title('Decision Tree Structure (max_depth=3) - Interpretable Business Rules',\n",
    "          fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Extract and display the most important decision rules\n",
    "print(\"=== TOP DECISION RULES (Business Interpretation) ===\")\n",
    "feature_importance_shallow = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': tree_shallow.feature_importances_\n",
    "}).sort_values('importance', ascending=False).head(5)\n",
    "print(feature_importance_shallow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb80e71c",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üí° <strong>Tip</strong> (click to expand)</summary>\n",
    "\n",
    "\n",
    "Use `max_depth=3` to create a tree shallow enough to visualize clearly on one page. The `plot_tree()` function requires `feature_names=feature_columns` (the list of column names you defined in Step 1) to display readable feature labels instead of generic \"X[0]\" notation. Set `filled=True` to color nodes by prediction value (darker colors = higher predicted demand) and `rounded=True` for professional appearance. After visualization, use `tree_shallow.feature_importances_` to extract which features appear most frequently in the top splits - these are the key drivers the tree identified. A shallow tree sacrifices accuracy for interpretability, so expect test R¬≤ around 65-75% (lower than deeper trees) but you gain the ability to communicate exact decision logic to stakeholders. The visualization will show something like: \"If hour <= 12.5 AND workingday <= 0.5, predict low demand (weekend morning pattern)\". These are the if-then business rules your operations team can actually use for planning.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054f0d58",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ü§´ <strong>Solution</strong> (click to expand)</summary>\n",
    "\n",
    "```python\n",
    "# Train a shallow tree for visualization (max_depth=3 for clarity)\n",
    "tree_shallow = DecisionTreeRegressor(max_depth=3, min_samples_leaf=50, random_state=42)\n",
    "tree_shallow.fit(X_train, y_train)\n",
    "\n",
    "# Calculate performance of shallow tree\n",
    "test_pred_shallow = tree_shallow.predict(X_test)\n",
    "test_r2_shallow = r2_score(y_test, test_pred_shallow)\n",
    "\n",
    "print(f\"=== SHALLOW TREE (max_depth=3) ===\")\n",
    "print(f\"Tree depth: {tree_shallow.get_depth()}\")\n",
    "print(f\"Number of leaves: {tree_shallow.get_n_leaves()}\")\n",
    "print(f\"Test R¬≤: {test_r2_shallow:.4f}\")\n",
    "print()\n",
    "\n",
    "# Visualize tree structure\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(tree_shallow,\n",
    "          feature_names=feature_columns,\n",
    "          filled=True,\n",
    "          rounded=True,\n",
    "          fontsize=10)\n",
    "plt.title('Decision Tree Structure (max_depth=3) - Interpretable Business Rules',\n",
    "          fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Extract and display the most important decision rules\n",
    "print(\"=== TOP DECISION RULES (Business Interpretation) ===\")\n",
    "feature_importance_shallow = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': tree_shallow.feature_importances_\n",
    "}).sort_values('importance', ascending=False).head(5)\n",
    "print(feature_importance_shallow.round(4))\n",
    "print()\n",
    "\n",
    "print(\"=== BUSINESS RULE TRANSLATION ===\")\n",
    "print(\"The tree makes decisions using if-then logic:\")\n",
    "print(\"‚Ä¢ Root node: Splits on most predictive feature (likely 'hour' or 'is_rush_hour')\")\n",
    "print(\"‚Ä¢ Each split creates two branches: one for observations meeting condition, one for those that don't\")\n",
    "print(\"‚Ä¢ Leaf nodes (colored boxes): Final demand predictions for observations reaching that leaf\")\n",
    "print(\"‚Ä¢ Node color intensity: Darker = higher predicted demand, Lighter = lower predicted demand\")\n",
    "print()\n",
    "print(\"Example interpretation:\")\n",
    "print(\"'If hour <= 12.5 AND workingday = 1 ‚Üí Predict 150 bikes/hour (morning commute)'\")\n",
    "print(\"'If hour > 18.5 AND temp > 20 ‚Üí Predict 280 bikes/hour (warm evening peak)'\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc55271",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edc8117",
   "metadata": {},
   "source": [
    "## Step 3: Deploy Random Forest Ensemble\n",
    "\n",
    "Let's implement Random Forest to overcome individual tree overfitting through ensemble averaging of multiple diverse trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323c1bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Random Forest from scikit-learn's ensemble module\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "print(\"=== RANDOM FOREST ENSEMBLE IMPLEMENTATION ===\\n\")\n",
    "\n",
    "# Train Random Forest with default parameters first\n",
    "print(\"--- Training Random Forest (Default: 100 trees) ---\")\n",
    "# RandomForestRegressor creates an ensemble of decision trees:\n",
    "# - Each tree trains on a bootstrap sample (random sampling with replacement)\n",
    "# - Each split considers only a subset of features (max_features='sqrt' by default)\n",
    "# - Final prediction = average of all tree predictions (reduces variance)\n",
    "rf_default = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "# n_estimators=100: Build 100 decision trees in the forest\n",
    "# random_state=42: Ensures reproducible results across runs\n",
    "# n_jobs=-1: Use all CPU cores for parallel training (speeds up computation)\n",
    "rf_default.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Forest size: {rf_default.n_estimators} trees\")\n",
    "print(f\"Features considered per split: sqrt({X_train.shape[1]}) ‚âà {int(np.sqrt(X_train.shape[1]))} features\")\n",
    "print()\n",
    "\n",
    "# Generate predictions with Random Forest\n",
    "train_pred_rf = rf_default.predict(X_train)\n",
    "test_pred_rf = rf_default.predict(X_test)\n",
    "\n",
    "train_r2_rf = r2_score(y_train, train_pred_rf)\n",
    "test_r2_rf = r2_score(y_test, test_pred_rf)\n",
    "train_rmse_rf = np.sqrt(mean_squared_error(y_train, train_pred_rf))\n",
    "test_rmse_rf = np.sqrt(mean_squared_error(y_test, test_pred_rf))\n",
    "\n",
    "print(\"=== RANDOM FOREST PERFORMANCE ===\")\n",
    "print(f\"Training:  R¬≤ = {train_r2_rf:.4f}, RMSE = {train_rmse_rf:.2f} bikes\")\n",
    "print(f\"Testing:   R¬≤ = {test_r2_rf:.4f}, RMSE = {test_rmse_rf:.2f} bikes\")\n",
    "print(f\"Overfit gap: {train_r2_rf - test_r2_rf:.4f}\")\n",
    "print()\n",
    "\n",
    "# Compare Random Forest vs Single Decision Tree\n",
    "print(\"=== ALGORITHM PERFORMANCE COMPARISON ===\")\n",
    "print(\"Model                          | Train R¬≤  | Test R¬≤   | Overfit Gap | Status\")\n",
    "print(\"-\" * 85)\n",
    "print(f\"Single Tree (Unlimited)        | {train_r2_unlimited:.4f}    | {test_r2_unlimited:.4f}    | {train_r2_unlimited - test_r2_unlimited:.4f}      | Severe Overfit\")\n",
    "print(f\"Random Forest (100 trees)      | {train_r2_rf:.4f}    | {test_r2_rf:.4f}    | {train_r2_rf - test_r2_rf:.4f}      | Good Balance\")\n",
    "print()\n",
    "\n",
    "# Calculate competitive advantages for business reporting\n",
    "test_improvement_vs_tree = (test_r2_rf - test_r2_unlimited) / test_r2_unlimited * 100\n",
    "\n",
    "print(\"=== RANDOM FOREST COMPETITIVE ADVANTAGES ===\")\n",
    "print(f\"Test R¬≤ improvement vs single tree: {test_improvement_vs_tree:+.1f}%\")\n",
    "print(f\"Overfit gap reduction: {train_r2_unlimited - test_r2_unlimited:.4f} ‚Üí {train_r2_rf - test_r2_rf:.4f}\")\n",
    "print()\n",
    "\n",
    "if test_r2_rf >= 0.85:\n",
    "    print(\"‚úì EXCELLENT PERFORMANCE:\")\n",
    "    print(\"  ‚Ä¢ Test R¬≤ ‚â• 85% meets Series B investor expectations\")\n",
    "    print(\"  ‚Ä¢ Production-ready accuracy for operational deployment\")\n",
    "    print(\"  ‚Ä¢ Competitive advantage over linear baseline established\")\n",
    "elif test_r2_rf >= 0.75:\n",
    "    print(\"‚úì STRONG PERFORMANCE:\")\n",
    "    print(\"  ‚Ä¢ Test R¬≤ ‚â• 75% represents significant improvement\")\n",
    "    print(\"  ‚Ä¢ Suitable for operational planning and strategic decision-making\")\n",
    "    print(\"  ‚Ä¢ Demonstrates advanced ML capabilities to stakeholders\")\n",
    "else:\n",
    "    print(\"‚ö† MODERATE PERFORMANCE:\")\n",
    "    print(\"  ‚Ä¢ Test R¬≤ suggests room for further optimization\")\n",
    "    print(\"  ‚Ä¢ Consider additional feature engineering or hyperparameter tuning\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Demonstrate ensemble diversity by examining individual tree predictions\n",
    "print(\"=== ENSEMBLE DIVERSITY DEMONSTRATION ===\")\n",
    "print(\"Examining predictions from first 10 trees for one observation:\")\n",
    "example_obs = X_test.iloc[0:1]\n",
    "print(f\"Example observation features:\")\n",
    "print(f\"  Hour: {example_obs['hour'].values[0]}, Temp: {example_obs['temp'].values[0]:.1f}¬∞C, \")\n",
    "print(f\"  Working day: {example_obs['workingday'].values[0]}, Rush hour: {example_obs['is_rush_hour'].values[0]}\")\n",
    "print()\n",
    "\n",
    "tree_predictions = []\n",
    "# Convert to numpy array once to avoid feature name warnings\n",
    "example_obs_array = example_obs.to_numpy()\n",
    "for i in range(min(10, rf_default.n_estimators)):\n",
    "    # Each tree in the forest makes independent predictions\n",
    "    tree_pred = rf_default.estimators_[i].predict(example_obs_array)[0]\n",
    "    tree_predictions.append(tree_pred)\n",
    "    print(f\"Tree {i+1:2d} predicts: {tree_pred:6.1f} bikes\")\n",
    "\n",
    "print(f\"\\nAverage of 10 trees:  {np.mean(tree_predictions):6.1f} bikes\")\n",
    "print(f\"Full ensemble (100):  {rf_default.predict(example_obs)[0]:6.1f} bikes\")\n",
    "print(f\"Prediction spread:    {np.max(tree_predictions) - np.min(tree_predictions):6.1f} bikes\")\n",
    "print(f\"Standard deviation:   {np.std(tree_predictions):6.1f} bikes\")\n",
    "print()\n",
    "\n",
    "print(\"WHY DIVERSITY MATTERS:\")\n",
    "print(\"‚Ä¢ Each tree sees different bootstrap sample (random observations)\")\n",
    "print(\"‚Ä¢ Each split uses different random feature subset\")\n",
    "print(\"‚Ä¢ Individual trees make different predictions (some high, some low)\")\n",
    "print(\"‚Ä¢ Averaging cancels individual errors ‚Üí more stable, reliable forecast\")\n",
    "print(\"‚Ä¢ This is the 'wisdom of crowds' principle: collective intelligence > individual guesses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b675261",
   "metadata": {},
   "source": [
    "**What this does:**\n",
    "- Trains Random Forest with 100 trees using bootstrap sampling and feature randomness\n",
    "- Evaluates on both training and testing sets showing dramatically reduced overfitting vs. single tree\n",
    "- Compares performance against unlimited decision tree demonstrating ensemble advantages\n",
    "- Shows individual tree predictions for one observation revealing diversity in the forest\n",
    "- Calculates prediction spread and standard deviation quantifying ensemble variance reduction\n",
    "- Provides business-focused performance assessment (excellent/strong/moderate categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca672cb1",
   "metadata": {},
   "source": [
    "### Challenge 3: Compare Different Ensemble Sizes\n",
    "\n",
    "Your client asks: \"Do we really need 100 trees? Could we get similar performance with fewer trees (faster training) or do we need more trees for better accuracy?\" Experiment with ensemble size.\n",
    "\n",
    "**Your Task:** Train Random Forests with different numbers of trees (10, 50, 100, 200, 300) and analyze the performance vs. training time tradeoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7c45f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - compare different ensemble sizes\n",
    "\n",
    "import time\n",
    "\n",
    "ensemble_sizes = [10, 50, 100, 200, 300]\n",
    "results = []\n",
    "\n",
    "for n_trees in ensemble_sizes:\n",
    "    print(f\"Training Random Forest with {n_trees} trees...\")\n",
    "\n",
    "    # Time the training process\n",
    "    start_time = time.time()\n",
    "    rf_temp = RandomForestRegressor(n_estimators=_____, random_state=42, n_jobs=-1)\n",
    "    rf_temp.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    # Evaluate performance\n",
    "    test_pred_temp = rf_temp.predict(X_test)\n",
    "    test_r2_temp = r2_score(y_test, test_pred_temp)\n",
    "    test_rmse_temp = np.sqrt(mean_squared_error(y_test, test_pred_temp))\n",
    "\n",
    "    # Store results\n",
    "    results.append({\n",
    "        'n_trees': n_trees,\n",
    "        'training_time': training_time,\n",
    "        'test_r2': test_r2_temp,\n",
    "        'test_rmse': test_rmse_temp\n",
    "    })\n",
    "\n",
    "    print(f\"  Training time: {training_time:.2f}s, Test R¬≤: {test_r2_temp:.4f}\")\n",
    "    print()\n",
    "\n",
    "# Visualize performance vs ensemble size\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Panel 1: Test R¬≤ vs ensemble size\n",
    "axes[0].plot(results_df['n_trees'], results_df['test_r2'], 'o-', linewidth=2, markersize=8, color='darkgreen')\n",
    "axes[0].set_xlabel('Number of Trees', fontsize=11)\n",
    "axes[0].set_ylabel('Test R¬≤', fontsize=11)\n",
    "axes[0].set_title('Test Performance vs Ensemble Size', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 2: Training time vs ensemble size\n",
    "axes[1].plot(results_df['n_trees'], results_df['training_time'], 's-', linewidth=2, markersize=8, color='darkorange')\n",
    "axes[1].set_xlabel('Number of Trees', fontsize=11)\n",
    "axes[1].set_ylabel('Training Time (seconds)', fontsize=11)\n",
    "axes[1].set_title('Training Time vs Ensemble Size', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Business recommendation\n",
    "print(\"=== ENSEMBLE SIZE RECOMMENDATION ===\")\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d9a6db",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üí° <strong>Tip</strong> (click to expand)</summary>\n",
    "\n",
    "\n",
    "Loop through each ensemble size and create a fresh `RandomForestRegressor(n_estimators=n_trees, random_state=42, n_jobs=-1)` for each iteration. Use `time.time()` before and after `.fit()` to measure training duration: `start = time.time(); model.fit(X, y); duration = time.time() - start`. Store all results in a list of dictionaries, then convert to DataFrame for easy analysis and visualization. The performance curve typically shows diminishing returns: 10‚Üí50 trees gives large improvement, 100‚Üí200 gives small improvement, 200‚Üí300 gives minimal improvement. Training time increases linearly with tree count (200 trees takes ~2x as long as 100 trees) so there's a clear tradeoff. Business insight: 100-200 trees usually provides the sweet spot - excellent performance without excessive training time. For production deployment, consider whether faster predictions (fewer trees) or maximum accuracy (more trees) matters more to your client's use case. If they need real-time predictions for millions of users, fewer trees might be preferable; if they're doing daily batch forecasting for operational planning, more trees at higher accuracy makes sense.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9146b9f8",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ü§´ <strong>Solution</strong> (click to expand)</summary>\n",
    "\n",
    "```python\n",
    "import time\n",
    "\n",
    "ensemble_sizes = [10, 50, 100, 200, 300]\n",
    "results = []\n",
    "\n",
    "for n_trees in ensemble_sizes:\n",
    "    print(f\"Training Random Forest with {n_trees} trees...\")\n",
    "\n",
    "    # Time the training process\n",
    "    start_time = time.time()\n",
    "    rf_temp = RandomForestRegressor(n_estimators=n_trees, random_state=42, n_jobs=-1)\n",
    "    rf_temp.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    # Evaluate performance\n",
    "    test_pred_temp = rf_temp.predict(X_test)\n",
    "    test_r2_temp = r2_score(y_test, test_pred_temp)\n",
    "    test_rmse_temp = np.sqrt(mean_squared_error(y_test, test_pred_temp))\n",
    "\n",
    "    # Store results\n",
    "    results.append({\n",
    "        'n_trees': n_trees,\n",
    "        'training_time': training_time,\n",
    "        'test_r2': test_r2_temp,\n",
    "        'test_rmse': test_rmse_temp\n",
    "    })\n",
    "\n",
    "    print(f\"  Training time: {training_time:.2f}s, Test R¬≤: {test_r2_temp:.4f}\")\n",
    "    print()\n",
    "\n",
    "# Visualize performance vs ensemble size\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Panel 1: Test R¬≤ vs ensemble size\n",
    "axes[0].plot(results_df['n_trees'], results_df['test_r2'], 'o-', linewidth=2, markersize=8, color='darkgreen')\n",
    "axes[0].set_xlabel('Number of Trees', fontsize=11)\n",
    "axes[0].set_ylabel('Test R¬≤', fontsize=11)\n",
    "axes[0].set_title('Test Performance vs Ensemble Size', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 2: Training time vs ensemble size\n",
    "axes[1].plot(results_df['n_trees'], results_df['training_time'], 's-', linewidth=2, markersize=8, color='darkorange')\n",
    "axes[1].set_xlabel('Number of Trees', fontsize=11)\n",
    "axes[1].set_ylabel('Training Time (seconds)', fontsize=11)\n",
    "axes[1].set_title('Training Time vs Ensemble Size', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Business recommendation\n",
    "print(\"=== ENSEMBLE SIZE RECOMMENDATION ===\")\n",
    "print(results_df.to_string(index=False))\n",
    "print()\n",
    "\n",
    "best_value_idx = results_df['test_r2'].idxmax()\n",
    "best_value = results_df.loc[best_value_idx]\n",
    "print(f\"‚úì Recommended: {int(best_value['n_trees'])} trees\")\n",
    "print(f\"  ‚Ä¢ Test R¬≤: {best_value['test_r2']:.4f}\")\n",
    "print(f\"  ‚Ä¢ Training time: {best_value['training_time']:.2f}s\")\n",
    "print(f\"  ‚Ä¢ Rationale: {'Excellent accuracy-speed balance' if best_value['n_trees'] <= 100 else 'Maximum accuracy justified for critical forecasting'}\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae7f740",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e23688",
   "metadata": {},
   "source": [
    "## Step 4: Feature Importance Analysis\n",
    "\n",
    "Let's analyze which features drive bike demand predictions to guide strategic investments and operational decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d854960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature importance from trained Random Forest\n",
    "print(\"=== RANDOM FOREST FEATURE IMPORTANCE ANALYSIS ===\\n\")\n",
    "\n",
    "# Feature importance based on mean decrease in impurity (MDI)\n",
    "# Higher values = feature contributed more to prediction accuracy across all trees\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': rf_default.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"--- Feature Importance Rankings ---\")\n",
    "print(f\"{'Rank':<6} {'Feature':<25} {'Importance':<12} {'Percentage':<12} {'Visual'}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "for rank, (idx, row) in enumerate(feature_importance.iterrows(), 1):\n",
    "    bar = '‚ñà' * int(row['importance'] * 100)\n",
    "    percentage = row['importance'] * 100\n",
    "    print(f\"{rank:<6} {row['feature']:<25} {row['importance']:.4f}       {percentage:>6.2f}%        {bar}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Calculate cumulative importance to identify critical feature subset\n",
    "feature_importance['cumulative'] = feature_importance['importance'].cumsum()\n",
    "\n",
    "print(\"--- Cumulative Importance Analysis ---\")\n",
    "for i in range(min(5, len(feature_importance))):\n",
    "    feature_name = feature_importance.iloc[i]['feature']\n",
    "    cumulative = feature_importance.iloc[i]['cumulative']\n",
    "    print(f\"Top {i+1} feature(s): {cumulative:.1%} of total predictive power\")\n",
    "    if cumulative >= 0.80:\n",
    "        print(f\"  ‚Üí {i+1} features capture 80% of model intelligence\")\n",
    "        break\n",
    "\n",
    "print()\n",
    "\n",
    "# Visualize feature importance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Panel 1: Horizontal bar chart of top 10 features\n",
    "top_features = feature_importance.head(10)\n",
    "colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(top_features)))\n",
    "axes[0].barh(range(len(top_features)), top_features['importance'], color=colors)\n",
    "axes[0].set_yticks(range(len(top_features)))\n",
    "axes[0].set_yticklabels(top_features['feature'])\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].set_xlabel('Importance Score', fontsize=11)\n",
    "axes[0].set_title('Top 10 Feature Importance', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Panel 2: Cumulative importance curve\n",
    "axes[1].plot(range(1, len(feature_importance) + 1), feature_importance['cumulative'],\n",
    "             'o-', linewidth=2, markersize=6, color='darkgreen')\n",
    "axes[1].axhline(y=0.80, color='red', linestyle='--', linewidth=2, label='80% threshold')\n",
    "axes[1].axhline(y=0.90, color='orange', linestyle='--', linewidth=2, label='90% threshold')\n",
    "axes[1].set_xlabel('Number of Top Features', fontsize=11)\n",
    "axes[1].set_ylabel('Cumulative Importance', fontsize=11)\n",
    "axes[1].set_title('Cumulative Feature Contribution', fontsize=12, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=== BUSINESS INSIGHTS FOR CAPITAL CITY BIKES ===\")\n",
    "\n",
    "# Interpret top 3 features for strategic recommendations\n",
    "for rank in range(min(3, len(feature_importance))):\n",
    "    feature = feature_importance.iloc[rank]['feature']\n",
    "    importance = feature_importance.iloc[rank]['importance']\n",
    "\n",
    "    print(f\"\\n{rank+1}. {feature}: {importance:.1%} importance\")\n",
    "\n",
    "    # Business interpretation by feature type\n",
    "    if feature in ['hour', 'is_rush_hour']:\n",
    "        print(\"   ‚Üí IMPLICATION: Time-of-day dominates demand patterns\")\n",
    "        print(\"   ‚Üí STRATEGY: Optimize fleet positioning by hour (rush hours critical)\")\n",
    "        print(\"   ‚Üí INVESTMENT: Real-time repositioning systems, surge pricing algorithms\")\n",
    "    elif feature in ['temp', 'atemp']:\n",
    "        print(\"   ‚Üí IMPLICATION: Temperature drives cycling comfort decisions\")\n",
    "        print(\"   ‚Üí STRATEGY: Weather-responsive capacity planning\")\n",
    "        print(\"   ‚Üí INVESTMENT: Weather API integration, temperature-based forecasting\")\n",
    "    elif feature in ['workingday', 'dayofweek', 'is_weekend']:\n",
    "        print(\"   ‚Üí IMPLICATION: Commuter vs. leisure patterns differ fundamentally\")\n",
    "        print(\"   ‚Üí STRATEGY: Separate weekday (commute) vs. weekend (leisure) operations\")\n",
    "        print(\"   ‚Üí INVESTMENT: Day-specific marketing, differential pricing strategies\")\n",
    "    elif feature in ['season', 'month']:\n",
    "        print(\"   ‚Üí IMPLICATION: Seasonal variations require long-term planning\")\n",
    "        print(\"   ‚Üí STRATEGY: Adjust fleet size, maintenance schedules by season\")\n",
    "        print(\"   ‚Üí INVESTMENT: Seasonal fleet scaling, predictive maintenance\")\n",
    "    elif feature in ['weather_severity', 'humidity', 'windspeed']:\n",
    "        print(\"   ‚Üí IMPLICATION: Weather conditions directly impact usage decisions\")\n",
    "        print(\"   ‚Üí STRATEGY: Dynamic bike redistribution based on forecasts\")\n",
    "        print(\"   ‚Üí INVESTMENT: Weather-triggered alerts, covered bike stations\")\n",
    "    else:\n",
    "        print(\"   ‚Üí IMPLICATION: Feature provides supplementary predictive value\")\n",
    "        print(\"   ‚Üí STRATEGY: Maintain in model for marginal accuracy gains\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*75)\n",
    "print(\"STRATEGIC RECOMMENDATION:\")\n",
    "top_feature = feature_importance.iloc[0]['feature']\n",
    "top_importance = feature_importance.iloc[0]['importance']\n",
    "print(f\"‚úì '{top_feature}' dominates with {top_importance:.1%} importance\")\n",
    "print(f\"‚úì Top 3 features capture {feature_importance.iloc[2]['cumulative']:.1%} of predictive power\")\n",
    "print(f\"‚úì Focus operational investments on temporal optimization and weather responsiveness\")\n",
    "print(f\"‚úì These insights justify Series B funding requests for real-time forecasting systems\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e54755d",
   "metadata": {},
   "source": [
    "**What this does:**\n",
    "- Extracts `.feature_importances_` from trained Random Forest showing MDI (Mean Decrease in Impurity) scores\n",
    "- Displays ranked table with importance scores, percentages, and visual bars for quick interpretation\n",
    "- Calculates cumulative importance showing how many features capture 80%/90% of predictive power\n",
    "- Creates two-panel visualization: horizontal bar chart (top 10 features) and cumulative curve\n",
    "- Translates top features into business implications with strategic recommendations for each\n",
    "- Provides actionable insights for resource allocation, investment decisions, and operational priorities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6b7157",
   "metadata": {},
   "source": [
    "### Challenge 4: Experiment with New Features and Analyze Feature Importance\n",
    "\n",
    "Your client asks: \"We've seen what features matter now, but what if we engineer additional features? Could we discover new patterns that improve predictions? I want to experiment with new features and see how they compare in the importance rankings.\"\n",
    "\n",
    "**Your Task:** Create 3-5 new experimental features (e.g., squared terms, new time windows, weather combinations), retrain the Random Forest, and analyze how feature importance changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56613534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - create new features and analyze importance changes\n",
    "\n",
    "# Step 1: Create new experimental features\n",
    "# Examples of features you might try:\n",
    "# - Squared/polynomial features: temp_squared, humidity_squared\n",
    "# - New time windows: is_midday, is_late_night\n",
    "# - Weather combinations: temp_humidity_interaction\n",
    "# - Lag features: previous_hour_pattern\n",
    "# - Day type combinations: weekend_hour_interaction\n",
    "\n",
    "print(\"=== EXPERIMENTING WITH NEW FEATURES ===\\n\")\n",
    "\n",
    "# Add your new features to the dataframe\n",
    "df['temp_squared'] = df['temp'] ** 2\n",
    "df['___'] = ___  # Add 2-4 more experimental features\n",
    "df['___'] = ___\n",
    "df['___'] = ___\n",
    "\n",
    "# Create new feature list including original + experimental features\n",
    "experimental_features = feature_columns + ['temp_squared', '___', '___', '___']\n",
    "\n",
    "print(f\"Original features: {len(feature_columns)}\")\n",
    "print(f\"Experimental features: {len(experimental_features)}\")\n",
    "print(f\"New features added: {len(experimental_features) - len(feature_columns)}\")\n",
    "print()\n",
    "\n",
    "# Step 2: Train Random Forest with expanded feature set\n",
    "X_experimental = df[experimental_features]\n",
    "y_experimental = df['count']\n",
    "\n",
    "X_train_exp = X_experimental.iloc[:split_index]\n",
    "X_test_exp = X_experimental.iloc[split_index:]\n",
    "\n",
    "rf_experimental = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_experimental.fit(X_train_exp, y_train)\n",
    "\n",
    "# Step 3: Evaluate performance change\n",
    "test_pred_exp = rf_experimental.predict(X_test_exp)\n",
    "test_r2_exp = r2_score(y_test, test_pred_exp)\n",
    "\n",
    "print(f\"=== PERFORMANCE COMPARISON ===\")\n",
    "print(f\"Baseline model (original features):     R¬≤ = {test_r2_rf:.4f}\")\n",
    "print(f\"Experimental model (expanded features): R¬≤ = {test_r2_exp:.4f}\")\n",
    "print(f\"Performance change:                     {(test_r2_exp - test_r2_rf):.4f} ({((test_r2_exp - test_r2_rf)/test_r2_rf)*100:+.2f}%)\")\n",
    "print()\n",
    "\n",
    "# Step 4: Analyze new feature importance rankings\n",
    "feature_importance_exp = pd.DataFrame({\n",
    "    'feature': experimental_features,\n",
    "    'importance': rf_experimental.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"=== TOP 15 FEATURES (WITH EXPERIMENTAL FEATURES) ===\")\n",
    "for rank, (idx, row) in enumerate(feature_importance_exp.head(15).iterrows(), 1):\n",
    "    is_new = 'üÜï NEW' if row['feature'] not in feature_columns else '      '\n",
    "    bar = '‚ñà' * int(row['importance'] * 100)\n",
    "    print(f\"{rank:<3} {is_new} {row['feature']:<30} {row['importance']:.4f}  {bar}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Step 5: Compare feature importance distributions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Panel 1: Original model top 10\n",
    "top_original = feature_importance.head(10)\n",
    "colors_original = plt.cm.viridis(np.linspace(0.3, 0.9, len(top_original)))\n",
    "axes[0].barh(range(len(top_original)), top_original['importance'], color=colors_original)\n",
    "axes[0].set_yticks(range(len(top_original)))\n",
    "axes[0].set_yticklabels(top_original['feature'])\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].set_xlabel('Importance Score', fontsize=11)\n",
    "axes[0].set_title('Baseline Model - Top 10 Features', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Panel 2: Experimental model top 10\n",
    "top_experimental = feature_importance_exp.head(10)\n",
    "colors_experimental = plt.cm.plasma(np.linspace(0.3, 0.9, len(top_experimental)))\n",
    "axes[1].barh(range(len(top_experimental)), top_experimental['importance'], color=colors_experimental)\n",
    "axes[1].set_yticks(range(len(top_experimental)))\n",
    "axes[1].set_yticklabels(top_experimental['feature'])\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].set_xlabel('Importance Score', fontsize=11)\n",
    "axes[1].set_title('Experimental Model - Top 10 Features', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Step 6: Analyze insights\n",
    "print(\"=== EXPERIMENTAL FEATURE INSIGHTS ===\")\n",
    "# Check if any new features made it to top 10\n",
    "new_features_in_top10 = [f for f in top_experimental['feature'].values[:10] if f not in feature_columns]\n",
    "if new_features_in_top10:\n",
    "    print(f\"‚úì {len(new_features_in_top10)} new feature(s) in top 10: {', '.join(new_features_in_top10)}\")\n",
    "    print(\"  ‚Üí These features captured previously hidden patterns\")\n",
    "else:\n",
    "    print(\"‚úó No new features in top 10\")\n",
    "    print(\"  ‚Üí Original features still dominate, experimental features add marginal value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ffccb2",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üí° <strong>Tip</strong> (click to expand)</summary>\n",
    "\n",
    "\n",
    "Good experimental features to try: `temp_squared = df['temp'] ** 2` (captures non-linear temperature effects), `is_midday = ((df['hour'] >= 11) & (df['hour'] <= 14)).astype(int)` (lunch hour patterns), `temp_humidity_interaction = df['temp'] * df['humidity']` (discomfort index), `hour_squared = df['hour'] ** 2` (non-linear time effects), or `weekend_weather = df['is_weekend'] * df['weather_severity']` (weekend sensitivity to bad weather). After creating features, ensure they're included in `experimental_features = feature_columns + ['new_feature1', 'new_feature2', ...]`. When analyzing importance, look for: (1) Did any new features break into top 10? (2) Did performance improve meaningfully (>1% R¬≤ gain)? (3) Are new features interpretable enough for business use? Sometimes new features improve training accuracy but add complexity without production value. The visualization comparison shows if new features displace old ones or just add marginal value at the bottom of rankings. Business insight: Only keep experimental features that both improve performance AND rank in top 15 - otherwise they add computational cost without strategic benefit.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ec71e1",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ü§´ <strong>Solution</strong> (click to expand)</summary>\n",
    "\n",
    "```python\n",
    "print(\"=== EXPERIMENTING WITH NEW FEATURES ===\\n\")\n",
    "\n",
    "# Step 1: Create experimental features\n",
    "df['temp_squared'] = df['temp'] ** 2  # Non-linear temperature effect\n",
    "df['is_midday'] = ((df['hour'] >= 11) & (df['hour'] <= 14)).astype(int)  # Lunch period\n",
    "df['temp_humidity_interaction'] = df['temp'] * df['humidity']  # Discomfort index\n",
    "df['hour_squared'] = df['hour'] ** 2  # Non-linear time progression\n",
    "df['weekend_weather'] = df['is_weekend'] * df['weather_severity']  # Weekend weather sensitivity\n",
    "\n",
    "# Create expanded feature list\n",
    "experimental_features = feature_columns + [\n",
    "    'temp_squared', 'is_midday', 'temp_humidity_interaction',\n",
    "    'hour_squared', 'weekend_weather'\n",
    "]\n",
    "\n",
    "print(f\"Original features: {len(feature_columns)}\")\n",
    "print(f\"Experimental features: {len(experimental_features)}\")\n",
    "print(f\"New features added: {len(experimental_features) - len(feature_columns)}\")\n",
    "print(f\"\\nNew features: temp_squared, is_midday, temp_humidity_interaction, hour_squared, weekend_weather\")\n",
    "print()\n",
    "\n",
    "# Step 2: Train Random Forest with expanded feature set\n",
    "X_experimental = df[experimental_features]\n",
    "y_experimental = df['count']\n",
    "\n",
    "X_train_exp = X_experimental.iloc[:split_index]\n",
    "X_test_exp = X_experimental.iloc[split_index:]\n",
    "\n",
    "print(\"Training Random Forest with experimental features...\")\n",
    "rf_experimental = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_experimental.fit(X_train_exp, y_train)\n",
    "\n",
    "# Step 3: Evaluate performance change\n",
    "test_pred_exp = rf_experimental.predict(X_test_exp)\n",
    "test_r2_exp = r2_score(y_test, test_pred_exp)\n",
    "test_rmse_exp = np.sqrt(mean_squared_error(y_test, test_pred_exp))\n",
    "\n",
    "print(f\"\\n=== PERFORMANCE COMPARISON ===\")\n",
    "print(f\"Baseline model (17 original features):\")\n",
    "print(f\"  R¬≤ = {test_r2_rf:.4f}, RMSE = {test_rmse_rf:.2f} bikes\")\n",
    "print(f\"\\nExperimental model (22 expanded features):\")\n",
    "print(f\"  R¬≤ = {test_r2_exp:.4f}, RMSE = {test_rmse_exp:.2f} bikes\")\n",
    "print(f\"\\nPerformance change:\")\n",
    "print(f\"  ŒîR¬≤ = {(test_r2_exp - test_r2_rf):+.4f} ({((test_r2_exp - test_r2_rf)/test_r2_rf)*100:+.2f}%)\")\n",
    "print(f\"  ŒîRMSE = {(test_rmse_exp - test_rmse_rf):+.2f} bikes\")\n",
    "print()\n",
    "\n",
    "# Step 4: Analyze new feature importance rankings\n",
    "feature_importance_exp = pd.DataFrame({\n",
    "    'feature': experimental_features,\n",
    "    'importance': rf_experimental.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"=== TOP 15 FEATURES (WITH EXPERIMENTAL FEATURES) ===\")\n",
    "for rank, (idx, row) in enumerate(feature_importance_exp.head(15).iterrows(), 1):\n",
    "    is_new = 'üÜï NEW' if row['feature'] not in feature_columns else '      '\n",
    "    bar = '‚ñà' * int(row['importance'] * 100)\n",
    "    percentage = row['importance'] * 100\n",
    "    print(f\"{rank:<3} {is_new} {row['feature']:<30} {row['importance']:.4f} ({percentage:>5.2f}%)  {bar}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Step 5: Compare feature importance distributions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Panel 1: Original model top 10\n",
    "top_original = feature_importance.head(10)\n",
    "colors_original = plt.cm.viridis(np.linspace(0.3, 0.9, len(top_original)))\n",
    "axes[0].barh(range(len(top_original)), top_original['importance'], color=colors_original)\n",
    "axes[0].set_yticks(range(len(top_original)))\n",
    "axes[0].set_yticklabels(top_original['feature'])\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].set_xlabel('Importance Score', fontsize=11)\n",
    "axes[0].set_title('Baseline Model - Top 10 Features', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Panel 2: Experimental model top 10\n",
    "top_experimental = feature_importance_exp.head(10)\n",
    "colors_experimental = plt.cm.plasma(np.linspace(0.3, 0.9, len(top_experimental)))\n",
    "axes[1].barh(range(len(top_experimental)), top_experimental['importance'], color=colors_experimental)\n",
    "axes[1].set_yticks(range(len(top_experimental)))\n",
    "axes[1].set_yticklabels(top_experimental['feature'])\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].set_xlabel('Importance Score', fontsize=11)\n",
    "axes[1].set_title('Experimental Model - Top 10 Features', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Step 6: Detailed analysis of experimental features\n",
    "print(\"=== EXPERIMENTAL FEATURE INSIGHTS ===\")\n",
    "\n",
    "# Check if any new features made it to top 10\n",
    "new_features_list = ['temp_squared', 'is_midday', 'temp_humidity_interaction',\n",
    "                     'hour_squared', 'weekend_weather']\n",
    "new_features_in_top10 = [f for f in top_experimental['feature'].values[:10] if f in new_features_list]\n",
    "\n",
    "if new_features_in_top10:\n",
    "    print(f\"‚úì {len(new_features_in_top10)} new feature(s) in top 10:\")\n",
    "    for nf in new_features_in_top10:\n",
    "        rank = feature_importance_exp[feature_importance_exp['feature'] == nf].index[0] + 1\n",
    "        importance = feature_importance_exp[feature_importance_exp['feature'] == nf]['importance'].values[0]\n",
    "        print(f\"  ‚Ä¢ {nf}: Rank #{rank} ({importance:.1%} importance)\")\n",
    "    print(\"  ‚Üí These features captured previously hidden patterns!\")\n",
    "else:\n",
    "    print(\"‚úó No new features in top 10\")\n",
    "    print(\"  ‚Üí Original features still dominate\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Individual experimental feature analysis\n",
    "print(\"=== INDIVIDUAL EXPERIMENTAL FEATURE RANKINGS ===\")\n",
    "for exp_feat in new_features_list:\n",
    "    rank = feature_importance_exp[feature_importance_exp['feature'] == exp_feat].index[0] + 1\n",
    "    importance = feature_importance_exp[feature_importance_exp['feature'] == exp_feat]['importance'].values[0]\n",
    "    print(f\"{exp_feat:<30} Rank: #{rank:2d}/22  |  Importance: {importance:.4f} ({importance*100:.2f}%)\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Business recommendation\n",
    "print(\"=== RECOMMENDATION FOR CAPITAL CITY BIKES ===\")\n",
    "if test_r2_exp > test_r2_rf + 0.01:\n",
    "    print(f\"‚úì ADOPT experimental features: {((test_r2_exp - test_r2_rf)/test_r2_rf)*100:+.1f}% improvement justifies added complexity\")\n",
    "    print(f\"‚úì Focus on: {', '.join(new_features_in_top10[:3]) if new_features_in_top10 else 'top-ranked experimental features'}\")\n",
    "elif test_r2_exp > test_r2_rf:\n",
    "    print(f\"~ MARGINAL improvement ({((test_r2_exp - test_r2_rf)/test_r2_rf)*100:+.1f}%): Consider if complexity is worth small gain\")\n",
    "    print(f\"~ New features add minimal predictive value but increase computation\")\n",
    "else:\n",
    "    print(f\"‚úó NO improvement: Keep baseline model, experimental features don't help\")\n",
    "    print(f\"‚úó Original feature engineering was already optimal for this problem\")\n",
    "\n",
    "print()\n",
    "print(f\"Key insight: {'Expanded feature engineering successful!' if test_r2_exp > test_r2_rf + 0.01 else 'Original features sufficient - diminishing returns from additional engineering'}\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d16098",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af59add2",
   "metadata": {},
   "source": [
    "## Step 5: Validate Random Forest with Time Series Cross-Validation\n",
    "\n",
    "Let's apply TimeSeriesSplit to evaluate Random Forest performance across multiple temporal windows, ensuring our model generalizes reliably to future periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b18eacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import time series cross-validation tools\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"=== TIME SERIES CROSS-VALIDATION FOR RANDOM FOREST ===\\n\")\n",
    "\n",
    "# Create TimeSeriesSplit with 5 folds (expanding window)\n",
    "# Each fold trains on all past data and tests on the next time period\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "print(\"--- Why TimeSeriesSplit for Random Forests? ---\")\n",
    "print(\"‚ö† CRITICAL PRINCIPLE: Time series data requires chronological validation\")\n",
    "print(\"‚Ä¢ Random Forest's bootstrap sampling randomizes WITHIN training set\")\n",
    "print(\"‚Ä¢ Bootstrap does NOT protect against training on future to predict past\")\n",
    "print(\"‚Ä¢ Without chronological splits = DATA LEAKAGE = invalid performance estimates\")\n",
    "print(\"‚Ä¢ TimeSeriesSplit ensures we ALWAYS train on past, validate on future\")\n",
    "print()\n",
    "\n",
    "# Show fold structure with dates\n",
    "print(\"--- Time Series Cross-Validation Fold Structure ---\")\n",
    "print(\"Expanding window approach: each fold adds more training data\\n\")\n",
    "\n",
    "for fold_num, (train_idx, test_idx) in enumerate(tscv.split(X), 1):\n",
    "    train_dates = df.iloc[train_idx]['datetime']\n",
    "    test_dates = df.iloc[test_idx]['datetime']\n",
    "\n",
    "    print(f\"Fold {fold_num}:\")\n",
    "    print(f\"  Training: {len(train_idx):,} obs | {train_dates.min().date()} to {train_dates.max().date()}\")\n",
    "    print(f\"  Testing:  {len(test_idx):,} obs | {test_dates.min().date()} to {test_dates.max().date()}\")\n",
    "    print()\n",
    "\n",
    "# Train Random Forest with same parameters from Step 3\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Run cross-validation using TimeSeriesSplit\n",
    "print(\"--- Running Cross-Validation (this may take 1-2 minutes) ---\")\n",
    "cv_scores = cross_val_score(rf_model, X, y, cv=tscv, scoring='r2', n_jobs=-1)\n",
    "\n",
    "print(\"=== RANDOM FOREST CROSS-VALIDATION RESULTS ===\\n\")\n",
    "\n",
    "# Display fold-by-fold performance\n",
    "for i, score in enumerate(cv_scores, 1):\n",
    "    print(f\"Fold {i}: R¬≤ = {score:.4f}\")\n",
    "\n",
    "# Calculate summary statistics\n",
    "cv_mean = cv_scores.mean()\n",
    "cv_std = cv_scores.std()\n",
    "cv_min = cv_scores.min()\n",
    "cv_max = cv_scores.max()\n",
    "\n",
    "print(f\"\\n--- Performance Summary ---\")\n",
    "print(f\"Mean R¬≤:      {cv_mean:.4f}\")\n",
    "print(f\"Std Dev:      {cv_std:.4f}\")\n",
    "print(f\"Range:        {cv_min:.4f} to {cv_max:.4f}\")\n",
    "print(f\"95% CI:       {cv_mean - 1.96*cv_std:.4f} to {cv_mean + 1.96*cv_std:.4f}\")\n",
    "print()\n",
    "\n",
    "# Interpret consistency\n",
    "if cv_std < 0.03:\n",
    "    print(\"‚úì EXCELLENT CONSISTENCY:\")\n",
    "    print(\"  ‚Ä¢ Very low variability (std < 0.03)\")\n",
    "    print(\"  ‚Ä¢ Model performs reliably across different time periods\")\n",
    "    print(\"  ‚Ä¢ Suitable for production deployment with confidence\")\n",
    "elif cv_std < 0.06:\n",
    "    print(\"‚úì GOOD CONSISTENCY:\")\n",
    "    print(\"  ‚Ä¢ Moderate variability (std < 0.06)\")\n",
    "    print(\"  ‚Ä¢ Model performs well but some temporal variation exists\")\n",
    "    print(\"  ‚Ä¢ Acceptable for production with monitoring\")\n",
    "else:\n",
    "    print(\"‚ö† HIGH VARIABILITY:\")\n",
    "    print(\"  ‚Ä¢ Substantial performance differences across time periods\")\n",
    "    print(\"  ‚Ä¢ Investigate causes: seasonality, data drift, feature instability\")\n",
    "    print(\"  ‚Ä¢ Consider temporal feature engineering or separate seasonal models\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Visualize cross-validation performance\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Panel 1: Fold performance with confidence interval\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, len(cv_scores) + 1), cv_scores, 'o-', linewidth=2,\n",
    "         markersize=10, color='darkgreen', label='Fold R¬≤')\n",
    "plt.axhline(y=cv_mean, color='blue', linestyle='--', linewidth=2, label=f'Mean R¬≤ = {cv_mean:.4f}')\n",
    "plt.axhline(y=cv_mean + cv_std, color='red', linestyle=':', linewidth=1.5, label='¬±1 Std Dev')\n",
    "plt.axhline(y=cv_mean - cv_std, color='red', linestyle=':', linewidth=1.5)\n",
    "plt.xlabel('Fold Number', fontsize=11)\n",
    "plt.ylabel('R¬≤ Score', fontsize=11)\n",
    "plt.title('Random Forest Cross-Validation Performance', fontsize=12, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "# Panel 2: Performance distribution\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot([cv_scores], labels=['Random Forest'], widths=0.5)\n",
    "plt.ylabel('R¬≤ Score', fontsize=11)\n",
    "plt.title('Performance Distribution Across Folds', fontsize=12, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=== BUSINESS INTERPRETATION FOR CAPITAL CITY BIKES ===\")\n",
    "print(f\"‚úì Expected production performance: {cv_mean:.1%} R¬≤ (¬±{cv_std:.1%})\")\n",
    "print(f\"‚úì Worst-case scenario: {cv_min:.1%} R¬≤ (prepare for this in capacity planning)\")\n",
    "print(f\"‚úì Best-case scenario: {cv_max:.1%} R¬≤ (demonstrates model potential)\")\n",
    "print(f\"‚úì Model reliability: {'High' if cv_std < 0.03 else 'Moderate' if cv_std < 0.06 else 'Variable'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9141684",
   "metadata": {},
   "source": [
    "**What this does:**\n",
    "- Creates TimeSeriesSplit with 5 folds using expanding window approach (each fold trains on more historical data)\n",
    "- Explicitly explains why bootstrap sampling in Random Forest doesn't eliminate need for chronological validation\n",
    "- Displays fold structure with actual dates showing train/test periods for transparency\n",
    "- Runs cross_val_score() with TimeSeriesSplit to get robust performance estimates across time\n",
    "- Calculates mean, standard deviation, and 95% confidence interval for expected production performance\n",
    "- Visualizes fold-by-fold performance with confidence bands and distribution boxplot\n",
    "- Provides business-focused interpretation of consistency and worst/best-case scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff0dcbb",
   "metadata": {},
   "source": [
    "### Challenge 5: Compare Cross-Validation Stability Across Models\n",
    "\n",
    "Your client asks: \"How does Random Forest's cross-validation stability compare to a single Decision Tree? Does the ensemble really provide more reliable predictions across different time periods?\"\n",
    "\n",
    "**Your Task:** Run the same TimeSeriesSplit cross-validation on both an unlimited Decision Tree and a Random Forest, then compare their consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14ed23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - compare CV stability between Decision Tree and Random Forest\n",
    "\n",
    "# Model 1: Single Decision Tree (unlimited depth)\n",
    "tree_model = DecisionTreeRegressor(random_state=42)\n",
    "cv_scores_tree = cross_val_score(_____, X, y, cv=_____, scoring='r2', n_jobs=-1)\n",
    "\n",
    "# Model 2: Random Forest (100 trees)\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "cv_scores_rf = cross_val_score(_____, X, y, cv=_____, scoring='r2', n_jobs=-1)\n",
    "\n",
    "# Calculate statistics for both models\n",
    "tree_mean = cv_scores_tree.mean()\n",
    "tree_std = cv_scores_tree.std()\n",
    "rf_mean = cv_scores_rf.mean()\n",
    "rf_std = cv_scores_rf.std()\n",
    "\n",
    "print(\"=== MODEL STABILITY COMPARISON ===\")\n",
    "print(f\"\\nDecision Tree (Unlimited):\")\n",
    "print(f\"  Mean R¬≤: {tree_mean:.4f}\")\n",
    "print(f\"  Std Dev: {tree_std:.4f}\")\n",
    "print(f\"  Range:   {cv_scores_tree.min():.4f} to {cv_scores_tree.max():.4f}\")\n",
    "\n",
    "print(f\"\\nRandom Forest (100 trees):\")\n",
    "print(f\"  Mean R¬≤: {rf_mean:.4f}\")\n",
    "print(f\"  Std Dev: {rf_std:.4f}\")\n",
    "print(f\"  Range:   {cv_scores_rf.min():.4f} to {cv_scores_rf.max():.4f}\")\n",
    "\n",
    "# Visualize comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Side-by-side fold performance\n",
    "plt.subplot(1, 2, 1)\n",
    "x_pos = np.arange(1, len(cv_scores_tree) + 1)\n",
    "width = 0.35\n",
    "plt.bar(x_pos - width/2, cv_scores_tree, width, label='Decision Tree',\n",
    "        color='orange', alpha=0.7)\n",
    "plt.bar(x_pos + width/2, cv_scores_rf, width, label='Random Forest',\n",
    "        color='darkgreen', alpha=0.7)\n",
    "plt.xlabel('Fold Number', fontsize=11)\n",
    "plt.ylabel('R¬≤ Score', fontsize=11)\n",
    "plt.title('Fold-by-Fold Performance Comparison', fontsize=12, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Box plot comparison\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot([cv_scores_tree, cv_scores_rf],\n",
    "            labels=['Decision Tree', 'Random Forest'],\n",
    "            widths=0.5)\n",
    "plt.ylabel('R¬≤ Score', fontsize=11)\n",
    "plt.title('Performance Distribution Comparison', fontsize=12, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Stability analysis\n",
    "stability_improvement = (tree_std - rf_std) / tree_std * 100\n",
    "performance_improvement = (rf_mean - tree_mean) / tree_mean * 100\n",
    "\n",
    "print(f\"\\n=== ENSEMBLE ADVANTAGES ===\")\n",
    "print(f\"Performance improvement: {performance_improvement:+.1f}%\")\n",
    "print(f\"Stability improvement:   {stability_improvement:+.1f}% (lower std dev)\")\n",
    "print(f\"\\nConclusion: Random Forest provides {'more' if rf_std < tree_std else 'similar'} consistent predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7daf3f51",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üí° <strong>Tip</strong> (click to expand)</summary>\n",
    "\n",
    "\n",
    "Use the same `tscv = TimeSeriesSplit(n_splits=5)` object for both models to ensure identical fold splits for fair comparison. Call `cross_val_score(model, X, y, cv=tscv, scoring='r2', n_jobs=-1)` for each model - the function returns an array with one score per fold. Calculate standard deviation using `.std()` - lower std means more consistent performance across time periods. Create comparison visualizations using bar charts (fold-by-fold) and box plots (distribution) to show both mean performance and variability differences. The Decision Tree typically shows higher variability (large std dev) because each fold produces a completely different tree structure based on that specific time period's data, while Random Forest averages 100 trees which smooths out temporal variations. Business insight: Lower variability means more predictable production performance - executives prefer models that consistently deliver promised accuracy rather than models that sometimes excel but sometimes fail. If Random Forest shows 30-50% lower standard deviation, that's strong evidence for ensemble reliability worth communicating to stakeholders.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabbf985",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ü§´ <strong>Solution</strong> (click to expand)</summary>\n",
    "\n",
    "```python\n",
    "# Model 1: Single Decision Tree (unlimited depth)\n",
    "tree_model = DecisionTreeRegressor(random_state=42)\n",
    "cv_scores_tree = cross_val_score(tree_model, X, y, cv=tscv, scoring='r2', n_jobs=-1)\n",
    "\n",
    "# Model 2: Random Forest (100 trees)\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "cv_scores_rf = cross_val_score(rf_model, X, y, cv=tscv, scoring='r2', n_jobs=-1)\n",
    "\n",
    "# Calculate statistics for both models\n",
    "tree_mean = cv_scores_tree.mean()\n",
    "tree_std = cv_scores_tree.std()\n",
    "rf_mean = cv_scores_rf.mean()\n",
    "rf_std = cv_scores_rf.std()\n",
    "\n",
    "print(\"=== MODEL STABILITY COMPARISON ===\")\n",
    "print(f\"\\nDecision Tree (Unlimited):\")\n",
    "print(f\"  Mean R¬≤: {tree_mean:.4f}\")\n",
    "print(f\"  Std Dev: {tree_std:.4f}\")\n",
    "print(f\"  Range:   {cv_scores_tree.min():.4f} to {cv_scores_tree.max():.4f}\")\n",
    "print(f\"  Coefficient of Variation: {(tree_std/tree_mean)*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nRandom Forest (100 trees):\")\n",
    "print(f\"  Mean R¬≤: {rf_mean:.4f}\")\n",
    "print(f\"  Std Dev: {rf_std:.4f}\")\n",
    "print(f\"  Range:   {cv_scores_rf.min():.4f} to {cv_scores_rf.max():.4f}\")\n",
    "print(f\"  Coefficient of Variation: {(rf_std/rf_mean)*100:.1f}%\")\n",
    "\n",
    "# Visualize comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Side-by-side fold performance\n",
    "plt.subplot(1, 2, 1)\n",
    "x_pos = np.arange(1, len(cv_scores_tree) + 1)\n",
    "width = 0.35\n",
    "plt.bar(x_pos - width/2, cv_scores_tree, width, label='Decision Tree',\n",
    "        color='orange', alpha=0.7)\n",
    "plt.bar(x_pos + width/2, cv_scores_rf, width, label='Random Forest',\n",
    "        color='darkgreen', alpha=0.7)\n",
    "plt.xlabel('Fold Number', fontsize=11)\n",
    "plt.ylabel('R¬≤ Score', fontsize=11)\n",
    "plt.title('Fold-by-Fold Performance Comparison', fontsize=12, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "# Box plot comparison\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot([cv_scores_tree, cv_scores_rf],\n",
    "            labels=['Decision Tree', 'Random Forest'],\n",
    "            widths=0.5)\n",
    "plt.ylabel('R¬≤ Score', fontsize=11)\n",
    "plt.title('Performance Distribution Comparison', fontsize=12, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Stability analysis\n",
    "stability_improvement = (tree_std - rf_std) / tree_std * 100\n",
    "performance_improvement = (rf_mean - tree_mean) / tree_mean * 100\n",
    "\n",
    "print(f\"\\n=== ENSEMBLE ADVANTAGES ===\")\n",
    "print(f\"Performance improvement: {performance_improvement:+.1f}%\")\n",
    "print(f\"Stability improvement:   {stability_improvement:+.1f}% (reduced variability)\")\n",
    "print()\n",
    "\n",
    "print(\"=== KEY INSIGHTS FOR CAPITAL CITY BIKES ===\")\n",
    "print(f\"‚úì Random Forest shows {stability_improvement:.0f}% more consistent performance across time\")\n",
    "print(f\"‚úì Single trees are {'highly' if tree_std > 0.10 else 'moderately'} unstable - performance varies dramatically by period\")\n",
    "print(f\"‚úì Ensemble averaging smooths temporal variation ‚Üí reliable production forecasts\")\n",
    "print(f\"‚úì Lower variability = predictable SLA commitments to executives and investors\")\n",
    "print()\n",
    "\n",
    "print(\"RECOMMENDATION:\")\n",
    "if rf_std < tree_std and rf_mean > tree_mean:\n",
    "    print(\"‚úì Random Forest dominates: Higher mean performance AND lower variability\")\n",
    "    print(\"‚úì Deploy Random Forest for production - delivers consistent, reliable forecasts\")\n",
    "elif rf_mean > tree_mean:\n",
    "    print(\"‚úì Random Forest provides better average performance\")\n",
    "    print(\"‚úì Stability similar to single tree, but higher accuracy justifies deployment\")\n",
    "else:\n",
    "    print(\"‚ö† Unexpected result - investigate data characteristics and model configuration\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f52ba2d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd6514b",
   "metadata": {},
   "source": [
    "## Summary: Production-Grade Tree-Based Ensemble Modeling for Competitive Advantage\n",
    "\n",
    "**What We've Accomplished:**\n",
    "- **Engineered advanced features** including binary indicators (is_rush_hour, is_weekend), categorical encodings (temp_category, weather_severity), and interaction terms (temp√óhour, workingday√óhour) exposing 17 features designed for tree-based pattern discovery\n",
    "- **Implemented decision trees** demonstrating how unlimited depth leads to severe overfitting (training R¬≤ 99%, test R¬≤ 45%), revealing why single trees struggle with generalization\n",
    "- **Deployed Random Forest ensembles** achieving test R¬≤ ‚âà85% through bootstrap aggregation and feature randomness, dramatically reducing overfitting gap from 54 points (single tree) to ~13 points (ensemble)\n",
    "- **Analyzed feature importance** using MDI and permutation methods, identifying hour, temperature, and workingday interactions as dominant drivers (top 3 features capture ~80% of predictive power)\n",
    "\n",
    "**Key Technical Skills Mastered:**\n",
    "- **Feature engineering**: Binary encoding (`.astype(int)`), categorical binning (`pd.cut()`), interaction terms (element-wise multiplication), temporal extraction (`.dt.hour`, `.dt.dayofweek`)\n",
    "- **Decision trees**: DecisionTreeRegressor implementation, tree structure analysis (`.get_depth()`, `.get_n_leaves()`), visualization (`plot_tree()`), overfitting detection (train-test gap calculation)\n",
    "- **Random Forest ensembles**: RandomForestRegressor with n_estimators, max_features='sqrt', bootstrap=True; accessing individual estimators (`.estimators_[i]`), ensemble diversity demonstration\n",
    "- **Feature importance**: MDI extraction (`.feature_importances_`), permutation importance (`permutation_importance()`), cumulative importance analysis, business translation of rankings\n",
    "\n",
    "**Next Steps:**\n",
    "In Module 5, you'll advance to model evaluation and deployment strategies, mastering performance metrics beyond R¬≤ (MAE, MAPE for business reporting), residual analysis for error pattern diagnosis, learning curves for dataset size sufficiency, and production deployment considerations including prediction latency, model versioning, and monitoring strategies.\n",
    "\n",
    "Your Random Forest model transforms Capital City Bikes from linear constraints to non-linear intelligence, achieving 85%+ accuracy that positions them competitively against sophisticated rivals. You've demonstrated the advanced ensemble modeling capabilities, interpretable feature importance analysis, and systematic optimization workflows that distinguish senior ML engineers capable of delivering investor-grade predictive systems!"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
