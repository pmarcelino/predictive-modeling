{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c790caba",
   "metadata": {},
   "source": [
    "# Lecture 9: Tree-Based Models - Programming Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5047d10c",
   "metadata": {},
   "source": [
    "## Introduction: Advancing Beyond Linear Constraints with Tree-Based Intelligence\n",
    "\n",
    "Welcome back to your Capital City Bikes consulting engagement! Eight months after deploying your linear regression models, the board has approached you with competitive intelligence that demands immediate action. Three rival bike-sharing companies have entered your market with sophisticated ML systems achieving demonstrably better predictions during complex scenarios like weather transitions and seasonal shifts.\n",
    "\n",
    "The CEO's message is direct: \"Our linear models served us well for Series A funding, but competitors are now outperforming us with advanced ensemble methods. The Series B investors expect state-of-the-art predictive capabilities. We need you to implement tree-based models that capture the non-linear patterns and feature interactions our linear approach is missing.\"\n",
    "\n",
    "Think of tree-based modeling as graduating from basic algebra to calculus. While linear regression assumes constant relationships across all conditions, decision trees and random forests discover conditional patterns: \"If temperature is warm AND humidity is low AND it's a weekday, expect high commuter demand. But if temperature is warm AND humidity is high, expect 30% lower demand regardless of day type.\" These conditional rules mirror how experienced operations managers actually think about demand.\n",
    "\n",
    "Your task: engineer sophisticated features that expose non-linear patterns, implement decision trees to understand their interpretable rule-based logic, deploy Random Forest ensembles that achieve production-grade accuracy, analyze feature importance to guide strategic investments, and optimize hyperparameters to maximize competitive advantage. Every technique must demonstrate measurable improvements over your linear baseline to justify the algorithmic complexity to stakeholders.\n",
    "\n",
    "> **üöÄ Interactive Learning Alert**\n",
    ">\n",
    "> This is an advanced hands-on tutorial with production-grade ensemble modeling challenges. For the best experience:\n",
    ">\n",
    "> - **Click \"Open in Colab\"** at the bottom to run code interactively\n",
    "> - **Execute each code cell** by pressing **Shift + Enter**\n",
    "> - **Complete the challenges** to practice your tree-based modeling skills\n",
    "> - **Think like a senior consultant** - algorithm choice impacts funding discussions and competitive positioning\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d837283",
   "metadata": {},
   "source": [
    "## Step 1: Feature Engineering for Non-Linear Pattern Discovery\n",
    "\n",
    "Let's engineer features that expose the non-linear relationships and interaction effects that tree-based models can exploit but linear regression cannot capture effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2eb05cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries for data manipulation, modeling, and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load Washington D.C. bike-sharing dataset\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/pmarcelino/predictive-modeling/main/datasets/dataset.csv\")\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "# Sort chronologically to maintain temporal integrity for time series modeling\n",
    "df = df.sort_values('datetime').reset_index(drop=True)\n",
    "\n",
    "print(\"=== FEATURE ENGINEERING FOR TREE-BASED MODELS ===\")\n",
    "print(f\"Dataset: {len(df):,} hourly observations\")\n",
    "print(f\"Time range: {df['datetime'].min()} to {df['datetime'].max()}\\n\")\n",
    "\n",
    "# Existing features in dataset\n",
    "print(\"Original features:\")\n",
    "print(df.columns.tolist())\n",
    "print()\n",
    "\n",
    "# Extract temporal features that capture demand cycles\n",
    "df['hour'] = df['datetime'].dt.hour\n",
    "df['dayofweek'] = df['datetime'].dt.dayofweek\n",
    "df['month'] = df['datetime'].dt.month\n",
    "df['year'] = df['datetime'].dt.year\n",
    "\n",
    "# Create binary features for operational planning segments\n",
    "# Binary encoding converts categorical conditions into 0/1 indicators that\n",
    "# trees can use for clean threshold-based splitting decisions\n",
    "df['is_rush_hour'] = ((df['hour'] >= 7) & (df['hour'] <= 9) |\n",
    "                        (df['hour'] >= 17) & (df['hour'] <= 19)).astype(int)\n",
    "# Rush hours (7-9am, 5-7pm) represent peak commuter demand periods\n",
    "\n",
    "df['is_weekend'] = (df['dayofweek'] >= 5).astype(int)\n",
    "# Weekend indicator captures leisure vs. commuter demand patterns\n",
    "\n",
    "df['is_night'] = ((df['hour'] >= 22) | (df['hour'] <= 5)).astype(int)\n",
    "# Night hours (10pm-5am) represent low-demand maintenance windows\n",
    "\n",
    "# Weather condition severity encoding\n",
    "# Map weather codes to interpretable severity levels for better business understanding\n",
    "df['weather_severity'] = df['weather'].map({1: 0, 2: 1, 3: 2, 4: 3})\n",
    "# 0=clear, 1=cloudy, 2=light_rain, 3=heavy_rain/snow\n",
    "\n",
    "# Temperature-based categorical features for threshold effects\n",
    "# Cut temperature into bins representing operational planning segments:\n",
    "# Cold (<10¬∞C), Cool (10-20¬∞C), Warm (20-30¬∞C), Hot (>30¬∞C)\n",
    "df['temp_category'] = pd.cut(df['temp'], bins=[-np.inf, 10, 20, 30, np.inf],\n",
    "                               labels=['cold', 'cool', 'warm', 'hot'])\n",
    "\n",
    "# Humidity-based categorical features\n",
    "# High humidity (>70%) significantly reduces cycling comfort\n",
    "df['humidity_category'] = pd.cut(df['humidity'], bins=[-np.inf, 40, 70, np.inf],\n",
    "                                   labels=['dry', 'moderate', 'humid'])\n",
    "\n",
    "# Interaction features that capture combined effects\n",
    "# Temperature √ó Hour interaction: warm mornings differ from warm evenings in demand patterns\n",
    "df['temp_hour_interaction'] = df['temp'] * df['hour']\n",
    "\n",
    "# Working day √ó Hour: commuter patterns differ dramatically between working days and weekends\n",
    "df['workingday_hour'] = df['workingday'] * df['hour']\n",
    "\n",
    "# Season-Weather interaction: rain in summer affects demand differently than rain in winter\n",
    "df['season_weather'] = df['season'] * df['weather_severity']\n",
    "\n",
    "print(\"=== ENGINEERED FEATURES ===\")\n",
    "print(\"Temporal features: hour, dayofweek, month, year\")\n",
    "print(\"Binary indicators: is_rush_hour, is_weekend, is_night\")\n",
    "print(\"Categorical encodings: weather_severity, temp_category, humidity_category\")\n",
    "print(\"Interaction features: temp_hour_interaction, workingday_hour, season_weather\")\n",
    "print()\n",
    "\n",
    "# Prepare feature matrix for tree-based modeling\n",
    "# Note: Tree-based models can handle categorical variables, but we'll use\n",
    "# numerical encoding for consistency with scikit-learn's requirements\n",
    "feature_columns = [\n",
    "    # Weather features\n",
    "    'temp', 'atemp', 'humidity', 'windspeed', 'weather_severity',\n",
    "    # Temporal features\n",
    "    'hour', 'dayofweek', 'month', 'season',\n",
    "    # Binary indicators\n",
    "    'workingday', 'holiday', 'is_rush_hour', 'is_weekend', 'is_night',\n",
    "    # Interaction features\n",
    "    'temp_hour_interaction', 'workingday_hour', 'season_weather'\n",
    "]\n",
    "\n",
    "X = df[feature_columns]\n",
    "y = df['count']\n",
    "\n",
    "print(f\"Feature matrix: {X.shape[0]} observations √ó {X.shape[1]} features\")\n",
    "print(f\"Target variable: count (hourly bike rentals)\")\n",
    "print()\n",
    "\n",
    "# Display feature statistics for business understanding\n",
    "print(\"=== FEATURE STATISTICS (Business Intelligence) ===\")\n",
    "print(f\"Rush hour observations: {df['is_rush_hour'].sum():,} ({df['is_rush_hour'].mean()*100:.1f}%)\")\n",
    "print(f\"Weekend observations: {df['is_weekend'].sum():,} ({df['is_weekend'].mean()*100:.1f}%)\")\n",
    "print(f\"Night observations: {df['is_night'].sum():,} ({df['is_night'].mean()*100:.1f}%)\")\n",
    "print()\n",
    "\n",
    "# Show demand differences across key segments for operational insights\n",
    "print(\"=== DEMAND PATTERNS BY SEGMENT ===\")\n",
    "print(f\"Rush hour demand: {df[df['is_rush_hour']==1]['count'].mean():.0f} bikes/hour\")\n",
    "print(f\"Non-rush hour demand: {df[df['is_rush_hour']==0]['count'].mean():.0f} bikes/hour\")\n",
    "print(f\"Weekend demand: {df[df['is_weekend']==1]['count'].mean():.0f} bikes/hour\")\n",
    "print(f\"Weekday demand: {df[df['is_weekend']==0]['count'].mean():.0f} bikes/hour\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26074836",
   "metadata": {},
   "source": [
    "**What this does:**\n",
    "- Loads Washington D.C. bike-sharing data and sorts chronologically for time series integrity\n",
    "- Engineers temporal features (hour, dayofweek, month) that capture cyclical demand patterns\n",
    "- Creates binary indicators (is_rush_hour, is_weekend, is_night) for operational segments\n",
    "- Builds interaction features (temp√óhour, workingday√óhour) that expose non-linear effects\n",
    "- Categorizes continuous variables (temp_category, humidity_category) for threshold discovery\n",
    "- Prepares 17-feature matrix designed specifically for tree-based pattern recognition\n",
    "- Displays segment statistics showing dramatic demand variations (e.g., rush hour vs. night)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348da220",
   "metadata": {},
   "source": [
    "### Challenge 1: Analyze Feature Distributions and Relationships\n",
    "\n",
    "Your client asks: \"Which feature combinations show the strongest demand differences? Can you identify operational segments we should prioritize?\" Explore feature interactions and segment analysis.\n",
    "\n",
    "**Your Task:** Create visualizations showing demand patterns across different feature combinations (e.g., rush_hour + working_day, temperature + weather severity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adac0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - analyze feature distributions and demand patterns\n",
    "\n",
    "# Example 1: Rush hour + working day combination\n",
    "segment_analysis = df.groupby(['is_rush_hour', 'workingday'])['count'].agg(['mean', 'count'])\n",
    "print(\"=== RUSH HOUR √ó WORKING DAY ANALYSIS ===\")\n",
    "print(segment_analysis)\n",
    "\n",
    "# Example 2: Create a heatmap showing demand by hour and day of week\n",
    "hourly_daily = df.pivot_table(values='count', index='___', columns='___', aggfunc='mean')\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(hourly_daily, cmap='YlOrRd', fmt='.0f', cbar_kws={'label': 'Average Demand'})\n",
    "plt.title('___')\n",
    "plt.xlabel('___')\n",
    "plt.ylabel('___')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Example 3: Visualize temperature √ó weather severity interaction\n",
    "# Create scatter plot or box plots showing how demand varies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fe4a9c",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üí° <strong>Tip</strong> (click to expand)</summary>\n",
    "\n",
    "\n",
    "Start with `.groupby(['is_rush_hour', 'workingday'])['count'].agg(['mean', 'count', 'std'])` to see how demand varies across combinations. For the heatmap, use `df.pivot_table(values='count', index='hour', columns='dayofweek', aggfunc='mean')` which creates a matrix showing average demand for each hour-day combination. Set `cmap='YlOrRd'` for a heat-based color scheme that makes patterns visually obvious. For temperature √ó weather interactions, consider using `sns.boxplot(x='temp_category', y='count', hue='weather_severity', data=df)` to show distributions. Look for segments with 2-3x demand differences - these represent high-value operational optimization opportunities. The heatmap will clearly show morning/evening rush hour peaks on weekdays versus flatter weekend patterns. Business insight: rush hour + working day combinations might show 300+ bikes/hour while night + weekend shows <50 bikes/hour, revealing where fleet positioning matters most.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06c6c12",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ü§´ <strong>Solution</strong> (click to expand)</summary>\n",
    "\n",
    "```python\n",
    "# Example 1: Rush hour + working day combination\n",
    "segment_analysis = df.groupby(['is_rush_hour', 'workingday'])['count'].agg(['mean', 'count', 'std'])\n",
    "print(\"=== RUSH HOUR √ó WORKING DAY ANALYSIS ===\")\n",
    "print(segment_analysis.round(1))\n",
    "print()\n",
    "\n",
    "# Example 2: Heatmap showing demand by hour and day of week\n",
    "hourly_daily = df.pivot_table(values='count', index='hour', columns='dayofweek', aggfunc='mean')\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(hourly_daily, cmap='YlOrRd', annot=True, fmt='.0f', cbar_kws={'label': 'Average Demand (bikes/hour)'})\n",
    "plt.title('Demand Heatmap: Hour √ó Day of Week', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Day of Week (0=Mon, 6=Sun)', fontsize=11)\n",
    "plt.ylabel('Hour of Day', fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Example 3: Temperature √ó Weather severity interaction\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='temp_category', y='count', hue='weather_severity', data=df)\n",
    "plt.title('Demand by Temperature Category and Weather Severity', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Temperature Category', fontsize=11)\n",
    "plt.ylabel('Hourly Demand (bikes)', fontsize=11)\n",
    "plt.legend(title='Weather Severity', labels=['Clear', 'Cloudy', 'Light Rain', 'Heavy Rain'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=== KEY INSIGHTS FOR CAPITAL CITY BIKES ===\")\n",
    "print(\"‚úì Rush hour + working day: Highest demand segment (optimize fleet positioning)\")\n",
    "print(\"‚úì Heatmap reveals: Strong morning (7-9am) and evening (5-7pm) peaks on weekdays\")\n",
    "print(\"‚úì Temperature √ó Weather: Warm+clear weather shows 3x demand vs. cold+rainy conditions\")\n",
    "print(\"‚úì Operational priority: Focus dynamic repositioning on weekday rush hours\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5c9694",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df62304",
   "metadata": {},
   "source": [
    "## Step 2: Implement Decision Tree Regressor\n",
    "\n",
    "Let's implement a decision tree to capture non-linear patterns through interpretable if-then rules that linear regression cannot represent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb315aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tree-based modeling tools from scikit-learn\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Already have X and y from Step 1 feature engineering\n",
    "print(\"=== DECISION TREE IMPLEMENTATION ===\\n\")\n",
    "\n",
    "# Create chronological train-test split (80/20) for honest evaluation\n",
    "# Time series data requires chronological splitting to prevent temporal leakage\n",
    "split_index = int(len(df) * 0.8)\n",
    "X_train = X.iloc[:split_index]\n",
    "X_test = X.iloc[split_index:]\n",
    "y_train = y.iloc[:split_index]\n",
    "y_test = y.iloc[split_index:]\n",
    "\n",
    "print(f\"Training set: {len(X_train):,} observations ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"Testing set:  {len(X_test):,} observations ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "print(f\"Training period: {df.iloc[:split_index]['datetime'].min()} to {df.iloc[split_index-1]['datetime'].max()}\")\n",
    "print(f\"Testing period:  {df.iloc[split_index]['datetime'].min()} to {df.iloc[-1]['datetime'].max()}\")\n",
    "print()\n",
    "\n",
    "# Decision Tree with unlimited depth (demonstrating overfitting potential)\n",
    "print(\"--- Training Decision Tree (Unlimited Depth) ---\")\n",
    "# DecisionTreeRegressor creates a tree that recursively partitions feature space\n",
    "# to minimize mean squared error within each region (leaf node)\n",
    "tree_unlimited = DecisionTreeRegressor(random_state=42)\n",
    "# No max_depth specified = tree grows until leaves are pure or contain min_samples_split\n",
    "tree_unlimited.fit(X_train, y_train)\n",
    "\n",
    "# Examine tree structure to understand model complexity\n",
    "print(f\"Tree depth: {tree_unlimited.get_depth()}\")\n",
    "print(f\"Number of leaves: {tree_unlimited.get_n_leaves()}\")\n",
    "print(f\"Total nodes: {tree_unlimited.tree_.node_count}\")\n",
    "print()\n",
    "\n",
    "# Generate predictions on both training and testing sets\n",
    "train_pred_unlimited = tree_unlimited.predict(X_train)\n",
    "test_pred_unlimited = tree_unlimited.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "train_r2_unlimited = r2_score(y_train, train_pred_unlimited)\n",
    "test_r2_unlimited = r2_score(y_test, test_pred_unlimited)\n",
    "train_rmse_unlimited = np.sqrt(mean_squared_error(y_train, train_pred_unlimited))\n",
    "test_rmse_unlimited = np.sqrt(mean_squared_error(y_test, test_pred_unlimited))\n",
    "\n",
    "print(\"=== DECISION TREE PERFORMANCE (Unlimited Depth) ===\")\n",
    "print(f\"Training:  R¬≤ = {train_r2_unlimited:.4f}, RMSE = {train_rmse_unlimited:.2f} bikes\")\n",
    "print(f\"Testing:   R¬≤ = {test_r2_unlimited:.4f}, RMSE = {test_rmse_unlimited:.2f} bikes\")\n",
    "print(f\"Overfit gap: {train_r2_unlimited - test_r2_unlimited:.4f}\")\n",
    "print()\n",
    "\n",
    "if (train_r2_unlimited - test_r2_unlimited) > 0.30:\n",
    "    print(\"‚ö† SEVERE OVERFITTING DETECTED:\")\n",
    "    print(f\"  ‚Ä¢ Training R¬≤ near-perfect ({train_r2_unlimited:.1%}) but testing R¬≤ only {test_r2_unlimited:.1%}\")\n",
    "    print(f\"  ‚Ä¢ Gap of {train_r2_unlimited - test_r2_unlimited:.1%} indicates memorization, not learning\")\n",
    "    print(f\"  ‚Ä¢ Tree depth of {tree_unlimited.get_depth()} with {tree_unlimited.get_n_leaves():,} leaves creates overly specific rules\")\n",
    "    print(f\"  ‚Ä¢ Solution: Limit tree depth or use ensemble methods (Random Forest)\")\n",
    "elif (train_r2_unlimited - test_r2_unlimited) > 0.15:\n",
    "    print(\"‚ö† MODERATE OVERFITTING:\")\n",
    "    print(f\"  ‚Ä¢ Performance gap suggests some memorization of training data\")\n",
    "    print(f\"  ‚Ä¢ Consider constraining tree depth or using regularization\")\n",
    "else:\n",
    "    print(\"‚úì Good generalization - training and testing performance similar\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Now let's try a constrained tree with max_depth to control overfitting\n",
    "print(\"--- Training Decision Tree (Constrained: max_depth=10) ---\")\n",
    "tree_constrained = DecisionTreeRegressor(max_depth=10, min_samples_split=20,\n",
    "                                          min_samples_leaf=10, random_state=42)\n",
    "# max_depth=10: Limits tree to 10 levels deep\n",
    "# min_samples_split=20: Requires at least 20 observations to create a split\n",
    "# min_samples_leaf=10: Each leaf must contain at least 10 observations\n",
    "tree_constrained.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Tree depth: {tree_constrained.get_depth()}\")\n",
    "print(f\"Number of leaves: {tree_constrained.get_n_leaves()}\")\n",
    "print()\n",
    "\n",
    "# Generate predictions with constrained tree\n",
    "train_pred_constrained = tree_constrained.predict(X_train)\n",
    "test_pred_constrained = tree_constrained.predict(X_test)\n",
    "\n",
    "train_r2_constrained = r2_score(y_train, train_pred_constrained)\n",
    "test_r2_constrained = r2_score(y_test, test_pred_constrained)\n",
    "train_rmse_constrained = np.sqrt(mean_squared_error(y_train, train_pred_constrained))\n",
    "test_rmse_constrained = np.sqrt(mean_squared_error(y_test, test_pred_constrained))\n",
    "\n",
    "print(\"=== DECISION TREE PERFORMANCE (Constrained) ===\")\n",
    "print(f\"Training:  R¬≤ = {train_r2_constrained:.4f}, RMSE = {train_rmse_constrained:.2f} bikes\")\n",
    "print(f\"Testing:   R¬≤ = {test_r2_constrained:.4f}, RMSE = {test_rmse_constrained:.2f} bikes\")\n",
    "print(f\"Overfit gap: {train_r2_constrained - test_r2_constrained:.4f}\")\n",
    "print()\n",
    "\n",
    "# Compare constrained vs unlimited trees\n",
    "print(\"=== COMPARISON: Unlimited vs Constrained Tree ===\")\n",
    "print(f\"Test R¬≤ improvement: {test_r2_constrained:.4f} vs {test_r2_unlimited:.4f} ({test_r2_constrained - test_r2_unlimited:+.4f})\")\n",
    "print(f\"Overfit gap reduction: {train_r2_unlimited - test_r2_unlimited:.4f} ‚Üí {train_r2_constrained - test_r2_constrained:.4f}\")\n",
    "print()\n",
    "\n",
    "if test_r2_constrained > test_r2_unlimited:\n",
    "    print(\"‚úì CONSTRAINED TREE WINS:\")\n",
    "    print(\"  ‚Ä¢ Better testing performance despite lower training R¬≤\")\n",
    "    print(\"  ‚Ä¢ Reduced overfitting leads to better generalization\")\n",
    "    print(\"  ‚Ä¢ Demonstrates bias-variance tradeoff: small bias increase, large variance decrease\")\n",
    "else:\n",
    "    print(\"Note: Unlimited tree achieves better test performance in this case\")\n",
    "    print(\"This can occur when data patterns are genuinely complex and tree depth needed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09943426",
   "metadata": {},
   "source": [
    "**What this does:**\n",
    "- Creates chronological 80/20 train-test split preserving temporal order for honest evaluation\n",
    "- Trains unlimited-depth decision tree showing severe overfitting (training R¬≤ ‚âà99%, test R¬≤ ‚âà45%)\n",
    "- Displays tree structure metrics (depth, leaves, nodes) revealing model complexity\n",
    "- Trains constrained tree (max_depth=10, min samples constraints) to reduce overfitting\n",
    "- Compares both trees showing how depth constraints improve generalization at cost of training fit\n",
    "- Calculates overfit gap (train R¬≤ - test R¬≤) demonstrating bias-variance tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d648686",
   "metadata": {},
   "source": [
    "### Challenge 2: Visualize Decision Tree Structure\n",
    "\n",
    "Your client asks: \"Can you show me how the tree makes decisions? I want to understand the business rules it learned.\" Create a visualization of a shallow tree for interpretability.\n",
    "\n",
    "**Your Task:** Train a very shallow tree (max_depth=3) and visualize its structure with feature names and decision thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cad305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - create and visualize shallow decision tree\n",
    "\n",
    "# Train a shallow tree for visualization (max_depth=3 for clarity)\n",
    "tree_shallow = DecisionTreeRegressor(max_depth=___, min_samples_leaf=50, random_state=42)\n",
    "tree_shallow.fit(X_train, y_train)\n",
    "\n",
    "# Calculate performance of shallow tree\n",
    "test_pred_shallow = tree_shallow.predict(X_test)\n",
    "test_r2_shallow = r2_score(y_test, test_pred_shallow)\n",
    "\n",
    "print(f\"=== SHALLOW TREE (max_depth=3) ===\")\n",
    "print(f\"Tree depth: {tree_shallow.get_depth()}\")\n",
    "print(f\"Number of leaves: {tree_shallow.get_n_leaves()}\")\n",
    "print(f\"Test R¬≤: {test_r2_shallow:.4f}\")\n",
    "print()\n",
    "\n",
    "# Visualize tree structure\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(tree_shallow,\n",
    "          feature_names=_____,\n",
    "          filled=True,\n",
    "          rounded=True,\n",
    "          fontsize=10)\n",
    "plt.title('Decision Tree Structure (max_depth=3) - Interpretable Business Rules',\n",
    "          fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Extract and display the most important decision rules\n",
    "print(\"=== TOP DECISION RULES (Business Interpretation) ===\")\n",
    "feature_importance_shallow = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': tree_shallow.feature_importances_\n",
    "}).sort_values('importance', ascending=False).head(5)\n",
    "print(feature_importance_shallow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de2adcb",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üí° <strong>Tip</strong> (click to expand)</summary>\n",
    "\n",
    "\n",
    "Use `max_depth=3` to create a tree shallow enough to visualize clearly on one page. The `plot_tree()` function requires `feature_names=feature_columns` (the list of column names you defined in Step 1) to display readable feature labels instead of generic \"X[0]\" notation. Set `filled=True` to color nodes by prediction value (darker colors = higher predicted demand) and `rounded=True` for professional appearance. After visualization, use `tree_shallow.feature_importances_` to extract which features appear most frequently in the top splits - these are the key drivers the tree identified. A shallow tree sacrifices accuracy for interpretability, so expect test R¬≤ around 65-75% (lower than deeper trees) but you gain the ability to communicate exact decision logic to stakeholders. The visualization will show something like: \"If hour <= 12.5 AND workingday <= 0.5, predict low demand (weekend morning pattern)\". These are the if-then business rules your operations team can actually use for planning.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe8571e",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ü§´ <strong>Solution</strong> (click to expand)</summary>\n",
    "\n",
    "```python\n",
    "# Train a shallow tree for visualization (max_depth=3 for clarity)\n",
    "tree_shallow = DecisionTreeRegressor(max_depth=3, min_samples_leaf=50, random_state=42)\n",
    "tree_shallow.fit(X_train, y_train)\n",
    "\n",
    "# Calculate performance of shallow tree\n",
    "test_pred_shallow = tree_shallow.predict(X_test)\n",
    "test_r2_shallow = r2_score(y_test, test_pred_shallow)\n",
    "\n",
    "print(f\"=== SHALLOW TREE (max_depth=3) ===\")\n",
    "print(f\"Tree depth: {tree_shallow.get_depth()}\")\n",
    "print(f\"Number of leaves: {tree_shallow.get_n_leaves()}\")\n",
    "print(f\"Test R¬≤: {test_r2_shallow:.4f}\")\n",
    "print()\n",
    "\n",
    "# Visualize tree structure\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(tree_shallow,\n",
    "          feature_names=feature_columns,\n",
    "          filled=True,\n",
    "          rounded=True,\n",
    "          fontsize=10)\n",
    "plt.title('Decision Tree Structure (max_depth=3) - Interpretable Business Rules',\n",
    "          fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Extract and display the most important decision rules\n",
    "print(\"=== TOP DECISION RULES (Business Interpretation) ===\")\n",
    "feature_importance_shallow = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': tree_shallow.feature_importances_\n",
    "}).sort_values('importance', ascending=False).head(5)\n",
    "print(feature_importance_shallow.round(4))\n",
    "print()\n",
    "\n",
    "print(\"=== BUSINESS RULE TRANSLATION ===\")\n",
    "print(\"The tree makes decisions using if-then logic:\")\n",
    "print(\"‚Ä¢ Root node: Splits on most predictive feature (likely 'hour' or 'is_rush_hour')\")\n",
    "print(\"‚Ä¢ Each split creates two branches: one for observations meeting condition, one for those that don't\")\n",
    "print(\"‚Ä¢ Leaf nodes (colored boxes): Final demand predictions for observations reaching that leaf\")\n",
    "print(\"‚Ä¢ Node color intensity: Darker = higher predicted demand, Lighter = lower predicted demand\")\n",
    "print()\n",
    "print(\"Example interpretation:\")\n",
    "print(\"'If hour <= 12.5 AND workingday = 1 ‚Üí Predict 150 bikes/hour (morning commute)'\")\n",
    "print(\"'If hour > 18.5 AND temp > 20 ‚Üí Predict 280 bikes/hour (warm evening peak)'\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45563f0d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d3add9",
   "metadata": {},
   "source": [
    "## Step 3: Deploy Random Forest Ensemble\n",
    "\n",
    "Let's implement Random Forest to overcome individual tree overfitting through ensemble averaging of multiple diverse trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb19d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Random Forest from scikit-learn's ensemble module\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "print(\"=== RANDOM FOREST ENSEMBLE IMPLEMENTATION ===\\n\")\n",
    "\n",
    "# Train Random Forest with default parameters first\n",
    "print(\"--- Training Random Forest (Default: 100 trees) ---\")\n",
    "# RandomForestRegressor creates an ensemble of decision trees:\n",
    "# - Each tree trains on a bootstrap sample (random sampling with replacement)\n",
    "# - Each split considers only a subset of features (max_features='sqrt' by default)\n",
    "# - Final prediction = average of all tree predictions (reduces variance)\n",
    "rf_default = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "# n_estimators=100: Build 100 decision trees in the forest\n",
    "# random_state=42: Ensures reproducible results across runs\n",
    "# n_jobs=-1: Use all CPU cores for parallel training (speeds up computation)\n",
    "rf_default.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Forest size: {rf_default.n_estimators} trees\")\n",
    "print(f\"Features considered per split: sqrt({X_train.shape[1]}) ‚âà {int(np.sqrt(X_train.shape[1]))} features\")\n",
    "print()\n",
    "\n",
    "# Generate predictions with Random Forest\n",
    "train_pred_rf = rf_default.predict(X_train)\n",
    "test_pred_rf = rf_default.predict(X_test)\n",
    "\n",
    "train_r2_rf = r2_score(y_train, train_pred_rf)\n",
    "test_r2_rf = r2_score(y_test, test_pred_rf)\n",
    "train_rmse_rf = np.sqrt(mean_squared_error(y_train, train_pred_rf))\n",
    "test_rmse_rf = np.sqrt(mean_squared_error(y_test, test_pred_rf))\n",
    "\n",
    "print(\"=== RANDOM FOREST PERFORMANCE ===\")\n",
    "print(f\"Training:  R¬≤ = {train_r2_rf:.4f}, RMSE = {train_rmse_rf:.2f} bikes\")\n",
    "print(f\"Testing:   R¬≤ = {test_r2_rf:.4f}, RMSE = {test_rmse_rf:.2f} bikes\")\n",
    "print(f\"Overfit gap: {train_r2_rf - test_r2_rf:.4f}\")\n",
    "print()\n",
    "\n",
    "# Compare Random Forest vs Single Decision Tree vs Linear Baseline\n",
    "print(\"=== ALGORITHM PERFORMANCE COMPARISON ===\")\n",
    "print(\"Model                          | Train R¬≤  | Test R¬≤   | Overfit Gap | Status\")\n",
    "print(\"-\" * 85)\n",
    "print(f\"Single Tree (Unlimited)        | {train_r2_unlimited:.4f}    | {test_r2_unlimited:.4f}    | {train_r2_unlimited - test_r2_unlimited:.4f}      | Severe Overfit\")\n",
    "print(f\"Single Tree (Constrained)      | {train_r2_constrained:.4f}    | {test_r2_constrained:.4f}    | {train_r2_constrained - test_r2_constrained:.4f}      | Moderate Overfit\")\n",
    "print(f\"Random Forest (100 trees)      | {train_r2_rf:.4f}    | {test_r2_rf:.4f}    | {train_r2_rf - test_r2_rf:.4f}      | Good Balance\")\n",
    "print()\n",
    "\n",
    "# Calculate competitive advantages for business reporting\n",
    "test_improvement_vs_unlimited = (test_r2_rf - test_r2_unlimited) / test_r2_unlimited * 100\n",
    "test_improvement_vs_constrained = (test_r2_rf - test_r2_constrained) / test_r2_constrained * 100\n",
    "\n",
    "print(\"=== RANDOM FOREST COMPETITIVE ADVANTAGES ===\")\n",
    "print(f\"Test R¬≤ improvement vs unlimited tree: {test_improvement_vs_unlimited:+.1f}%\")\n",
    "print(f\"Test R¬≤ improvement vs constrained tree: {test_improvement_vs_constrained:+.1f}%\")\n",
    "print(f\"Overfit gap reduction: {train_r2_unlimited - test_r2_unlimited:.4f} ‚Üí {train_r2_rf - test_r2_rf:.4f}\")\n",
    "print()\n",
    "\n",
    "if test_r2_rf >= 0.85:\n",
    "    print(\"‚úì EXCELLENT PERFORMANCE:\")\n",
    "    print(\"  ‚Ä¢ Test R¬≤ ‚â• 85% meets Series B investor expectations\")\n",
    "    print(\"  ‚Ä¢ Production-ready accuracy for operational deployment\")\n",
    "    print(\"  ‚Ä¢ Competitive advantage over linear baseline established\")\n",
    "elif test_r2_rf >= 0.75:\n",
    "    print(\"‚úì STRONG PERFORMANCE:\")\n",
    "    print(\"  ‚Ä¢ Test R¬≤ ‚â• 75% represents significant improvement\")\n",
    "    print(\"  ‚Ä¢ Suitable for operational planning and strategic decision-making\")\n",
    "    print(\"  ‚Ä¢ Demonstrates advanced ML capabilities to stakeholders\")\n",
    "else:\n",
    "    print(\"‚ö† MODERATE PERFORMANCE:\")\n",
    "    print(\"  ‚Ä¢ Test R¬≤ suggests room for further optimization\")\n",
    "    print(\"  ‚Ä¢ Consider additional feature engineering or hyperparameter tuning\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Demonstrate ensemble diversity by examining individual tree predictions\n",
    "print(\"=== ENSEMBLE DIVERSITY DEMONSTRATION ===\")\n",
    "print(\"Examining predictions from first 10 trees for one observation:\")\n",
    "example_obs = X_test.iloc[0:1]\n",
    "print(f\"Example observation features:\")\n",
    "print(f\"  Hour: {example_obs['hour'].values[0]}, Temp: {example_obs['temp'].values[0]:.1f}¬∞C, \")\n",
    "print(f\"  Working day: {example_obs['workingday'].values[0]}, Rush hour: {example_obs['is_rush_hour'].values[0]}\")\n",
    "print()\n",
    "\n",
    "tree_predictions = []\n",
    "for i in range(min(10, rf_default.n_estimators)):\n",
    "    # Each tree in the forest makes independent predictions\n",
    "    tree_pred = rf_default.estimators_[i].predict(example_obs)[0]\n",
    "    tree_predictions.append(tree_pred)\n",
    "    print(f\"Tree {i+1:2d} predicts: {tree_pred:6.1f} bikes\")\n",
    "\n",
    "print(f\"\\nAverage of 10 trees:  {np.mean(tree_predictions):6.1f} bikes\")\n",
    "print(f\"Full ensemble (100):  {rf_default.predict(example_obs)[0]:6.1f} bikes\")\n",
    "print(f\"Prediction spread:    {np.max(tree_predictions) - np.min(tree_predictions):6.1f} bikes\")\n",
    "print(f\"Standard deviation:   {np.std(tree_predictions):6.1f} bikes\")\n",
    "print()\n",
    "\n",
    "print(\"WHY DIVERSITY MATTERS:\")\n",
    "print(\"‚Ä¢ Each tree sees different bootstrap sample (random observations)\")\n",
    "print(\"‚Ä¢ Each split uses different random feature subset\")\n",
    "print(\"‚Ä¢ Individual trees make different predictions (some high, some low)\")\n",
    "print(\"‚Ä¢ Averaging cancels individual errors ‚Üí more stable, reliable forecast\")\n",
    "print(\"‚Ä¢ This is the 'wisdom of crowds' principle: collective intelligence > individual guesses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba235283",
   "metadata": {},
   "source": [
    "**What this does:**\n",
    "- Trains Random Forest with 100 trees using bootstrap sampling and feature randomness\n",
    "- Evaluates on both training and testing sets showing dramatically reduced overfitting\n",
    "- Compares performance against single trees demonstrating ensemble advantages\n",
    "- Shows individual tree predictions for one observation revealing diversity in the forest\n",
    "- Calculates prediction spread and standard deviation quantifying ensemble variance reduction\n",
    "- Provides business-focused performance assessment (excellent/strong/moderate categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07aa1a90",
   "metadata": {},
   "source": [
    "### Challenge 3: Compare Different Ensemble Sizes\n",
    "\n",
    "Your client asks: \"Do we really need 100 trees? Could we get similar performance with fewer trees (faster training) or do we need more trees for better accuracy?\" Experiment with ensemble size.\n",
    "\n",
    "**Your Task:** Train Random Forests with different numbers of trees (10, 50, 100, 200, 300) and analyze the performance vs. training time tradeoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6cd9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - compare different ensemble sizes\n",
    "\n",
    "import time\n",
    "\n",
    "ensemble_sizes = [10, 50, 100, 200, 300]\n",
    "results = []\n",
    "\n",
    "for n_trees in ensemble_sizes:\n",
    "    print(f\"Training Random Forest with {n_trees} trees...\")\n",
    "\n",
    "    # Time the training process\n",
    "    start_time = time.time()\n",
    "    rf_temp = RandomForestRegressor(n_estimators=_____, random_state=42, n_jobs=-1)\n",
    "    rf_temp.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    # Evaluate performance\n",
    "    test_pred_temp = rf_temp.predict(X_test)\n",
    "    test_r2_temp = r2_score(y_test, test_pred_temp)\n",
    "    test_rmse_temp = np.sqrt(mean_squared_error(y_test, test_pred_temp))\n",
    "\n",
    "    # Store results\n",
    "    results.append({\n",
    "        'n_trees': n_trees,\n",
    "        'training_time': training_time,\n",
    "        'test_r2': test_r2_temp,\n",
    "        'test_rmse': test_rmse_temp\n",
    "    })\n",
    "\n",
    "    print(f\"  Training time: {training_time:.2f}s, Test R¬≤: {test_r2_temp:.4f}\")\n",
    "    print()\n",
    "\n",
    "# Visualize performance vs ensemble size\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Panel 1: Test R¬≤ vs ensemble size\n",
    "axes[0].plot(results_df['n_trees'], results_df['test_r2'], 'o-', linewidth=2, markersize=8, color='darkgreen')\n",
    "axes[0].set_xlabel('Number of Trees', fontsize=11)\n",
    "axes[0].set_ylabel('Test R¬≤', fontsize=11)\n",
    "axes[0].set_title('Test Performance vs Ensemble Size', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 2: Training time vs ensemble size\n",
    "axes[1].plot(results_df['n_trees'], results_df['training_time'], 's-', linewidth=2, markersize=8, color='darkorange')\n",
    "axes[1].set_xlabel('Number of Trees', fontsize=11)\n",
    "axes[1].set_ylabel('Training Time (seconds)', fontsize=11)\n",
    "axes[1].set_title('Training Time vs Ensemble Size', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Business recommendation\n",
    "print(\"=== ENSEMBLE SIZE RECOMMENDATION ===\")\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c127e5",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üí° <strong>Tip</strong> (click to expand)</summary>\n",
    "\n",
    "\n",
    "Loop through each ensemble size and create a fresh `RandomForestRegressor(n_estimators=n_trees, random_state=42, n_jobs=-1)` for each iteration. Use `time.time()` before and after `.fit()` to measure training duration: `start = time.time(); model.fit(X, y); duration = time.time() - start`. Store all results in a list of dictionaries, then convert to DataFrame for easy analysis and visualization. The performance curve typically shows diminishing returns: 10‚Üí50 trees gives large improvement, 100‚Üí200 gives small improvement, 200‚Üí300 gives minimal improvement. Training time increases linearly with tree count (200 trees takes ~2x as long as 100 trees) so there's a clear tradeoff. Business insight: 100-200 trees usually provides the sweet spot - excellent performance without excessive training time. For production deployment, consider whether faster predictions (fewer trees) or maximum accuracy (more trees) matters more to your client's use case. If they need real-time predictions for millions of users, fewer trees might be preferable; if they're doing daily batch forecasting for operational planning, more trees at higher accuracy makes sense.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d11dd7c",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ü§´ <strong>Solution</strong> (click to expand)</summary>\n",
    "\n",
    "```python\n",
    "import time\n",
    "\n",
    "ensemble_sizes = [10, 50, 100, 200, 300]\n",
    "results = []\n",
    "\n",
    "for n_trees in ensemble_sizes:\n",
    "    print(f\"Training Random Forest with {n_trees} trees...\")\n",
    "\n",
    "    # Time the training process\n",
    "    start_time = time.time()\n",
    "    rf_temp = RandomForestRegressor(n_estimators=n_trees, random_state=42, n_jobs=-1)\n",
    "    rf_temp.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    # Evaluate performance\n",
    "    test_pred_temp = rf_temp.predict(X_test)\n",
    "    test_r2_temp = r2_score(y_test, test_pred_temp)\n",
    "    test_rmse_temp = np.sqrt(mean_squared_error(y_test, test_pred_temp))\n",
    "\n",
    "    # Store results\n",
    "    results.append({\n",
    "        'n_trees': n_trees,\n",
    "        'training_time': training_time,\n",
    "        'test_r2': test_r2_temp,\n",
    "        'test_rmse': test_rmse_temp\n",
    "    })\n",
    "\n",
    "    print(f\"  Training time: {training_time:.2f}s, Test R¬≤: {test_r2_temp:.4f}\")\n",
    "    print()\n",
    "\n",
    "# Visualize performance vs ensemble size\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Panel 1: Test R¬≤ vs ensemble size\n",
    "axes[0].plot(results_df['n_trees'], results_df['test_r2'], 'o-', linewidth=2, markersize=8, color='darkgreen')\n",
    "axes[0].set_xlabel('Number of Trees', fontsize=11)\n",
    "axes[0].set_ylabel('Test R¬≤', fontsize=11)\n",
    "axes[0].set_title('Test Performance vs Ensemble Size', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 2: Training time vs ensemble size\n",
    "axes[1].plot(results_df['n_trees'], results_df['training_time'], 's-', linewidth=2, markersize=8, color='darkorange')\n",
    "axes[1].set_xlabel('Number of Trees', fontsize=11)\n",
    "axes[1].set_ylabel('Training Time (seconds)', fontsize=11)\n",
    "axes[1].set_title('Training Time vs Ensemble Size', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Business recommendation\n",
    "print(\"=== ENSEMBLE SIZE RECOMMENDATION ===\")\n",
    "print(results_df.to_string(index=False))\n",
    "print()\n",
    "\n",
    "best_value_idx = results_df['test_r2'].idxmax()\n",
    "best_value = results_df.loc[best_value_idx]\n",
    "print(f\"‚úì Recommended: {int(best_value['n_trees'])} trees\")\n",
    "print(f\"  ‚Ä¢ Test R¬≤: {best_value['test_r2']:.4f}\")\n",
    "print(f\"  ‚Ä¢ Training time: {best_value['training_time']:.2f}s\")\n",
    "print(f\"  ‚Ä¢ Rationale: {'Excellent accuracy-speed balance' if best_value['n_trees'] <= 100 else 'Maximum accuracy justified for critical forecasting'}\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde90115",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab944e6",
   "metadata": {},
   "source": [
    "## Step 4: Feature Importance Analysis\n",
    "\n",
    "Let's analyze which features drive bike demand predictions to guide strategic investments and operational decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e77af9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature importance from trained Random Forest\n",
    "print(\"=== RANDOM FOREST FEATURE IMPORTANCE ANALYSIS ===\\n\")\n",
    "\n",
    "# Feature importance based on mean decrease in impurity (MDI)\n",
    "# Higher values = feature contributed more to prediction accuracy across all trees\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': rf_default.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"--- Feature Importance Rankings ---\")\n",
    "print(f\"{'Rank':<6} {'Feature':<25} {'Importance':<12} {'Percentage':<12} {'Visual'}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "for rank, (idx, row) in enumerate(feature_importance.iterrows(), 1):\n",
    "    bar = '‚ñà' * int(row['importance'] * 100)\n",
    "    percentage = row['importance'] * 100\n",
    "    print(f\"{rank:<6} {row['feature']:<25} {row['importance']:.4f}       {percentage:>6.2f}%        {bar}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Calculate cumulative importance to identify critical feature subset\n",
    "feature_importance['cumulative'] = feature_importance['importance'].cumsum()\n",
    "\n",
    "print(\"--- Cumulative Importance Analysis ---\")\n",
    "for i in range(min(5, len(feature_importance))):\n",
    "    feature_name = feature_importance.iloc[i]['feature']\n",
    "    cumulative = feature_importance.iloc[i]['cumulative']\n",
    "    print(f\"Top {i+1} feature(s): {cumulative:.1%} of total predictive power\")\n",
    "    if cumulative >= 0.80:\n",
    "        print(f\"  ‚Üí {i+1} features capture 80% of model intelligence\")\n",
    "        break\n",
    "\n",
    "print()\n",
    "\n",
    "# Visualize feature importance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Panel 1: Horizontal bar chart of top 10 features\n",
    "top_features = feature_importance.head(10)\n",
    "colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(top_features)))\n",
    "axes[0].barh(range(len(top_features)), top_features['importance'], color=colors)\n",
    "axes[0].set_yticks(range(len(top_features)))\n",
    "axes[0].set_yticklabels(top_features['feature'])\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].set_xlabel('Importance Score', fontsize=11)\n",
    "axes[0].set_title('Top 10 Feature Importance', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Panel 2: Cumulative importance curve\n",
    "axes[1].plot(range(1, len(feature_importance) + 1), feature_importance['cumulative'],\n",
    "             'o-', linewidth=2, markersize=6, color='darkgreen')\n",
    "axes[1].axhline(y=0.80, color='red', linestyle='--', linewidth=2, label='80% threshold')\n",
    "axes[1].axhline(y=0.90, color='orange', linestyle='--', linewidth=2, label='90% threshold')\n",
    "axes[1].set_xlabel('Number of Top Features', fontsize=11)\n",
    "axes[1].set_ylabel('Cumulative Importance', fontsize=11)\n",
    "axes[1].set_title('Cumulative Feature Contribution', fontsize=12, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=== BUSINESS INSIGHTS FOR CAPITAL CITY BIKES ===\")\n",
    "\n",
    "# Interpret top 3 features for strategic recommendations\n",
    "for rank in range(min(3, len(feature_importance))):\n",
    "    feature = feature_importance.iloc[rank]['feature']\n",
    "    importance = feature_importance.iloc[rank]['importance']\n",
    "\n",
    "    print(f\"\\n{rank+1}. {feature}: {importance:.1%} importance\")\n",
    "\n",
    "    # Business interpretation by feature type\n",
    "    if feature in ['hour', 'is_rush_hour']:\n",
    "        print(\"   ‚Üí IMPLICATION: Time-of-day dominates demand patterns\")\n",
    "        print(\"   ‚Üí STRATEGY: Optimize fleet positioning by hour (rush hours critical)\")\n",
    "        print(\"   ‚Üí INVESTMENT: Real-time repositioning systems, surge pricing algorithms\")\n",
    "    elif feature in ['temp', 'atemp']:\n",
    "        print(\"   ‚Üí IMPLICATION: Temperature drives cycling comfort decisions\")\n",
    "        print(\"   ‚Üí STRATEGY: Weather-responsive capacity planning\")\n",
    "        print(\"   ‚Üí INVESTMENT: Weather API integration, temperature-based forecasting\")\n",
    "    elif feature in ['workingday', 'dayofweek', 'is_weekend']:\n",
    "        print(\"   ‚Üí IMPLICATION: Commuter vs. leisure patterns differ fundamentally\")\n",
    "        print(\"   ‚Üí STRATEGY: Separate weekday (commute) vs. weekend (leisure) operations\")\n",
    "        print(\"   ‚Üí INVESTMENT: Day-specific marketing, differential pricing strategies\")\n",
    "    elif feature in ['season', 'month']:\n",
    "        print(\"   ‚Üí IMPLICATION: Seasonal variations require long-term planning\")\n",
    "        print(\"   ‚Üí STRATEGY: Adjust fleet size, maintenance schedules by season\")\n",
    "        print(\"   ‚Üí INVESTMENT: Seasonal fleet scaling, predictive maintenance\")\n",
    "    elif feature in ['weather_severity', 'humidity', 'windspeed']:\n",
    "        print(\"   ‚Üí IMPLICATION: Weather conditions directly impact usage decisions\")\n",
    "        print(\"   ‚Üí STRATEGY: Dynamic bike redistribution based on forecasts\")\n",
    "        print(\"   ‚Üí INVESTMENT: Weather-triggered alerts, covered bike stations\")\n",
    "    else:\n",
    "        print(\"   ‚Üí IMPLICATION: Feature provides supplementary predictive value\")\n",
    "        print(\"   ‚Üí STRATEGY: Maintain in model for marginal accuracy gains\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*75)\n",
    "print(\"STRATEGIC RECOMMENDATION:\")\n",
    "top_feature = feature_importance.iloc[0]['feature']\n",
    "top_importance = feature_importance.iloc[0]['importance']\n",
    "print(f\"‚úì '{top_feature}' dominates with {top_importance:.1%} importance\")\n",
    "print(f\"‚úì Top 3 features capture {feature_importance.iloc[2]['cumulative']:.1%} of predictive power\")\n",
    "print(f\"‚úì Focus operational investments on temporal optimization and weather responsiveness\")\n",
    "print(f\"‚úì These insights justify Series B funding requests for real-time forecasting systems\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354196ac",
   "metadata": {},
   "source": [
    "**What this does:**\n",
    "- Extracts `.feature_importances_` from trained Random Forest showing MDI (Mean Decrease in Impurity) scores\n",
    "- Displays ranked table with importance scores, percentages, and visual bars for quick interpretation\n",
    "- Calculates cumulative importance showing how many features capture 80%/90% of predictive power\n",
    "- Creates two-panel visualization: horizontal bar chart (top 10 features) and cumulative curve\n",
    "- Translates top features into business implications with strategic recommendations for each\n",
    "- Provides actionable insights for resource allocation, investment decisions, and operational priorities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89594593",
   "metadata": {},
   "source": [
    "### Challenge 4: Validate Feature Importance Through Permutation\n",
    "\n",
    "Your client asks: \"How can we be sure these importance scores are reliable? What if they're artifacts of correlated features?\" Test feature importance using permutation importance as validation.\n",
    "\n",
    "**Your Task:** Calculate permutation importance (how much test performance drops when each feature is randomly shuffled) and compare with MDI importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc79d86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - calculate and compare permutation importance\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "print(\"=== PERMUTATION IMPORTANCE VALIDATION ===\")\n",
    "print(\"(Measuring performance drop when each feature is randomly shuffled)\")\n",
    "print()\n",
    "\n",
    "# Calculate permutation importance on test set\n",
    "# This method randomly shuffles each feature and measures the drop in model performance\n",
    "# More reliable than MDI for correlated features\n",
    "perm_importance = permutation_importance(rf_default, X_test, y_test,\n",
    "                                         n_repeats=10, random_state=42, n_jobs=-1)\n",
    "# n_repeats=10: Shuffle each feature 10 times and average results\n",
    "# Provides stable estimates despite randomness in shuffling\n",
    "\n",
    "# Create comparison DataFrame\n",
    "importance_comparison = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'mdi_importance': rf_default.feature_importances_,\n",
    "    'perm_importance': perm_importance.importances_mean,\n",
    "    'perm_std': perm_importance.importances_std\n",
    "}).sort_values('perm_importance', ascending=False)\n",
    "\n",
    "print(\"--- Importance Comparison: MDI vs Permutation ---\")\n",
    "print(f\"{'Feature':<25} {'MDI':<10} {'Permutation':<12} {'Std':<10} {'Agreement'}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "for _, row in importance_comparison.head(10).iterrows():\n",
    "    mdi_rank = feature_importance[feature_importance['feature'] == row['feature']].index[0] + 1\n",
    "    perm_rank = importance_comparison[importance_comparison['feature'] == row['feature']].index[0] + 1\n",
    "    rank_diff = abs(mdi_rank - perm_rank)\n",
    "    agreement = \"‚úì High\" if rank_diff <= 2 else \"~ Medium\" if rank_diff <= 5 else \"‚úó Low\"\n",
    "\n",
    "    print(f\"{row['feature']:<25} {row['mdi_importance']:<10.4f} {row['perm_importance']:<12.4f} \"\n",
    "          f\"{row['perm_std']:<10.4f} {agreement}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Visualize comparison\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_comparison = importance_comparison.head(10)\n",
    "x_pos = np.arange(len(top_comparison))\n",
    "width = 0.35\n",
    "\n",
    "plt.barh(x_pos - width/2, top_comparison['mdi_importance'], width,\n",
    "         label='MDI Importance', color='darkgreen', alpha=0.7)\n",
    "plt.barh(x_pos + width/2, top_comparison['perm_importance'], width,\n",
    "         label='Permutation Importance', color='darkorange', alpha=0.7)\n",
    "\n",
    "plt.yticks(x_pos, top_comparison['feature'])\n",
    "plt.xlabel('Importance Score', fontsize=11)\n",
    "plt.title('Feature Importance: MDI vs Permutation (Top 10 Features)',\n",
    "          fontsize=12, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=== VALIDATION CONCLUSIONS ===\")\n",
    "print(\"‚úì High agreement between MDI and permutation: Feature importance is reliable\")\n",
    "print(\"‚úì Low permutation std: Consistent importance across different shuffling trials\")\n",
    "print(\"‚ö† If major disagreement exists: Correlated features may share importance\")\n",
    "print(\"  ‚Üí Solution: Group correlated features (e.g., temp + atemp) for interpretation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0529ef",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üí° <strong>Tip</strong> (click to expand)</summary>\n",
    "\n",
    "\n",
    "Import `permutation_importance` from `sklearn.inspection` which implements the shuffling approach. Call it with `permutation_importance(model, X_test, y_test, n_repeats=10, random_state=42, n_jobs=-1)` - note we use X_test (not X_train) because we want to measure how much each feature helps generalization to new data. The function returns an object with `.importances_mean` (average importance across repeats) and `.importances_std` (standard deviation showing consistency). Create a comparison DataFrame joining MDI importance (from `model.feature_importances_`) with permutation importance - use `.sort_values('perm_importance', ascending=False)` to rank by permutation scores. Look for agreement: if both methods rank a feature highly, that's strong evidence it truly matters. Disagreement suggests correlated features (e.g., `temp` and `atemp` are highly correlated, so MDI may split their importance unpredictably). Permutation importance is more reliable but computationally expensive (requires making predictions multiple times), while MDI is fast but can be biased by correlations. Business insight: Features with high importance in BOTH methods are your most reliable strategic priorities.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62f0630",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ü§´ <strong>Solution</strong> (click to expand)</summary>\n",
    "\n",
    "```python\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "print(\"=== PERMUTATION IMPORTANCE VALIDATION ===\")\n",
    "print(\"(Measuring performance drop when each feature is randomly shuffled)\")\n",
    "print()\n",
    "\n",
    "# Calculate permutation importance on test set\n",
    "perm_importance = permutation_importance(rf_default, X_test, y_test,\n",
    "                                         n_repeats=10, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Create comparison DataFrame\n",
    "importance_comparison = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'mdi_importance': rf_default.feature_importances_,\n",
    "    'perm_importance': perm_importance.importances_mean,\n",
    "    'perm_std': perm_importance.importances_std\n",
    "}).sort_values('perm_importance', ascending=False)\n",
    "\n",
    "print(\"--- Importance Comparison: MDI vs Permutation ---\")\n",
    "print(f\"{'Feature':<25} {'MDI':<10} {'Permutation':<12} {'Std':<10} {'Agreement'}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "for _, row in importance_comparison.head(10).iterrows():\n",
    "    mdi_rank = feature_importance[feature_importance['feature'] == row['feature']].index[0] + 1\n",
    "    perm_rank = importance_comparison[importance_comparison['feature'] == row['feature']].index[0] + 1\n",
    "    rank_diff = abs(mdi_rank - perm_rank)\n",
    "    agreement = \"‚úì High\" if rank_diff <= 2 else \"~ Medium\" if rank_diff <= 5 else \"‚úó Low\"\n",
    "\n",
    "    print(f\"{row['feature']:<25} {row['mdi_importance']:<10.4f} {row['perm_importance']:<12.4f} \"\n",
    "          f\"{row['perm_std']:<10.4f} {agreement}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Visualize comparison\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_comparison = importance_comparison.head(10)\n",
    "x_pos = np.arange(len(top_comparison))\n",
    "width = 0.35\n",
    "\n",
    "plt.barh(x_pos - width/2, top_comparison['mdi_importance'], width,\n",
    "         label='MDI Importance', color='darkgreen', alpha=0.7)\n",
    "plt.barh(x_pos + width/2, top_comparison['perm_importance'], width,\n",
    "         label='Permutation Importance', color='darkorange', alpha=0.7)\n",
    "\n",
    "plt.yticks(x_pos, top_comparison['feature'])\n",
    "plt.xlabel('Importance Score', fontsize=11)\n",
    "plt.title('Feature Importance: MDI vs Permutation (Top 10 Features)',\n",
    "          fontsize=12, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=== VALIDATION CONCLUSIONS ===\")\n",
    "correlation_check = importance_comparison.head(5)[['feature', 'mdi_importance', 'perm_importance']]\n",
    "print(\"\\nTop 5 features by permutation importance:\")\n",
    "print(correlation_check.to_string(index=False))\n",
    "print()\n",
    "\n",
    "print(\"‚úì Both methods agree on top features: hour, temp, is_rush_hour, workingday_hour\")\n",
    "print(\"‚úì Low permutation std (<0.01): Consistent importance across shuffling trials\")\n",
    "print(\"‚úì Feature importance is reliable - safe to base business decisions on these rankings\")\n",
    "print()\n",
    "print(\"Note: Slight rank differences are normal due to correlated features (e.g., temp vs atemp)\")\n",
    "print(\"Recommendation: Focus investments on consistently high-ranking features across both methods\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b59ce6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6866c10",
   "metadata": {},
   "source": [
    "## Step 5: Random Forest Hyperparameter Optimization\n",
    "\n",
    "Let's systematically explore Random Forest hyperparameters to maximize prediction accuracy for Capital City Bikes' competitive advantage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cfdf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GridSearchCV for systematic hyperparameter search\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "\n",
    "print(\"=== RANDOM FOREST HYPERPARAMETER OPTIMIZATION ===\\n\")\n",
    "\n",
    "# Define hyperparameter grid for systematic search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],           # Number of trees in forest\n",
    "    'max_depth': [10, 15, 20, None],           # Maximum tree depth (None = unlimited)\n",
    "    'min_samples_split': [2, 5, 10],           # Min samples required to split node\n",
    "    'min_samples_leaf': [1, 2, 5],             # Min samples required at leaf node\n",
    "    'max_features': ['sqrt', 'log2', 0.5]      # Features considered per split\n",
    "}\n",
    "\n",
    "print(\"--- Hyperparameter Search Space ---\")\n",
    "print(f\"n_estimators options: {param_grid['n_estimators']}\")\n",
    "print(f\"max_depth options: {param_grid['max_depth']}\")\n",
    "print(f\"min_samples_split options: {param_grid['min_samples_split']}\")\n",
    "print(f\"min_samples_leaf options: {param_grid['min_samples_leaf']}\")\n",
    "print(f\"max_features options: {param_grid['max_features']}\")\n",
    "print(f\"\\nTotal combinations: {len(param_grid['n_estimators']) * len(param_grid['max_depth']) * len(param_grid['min_samples_split']) * len(param_grid['min_samples_leaf']) * len(param_grid['max_features'])}\")\n",
    "print()\n",
    "\n",
    "# Use TimeSeriesSplit for time-aware cross-validation\n",
    "# This ensures we always train on past data and validate on future data\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "# Create GridSearchCV for systematic hyperparameter search\n",
    "print(\"--- Running Grid Search (this may take several minutes) ---\")\n",
    "print(\"Using TimeSeriesSplit with 3 folds for time series integrity\")\n",
    "print()\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "    param_grid=param_grid,\n",
    "    cv=tscv,                    # Time series cross-validation\n",
    "    scoring='r2',               # Optimize for R¬≤ score\n",
    "    n_jobs=-1,                  # Use all CPU cores\n",
    "    verbose=2                   # Show progress during search\n",
    ")\n",
    "\n",
    "# Run grid search on training data\n",
    "import time\n",
    "start_time = time.time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "search_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n=== GRID SEARCH COMPLETED ===\")\n",
    "print(f\"Search time: {search_time/60:.1f} minutes\")\n",
    "print()\n",
    "\n",
    "# Extract best parameters and performance\n",
    "best_params = grid_search.best_params_\n",
    "best_cv_score = grid_search.best_score_\n",
    "\n",
    "print(\"--- Best Hyperparameters Found ---\")\n",
    "for param, value in best_params.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "print()\n",
    "\n",
    "print(f\"Best cross-validation R¬≤: {best_cv_score:.4f}\")\n",
    "print()\n",
    "\n",
    "# Train final model with best hyperparameters on full training set\n",
    "print(\"--- Training Final Optimized Model ---\")\n",
    "rf_optimized = grid_search.best_estimator_\n",
    "# Note: grid_search.best_estimator_ is already trained on full X_train\n",
    "\n",
    "# Evaluate optimized model on test set\n",
    "test_pred_optimized = rf_optimized.predict(X_test)\n",
    "test_r2_optimized = r2_score(y_test, test_pred_optimized)\n",
    "test_rmse_optimized = np.sqrt(mean_squared_error(y_test, test_pred_optimized))\n",
    "\n",
    "print(f\"Optimized model test R¬≤: {test_r2_optimized:.4f}\")\n",
    "print(f\"Optimized model test RMSE: {test_rmse_optimized:.2f} bikes\")\n",
    "print()\n",
    "\n",
    "# Compare default vs optimized performance\n",
    "print(\"=== OPTIMIZATION IMPACT ASSESSMENT ===\")\n",
    "print(f\"Default RF (100 trees):  Test R¬≤ = {test_r2_rf:.4f}, RMSE = {test_rmse_rf:.2f}\")\n",
    "print(f\"Optimized RF:            Test R¬≤ = {test_r2_optimized:.4f}, RMSE = {test_rmse_optimized:.2f}\")\n",
    "print(f\"Improvement:             ŒîR¬≤ = {test_r2_optimized - test_r2_rf:+.4f}, ŒîRMSE = {test_rmse_rf - test_rmse_optimized:+.2f} bikes\")\n",
    "print()\n",
    "\n",
    "if (test_r2_optimized - test_r2_rf) > 0.02:\n",
    "    print(\"‚úì SIGNIFICANT IMPROVEMENT:\")\n",
    "    print(\"  ‚Ä¢ Hyperparameter optimization delivered measurable accuracy gains\")\n",
    "    print(\"  ‚Ä¢ Optimized model justified for production deployment\")\n",
    "elif (test_r2_optimized - test_r2_rf) > 0.005:\n",
    "    print(\"‚úì MODERATE IMPROVEMENT:\")\n",
    "    print(\"  ‚Ä¢ Small accuracy gains from optimization\")\n",
    "    print(\"  ‚Ä¢ Consider whether improvement justifies added model complexity\")\n",
    "else:\n",
    "    print(\"~ MINIMAL IMPROVEMENT:\")\n",
    "    print(\"  ‚Ä¢ Default parameters already near-optimal for this dataset\")\n",
    "    print(\"  ‚Ä¢ Can use simpler default model without significant performance loss\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Analyze top 5 parameter configurations from grid search\n",
    "print(\"=== TOP 5 PARAMETER CONFIGURATIONS ===\")\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "top_configs = results_df.nsmallest(5, 'rank_test_score')[\n",
    "    ['params', 'mean_test_score', 'std_test_score', 'rank_test_score']\n",
    "]\n",
    "\n",
    "for idx, row in top_configs.iterrows():\n",
    "    print(f\"Rank {int(row['rank_test_score'])}: CV R¬≤ = {row['mean_test_score']:.4f} (¬±{row['std_test_score']:.4f})\")\n",
    "    print(f\"  Parameters: {row['params']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722bf22b",
   "metadata": {},
   "source": [
    "**What this does:**\n",
    "- Defines comprehensive hyperparameter grid covering key Random Forest parameters\n",
    "- Uses TimeSeriesSplit (3 folds) to maintain temporal integrity during cross-validation\n",
    "- Runs GridSearchCV testing all parameter combinations with progress tracking\n",
    "- Extracts best hyperparameters and corresponding cross-validation performance\n",
    "- Trains final optimized model and evaluates on held-out test set\n",
    "- Compares optimized vs default model showing improvement magnitude\n",
    "- Displays top 5 configurations helping understand parameter sensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed0d97f",
   "metadata": {},
   "source": [
    "### Challenge 5: Analyze Hyperparameter Sensitivity\n",
    "\n",
    "Your client asks: \"Which hyperparameters matter most? Can we simplify our model by fixing less important parameters?\" Analyze which parameters have the biggest impact on performance.\n",
    "\n",
    "**Your Task:** Extract grid search results, visualize how performance varies with each hyperparameter, and identify which parameters are most critical vs. which have minimal impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d333233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - analyze hyperparameter sensitivity\n",
    "\n",
    "# Extract detailed grid search results\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# Analyze impact of n_estimators\n",
    "print(\"=== HYPERPARAMETER SENSITIVITY ANALYSIS ===\\n\")\n",
    "\n",
    "print(\"--- Impact of n_estimators (Number of Trees) ---\")\n",
    "estimator_analysis = results_df.groupby('param_n_estimators')['mean_test_score'].agg(['mean', 'std', 'min', 'max'])\n",
    "print(estimator_analysis)\n",
    "print()\n",
    "\n",
    "print(\"--- Impact of max_depth (Tree Depth) ---\")\n",
    "depth_analysis = results_df.groupby('param_max_depth')['mean_test_score'].agg(['mean', 'std', 'min', 'max'])\n",
    "print(depth_analysis)\n",
    "print()\n",
    "\n",
    "print(\"--- Impact of max_features (Feature Randomness) ---\")\n",
    "features_analysis = results_df.groupby('param_max_features')['mean_test_score'].agg(['mean', 'std', 'min', 'max'])\n",
    "print(features_analysis)\n",
    "print()\n",
    "\n",
    "# Visualize parameter sensitivity\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Panel 1: n_estimators impact\n",
    "param_values = sorted(results_df['param_n_estimators'].unique())\n",
    "mean_scores = [results_df[results_df['param_n_estimators']==val]['mean_test_score'].mean()\n",
    "               for val in param_values]\n",
    "axes[0, 0].plot(param_values, mean_scores, 'o-', linewidth=2, markersize=8, color='darkgreen')\n",
    "axes[0, 0].set_xlabel('n_estimators', fontsize=10)\n",
    "axes[0, 0].set_ylabel('Mean CV R¬≤', fontsize=10)\n",
    "axes[0, 0].set_title('Impact of Number of Trees', fontsize=11, fontweight='bold')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 2: max_depth impact\n",
    "# Convert None to string for plotting\n",
    "depth_values = sorted([str(x) for x in results_df['param_max_depth'].unique()],\n",
    "                      key=lambda x: float('inf') if x == 'None' else float(x))\n",
    "mean_scores_depth = [results_df[results_df['param_max_depth'].astype(str)==val]['mean_test_score'].mean()\n",
    "                     for val in depth_values]\n",
    "axes[0, 1].plot(range(len(depth_values)), mean_scores_depth, 's-', linewidth=2, markersize=8, color='darkorange')\n",
    "axes[0, 1].set_xticks(range(len(depth_values)))\n",
    "axes[0, 1].set_xticklabels(depth_values)\n",
    "axes[0, 1].set_xlabel('max_depth', fontsize=10)\n",
    "axes[0, 1].set_ylabel('Mean CV R¬≤', fontsize=10)\n",
    "axes[0, 1].set_title('Impact of Maximum Tree Depth', fontsize=11, fontweight='bold')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 3: max_features impact\n",
    "feature_values = sorted([str(x) for x in results_df['param_max_features'].unique()])\n",
    "mean_scores_features = [results_df[results_df['param_max_features'].astype(str)==val]['mean_test_score'].mean()\n",
    "                        for val in feature_values]\n",
    "axes[1, 0].bar(range(len(feature_values)), mean_scores_features, color='teal', alpha=0.7)\n",
    "axes[1, 0].set_xticks(range(len(feature_values)))\n",
    "axes[1, 0].set_xticklabels(feature_values)\n",
    "axes[1, 0].set_xlabel('max_features', fontsize=10)\n",
    "axes[1, 0].set_ylabel('Mean CV R¬≤', fontsize=10)\n",
    "axes[1, 0].set_title('Impact of Feature Randomness', fontsize=11, fontweight='bold')\n",
    "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Panel 4: min_samples_split impact\n",
    "split_values = sorted(results_df['param_min_samples_split'].unique())\n",
    "mean_scores_split = [results_df[results_df['param_min_samples_split']==val]['mean_test_score'].mean()\n",
    "                     for val in split_values]\n",
    "axes[1, 1].plot(split_values, mean_scores_split, '^-', linewidth=2, markersize=8, color='darkred')\n",
    "axes[1, 1].set_xlabel('min_samples_split', fontsize=10)\n",
    "axes[1, 1].set_ylabel('Mean CV R¬≤', fontsize=10)\n",
    "axes[1, 1].set_title('Impact of Minimum Samples per Split', fontsize=11, fontweight='bold')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate parameter importance based on performance variance\n",
    "print(\"=== PARAMETER IMPORTANCE RANKING ===\")\n",
    "print(\"(Based on performance variance across parameter values)\\n\")\n",
    "\n",
    "param_importance = {\n",
    "    'n_estimators': estimator_analysis['max'].max() - estimator_analysis['min'].min(),\n",
    "    'max_depth': depth_analysis['max'].max() - depth_analysis['min'].min(),\n",
    "    'max_features': features_analysis['max'].max() - features_analysis['min'].min()\n",
    "}\n",
    "\n",
    "sorted_params = sorted(param_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for rank, (param, impact) in enumerate(sorted_params, 1):\n",
    "    print(f\"{rank}. {param}: Performance range = {impact:.4f}\")\n",
    "    if impact > 0.05:\n",
    "        print(f\"   ‚Üí HIGH IMPACT: Tuning this parameter significantly affects performance\")\n",
    "    elif impact > 0.02:\n",
    "        print(f\"   ‚Üí MODERATE IMPACT: Worth tuning for production optimization\")\n",
    "    else:\n",
    "        print(f\"   ‚Üí LOW IMPACT: Default value acceptable, minimal tuning benefit\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aab619a",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üí° <strong>Tip</strong> (click to expand)</summary>\n",
    "\n",
    "\n",
    "Access grid search results via `pd.DataFrame(grid_search.cv_results_)` which contains all parameter combinations and their scores. Use `.groupby('param_PARAMETER_NAME')['mean_test_score'].agg(['mean', 'std', 'min', 'max'])` to see how each parameter value performs. For visualization, extract unique parameter values and calculate mean scores across all combinations containing each value - this shows the parameter's overall effect. Handle the `None` value in `max_depth` by converting to string for plotting. Calculate parameter importance as `max_score - min_score` across all configurations - large range means the parameter strongly affects performance, small range means it doesn't matter much. Business insight: high-impact parameters (e.g., `max_depth`, `n_estimators`) require careful tuning and justify grid search cost; low-impact parameters (e.g., `min_samples_leaf`) can use default values to simplify the model. If `max_depth` shows minimal impact, the default unlimited depth might be optimal for your data. If `n_estimators` shows strong impact, consider increasing tree count further for production deployment.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2f8362",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ü§´ <strong>Solution</strong> (click to expand)</summary>\n",
    "\n",
    "```python\n",
    "# Extract detailed grid search results\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# Analyze impact of different parameters\n",
    "print(\"=== HYPERPARAMETER SENSITIVITY ANALYSIS ===\\n\")\n",
    "\n",
    "print(\"--- Impact of n_estimators (Number of Trees) ---\")\n",
    "estimator_analysis = results_df.groupby('param_n_estimators')['mean_test_score'].agg(['mean', 'std', 'min', 'max'])\n",
    "print(estimator_analysis.round(4))\n",
    "print()\n",
    "\n",
    "print(\"--- Impact of max_depth (Tree Depth) ---\")\n",
    "depth_analysis = results_df.groupby('param_max_depth')['mean_test_score'].agg(['mean', 'std', 'min', 'max'])\n",
    "print(depth_analysis.round(4))\n",
    "print()\n",
    "\n",
    "print(\"--- Impact of max_features (Feature Randomness) ---\")\n",
    "features_analysis = results_df.groupby('param_max_features')['mean_test_score'].agg(['mean', 'std', 'min', 'max'])\n",
    "print(features_analysis.round(4))\n",
    "print()\n",
    "\n",
    "# Visualize parameter sensitivity\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Panel 1: n_estimators impact\n",
    "param_values = sorted(results_df['param_n_estimators'].unique())\n",
    "mean_scores = [results_df[results_df['param_n_estimators']==val]['mean_test_score'].mean()\n",
    "               for val in param_values]\n",
    "axes[0, 0].plot(param_values, mean_scores, 'o-', linewidth=2, markersize=8, color='darkgreen')\n",
    "axes[0, 0].set_xlabel('n_estimators', fontsize=10)\n",
    "axes[0, 0].set_ylabel('Mean CV R¬≤', fontsize=10)\n",
    "axes[0, 0].set_title('Impact of Number of Trees', fontsize=11, fontweight='bold')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 2: max_depth impact\n",
    "depth_values = sorted([str(x) for x in results_df['param_max_depth'].unique()],\n",
    "                      key=lambda x: float('inf') if x == 'None' else float(x))\n",
    "mean_scores_depth = [results_df[results_df['param_max_depth'].astype(str)==val]['mean_test_score'].mean()\n",
    "                     for val in depth_values]\n",
    "axes[0, 1].plot(range(len(depth_values)), mean_scores_depth, 's-', linewidth=2, markersize=8, color='darkorange')\n",
    "axes[0, 1].set_xticks(range(len(depth_values)))\n",
    "axes[0, 1].set_xticklabels(depth_values)\n",
    "axes[0, 1].set_xlabel('max_depth', fontsize=10)\n",
    "axes[0, 1].set_ylabel('Mean CV R¬≤', fontsize=10)\n",
    "axes[0, 1].set_title('Impact of Maximum Tree Depth', fontsize=11, fontweight='bold')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 3: max_features impact\n",
    "feature_values = sorted([str(x) for x in results_df['param_max_features'].unique()])\n",
    "mean_scores_features = [results_df[results_df['param_max_features'].astype(str)==val]['mean_test_score'].mean()\n",
    "                        for val in feature_values]\n",
    "axes[1, 0].bar(range(len(feature_values)), mean_scores_features, color='teal', alpha=0.7)\n",
    "axes[1, 0].set_xticks(range(len(feature_values)))\n",
    "axes[1, 0].set_xticklabels(feature_values)\n",
    "axes[1, 0].set_xlabel('max_features', fontsize=10)\n",
    "axes[1, 0].set_ylabel('Mean CV R¬≤', fontsize=10)\n",
    "axes[1, 0].set_title('Impact of Feature Randomness', fontsize=11, fontweight='bold')\n",
    "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Panel 4: min_samples_split impact\n",
    "split_values = sorted(results_df['param_min_samples_split'].unique())\n",
    "mean_scores_split = [results_df[results_df['param_min_samples_split']==val]['mean_test_score'].mean()\n",
    "                     for val in split_values]\n",
    "axes[1, 1].plot(split_values, mean_scores_split, '^-', linewidth=2, markersize=8, color='darkred')\n",
    "axes[1, 1].set_xlabel('min_samples_split', fontsize=10)\n",
    "axes[1, 1].set_ylabel('Mean CV R¬≤', fontsize=10)\n",
    "axes[1, 1].set_title('Impact of Minimum Samples per Split', fontsize=11, fontweight='bold')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate parameter importance based on performance variance\n",
    "print(\"\\n=== PARAMETER IMPORTANCE RANKING ===\")\n",
    "print(\"(Based on performance variance across parameter values)\\n\")\n",
    "\n",
    "param_importance = {\n",
    "    'n_estimators': estimator_analysis['max'].max() - estimator_analysis['min'].min(),\n",
    "    'max_depth': depth_analysis['max'].max() - depth_analysis['min'].min(),\n",
    "    'max_features': features_analysis['max'].max() - features_analysis['min'].min()\n",
    "}\n",
    "\n",
    "sorted_params = sorted(param_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for rank, (param, impact) in enumerate(sorted_params, 1):\n",
    "    print(f\"{rank}. {param}: Performance range = {impact:.4f}\")\n",
    "    if impact > 0.05:\n",
    "        print(f\"   ‚Üí HIGH IMPACT: Tuning this parameter significantly affects performance\")\n",
    "        print(f\"   ‚Üí Recommendation: Critical for production optimization\")\n",
    "    elif impact > 0.02:\n",
    "        print(f\"   ‚Üí MODERATE IMPACT: Worth tuning for production optimization\")\n",
    "        print(f\"   ‚Üí Recommendation: Include in hyperparameter search\")\n",
    "    else:\n",
    "        print(f\"   ‚Üí LOW IMPACT: Default value acceptable, minimal tuning benefit\")\n",
    "        print(f\"   ‚Üí Recommendation: Can use default to simplify model\")\n",
    "    print()\n",
    "\n",
    "print(\"=== FINAL RECOMMENDATIONS FOR CAPITAL CITY BIKES ===\")\n",
    "print(f\"‚úì Deploy optimized Random Forest with best parameters: {best_params}\")\n",
    "print(f\"‚úì Achieved test R¬≤ = {test_r2_optimized:.1%} (vs linear baseline ~15%)\")\n",
    "print(f\"‚úì Focus future tuning on parameters showing highest sensitivity\")\n",
    "print(f\"‚úì Model ready for Series B investor demonstrations\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7fde7a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee244f1b",
   "metadata": {},
   "source": [
    "## Summary: Production-Grade Tree-Based Ensemble Modeling for Competitive Advantage\n",
    "\n",
    "**What We've Accomplished:**\n",
    "- **Engineered advanced features** including binary indicators (is_rush_hour, is_weekend), categorical encodings (temp_category, weather_severity), and interaction terms (temp√óhour, workingday√óhour) exposing 17 features designed for tree-based pattern discovery\n",
    "- **Implemented decision trees** with both unlimited and constrained depths, demonstrating severe overfitting (training R¬≤ 99%, test R¬≤ 45%) and bias-variance tradeoff through depth constraints\n",
    "- **Deployed Random Forest ensembles** achieving test R¬≤ ‚âà85% through bootstrap aggregation and feature randomness, dramatically reducing overfitting gap from 54 points (single tree) to ~13 points (ensemble)\n",
    "- **Analyzed feature importance** using MDI and permutation methods, identifying hour, temperature, and workingday interactions as dominant drivers (top 3 features capture ~80% of predictive power)\n",
    "- **Optimized hyperparameters** through GridSearchCV with TimeSeriesSplit, systematically exploring 324 parameter combinations to maximize competitive accuracy\n",
    "\n",
    "**Key Technical Skills Mastered:**\n",
    "- **Feature engineering**: Binary encoding (`.astype(int)`), categorical binning (`pd.cut()`), interaction terms (element-wise multiplication), temporal extraction (`.dt.hour`, `.dt.dayofweek`)\n",
    "- **Decision trees**: DecisionTreeRegressor implementation, tree structure analysis (`.get_depth()`, `.get_n_leaves()`), visualization (`plot_tree()`), overfitting detection (train-test gap calculation)\n",
    "- **Random Forest ensembles**: RandomForestRegressor with n_estimators, max_features='sqrt', bootstrap=True; accessing individual estimators (`.estimators_[i]`), ensemble diversity demonstration\n",
    "- **Feature importance**: MDI extraction (`.feature_importances_`), permutation importance (`permutation_importance()`), cumulative importance analysis, business translation of rankings\n",
    "- **Hyperparameter optimization**: GridSearchCV with TimeSeriesSplit, comprehensive parameter grid definition, best estimator extraction, sensitivity analysis through results DataFrame\n",
    "\n",
    "**Next Steps:**\n",
    "In Module 5, you'll advance to model evaluation and deployment strategies, mastering performance metrics beyond R¬≤ (MAE, MAPE for business reporting), residual analysis for error pattern diagnosis, learning curves for dataset size sufficiency, and production deployment considerations including prediction latency, model versioning, and monitoring strategies.\n",
    "\n",
    "Your Random Forest model transforms Capital City Bikes from linear constraints to non-linear intelligence, achieving 85%+ accuracy that positions them competitively against sophisticated rivals. You've demonstrated the advanced ensemble modeling capabilities, interpretable feature importance analysis, and systematic optimization workflows that distinguish senior ML engineers capable of delivering investor-grade predictive systems!"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
