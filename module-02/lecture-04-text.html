<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Lecture 04: Text - Predictive Modeling MOOC</title>
    
<style>
    body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', 'Helvetica', 'Arial', sans-serif;
        line-height: 1.6;
        max-width: 1200px;
        margin: 0 auto;
        padding: 20px;
        background-color: #f8f9fa;
    }

    .container {
        background-color: white;
        border-radius: 8px;
        padding: 30px;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
    }

    .nav-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 20px 30px;
        border-radius: 8px 8px 0 0;
        margin: -30px -30px 30px -30px;
        display: flex;
        justify-content: space-between;
        align-items: center;
        flex-wrap: wrap;
        gap: 15px;
    }

    .nav-header h1 {
        margin: 0;
        font-size: 1.5rem;
        font-weight: 600;
    }

    .nav-buttons {
        display: flex;
        gap: 10px;
        flex-wrap: wrap;
    }

    .btn {
        display: inline-block;
        padding: 10px 20px;
        text-decoration: none;
        font-weight: 600;
        border-radius: 6px;
        transition: all 0.3s ease;
        font-size: 0.9rem;
    }

    .btn-colab {
        background-color: #f9ab00;
        color: #1a1a1a;
        border: 2px solid #f9ab00;
    }

    .btn-colab:hover {
        background-color: #ff9900;
        border-color: #ff9900;
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(249, 171, 0, 0.3);
    }

    .btn-github {
        background-color: transparent;
        color: white;
        border: 2px solid white;
    }

    .btn-github:hover {
        background-color: white;
        color: #667eea;
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(255, 255, 255, 0.3);
    }

    .jupyter-content {
        margin-top: 20px;
    }

    /* Notebook cell styling */
    div.cell {
        margin-bottom: 1.5rem;
    }

    div.input_area {
        border-left: 3px solid #667eea;
        background-color: #f8f9fa;
        padding: 10px;
        border-radius: 4px;
    }

    div.output_area {
        padding: 10px;
        border-left: 3px solid #28a745;
        background-color: #f8f9fa;
        border-radius: 4px;
        margin-top: 10px;
    }

    /* Code highlighting */
    .highlight {
        background-color: #f8f9fa;
        border-radius: 4px;
    }

    /* Responsive design */
    @media (max-width: 768px) {
        body {
            padding: 10px;
        }

        .container {
            padding: 15px;
        }

        .nav-header {
            padding: 15px;
            margin: -15px -15px 15px -15px;
        }

        .nav-header h1 {
            font-size: 1.2rem;
        }

        .nav-buttons {
            width: 100%;
            justify-content: center;
        }
    }
</style>

</head>
<body>
    <div class="container">
        <div class="nav-header">
            <h1>Lecture 04: Text</h1>
            <div class="nav-buttons">
                <a href="https://colab.research.google.com/github/pmarcelino/predictive-modeling/blob/main/04-implementation/module-02/lecture-04-text.ipynb" target="_blank" rel="noopener" class="btn btn-colab">
                    ▶ Open in Colab
                </a>
                <a href="https://github.com/pmarcelino/predictive-modeling/blob/main/04-implementation/module-02/lecture-04-text.ipynb" target="_blank" rel="noopener" class="btn btn-github">
                    📂 View on GitHub
                </a>
            </div>
        </div>
        <div class="jupyter-content">

<main>
<div class="border-box-sizing" id="notebook" tabindex="-1">
<div class="container" id="notebook-container">
<div class="cell border-box-sizing text_cell rendered" id="cell-id=9114bc3a"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Lecture-4:-Data-Quality-&amp;-Cleaning-Essentials---Professional-Data-Preparation">Lecture 4: Data Quality &amp; Cleaning Essentials - Professional Data Preparation<a class="anchor-link" href="#Lecture-4:-Data-Quality-&amp;-Cleaning-Essentials---Professional-Data-Preparation">¶</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=9cd24518"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Learning-Objectives">Learning Objectives<a class="anchor-link" href="#Learning-Objectives">¶</a></h2><p>By the end of this lecture, you will be able to:</p>
<ul>
<li>Identify and categorize different types of data quality issues in transportation datasets</li>
<li>Apply systematic approaches to detect inconsistencies, missing data, and outliers</li>
<li>Choose appropriate strategies for handling data quality issues</li>
<li>Implement professional data cleaning workflows using pandas methods</li>
</ul>
<hr/>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=53b23ec8"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="1.-The-Reality-of-Real-World-Transportation-Data">1. The Reality of Real-World Transportation Data<a class="anchor-link" href="#1.-The-Reality-of-Real-World-Transportation-Data">¶</a></h2><p>As your consulting work progresses, you'll quickly discover a fundamental truth: <strong>real-world data is messy</strong>. The clean datasets you see in textbooks don't exist in professional practice. Your bike-sharing client's data comes from sensors that malfunction, weather stations that go offline, and databases that occasionally corrupt records.</p>
<p>This messiness isn't just a technical inconvenience - it's a business-critical challenge. <strong>Poor data quality can lead to incorrect demand predictions</strong>, resulting in empty bike stations when customers need them or overflow situations where returning bikes becomes impossible. These operational failures directly impact customer satisfaction and revenue.</p>
<p>Your role as a professional consultant is to <strong>transform messy, incomplete data into reliable foundations for business decision-making</strong>. This requires systematic approaches, clear documentation, and transparent communication about data limitations and cleaning procedures.</p>
<p>After building fluency with pandas data structures, indexing, grouping, and datetime handling in Lecture 3, we now put those skills to work. In this lecture, we use them to run a fast, defensible data quality triage before modeling — the same practical checks you’ll rely on in professional projects.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=05c955ed"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.-Common-Data-Quality-Issues-in-Transportation-Systems">2. Common Data Quality Issues in Transportation Systems<a class="anchor-link" href="#2.-Common-Data-Quality-Issues-in-Transportation-Systems">¶</a></h2><p>Messiness isn’t a single problem—it comes in many forms, each affecting your analysis in different ways. As a consultant, your job is to <strong>recognize these issues early</strong> and decide how to handle them before they undermine your predictions.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=c9462f9a"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="2.1.-Understanding-Data-Quality-Dimensions">2.1. Understanding Data Quality Dimensions<a class="anchor-link" href="#2.1.-Understanding-Data-Quality-Dimensions">¶</a></h3><p>Data quality exists along multiple dimensions, each of which can influence your analysis in different ways. Let’s break down the five most important ones and see how they appear in transportation data:</p>
<ol>
<li><p><strong>Completeness</strong></p>
<ul>
<li><em>Definition:</em> Whether all expected values are present in the dataset.</li>
<li><em>Why it matters:</em> Missing values create blind spots, especially when the missingness is not random.</li>
<li><em>Example:</em> If bike-sharing sensors fail during storms, you may lose exactly the data needed to understand weather impacts on demand.</li>
</ul>
</li>
<li><p><strong>Accuracy</strong></p>
<ul>
<li><em>Definition:</em> The extent to which recorded values reflect reality.</li>
<li><em>Why it matters:</em> Inaccurate values can mislead both descriptive analysis and predictive models.</li>
<li><em>Example:</em> A temperature of -50°C recorded in Washington D.C. in July is a clear sensor error that could confuse demand models.</li>
</ul>
</li>
<li><p><strong>Consistency</strong></p>
<ul>
<li><em>Definition:</em> Whether data follows uniform formats, units, and scales.</li>
<li><em>Why it matters:</em> Inconsistent formats can corrupt calculations and comparisons.</li>
<li><em>Example:</em> Mixing Celsius and Fahrenheit in the same column, or having timestamps in multiple formats, leads to corrupted analysis.</li>
</ul>
</li>
<li><p><strong>Validity</strong></p>
<ul>
<li><em>Definition:</em> Whether values fall within logical or physically possible ranges.</li>
<li><em>Why it matters:</em> Invalid data points indicate measurement or collection errors.</li>
<li><em>Example:</em> Negative bike counts or humidity above 100% are impossible values that reveal collection problems.</li>
</ul>
</li>
<li><p><strong>Uniqueness</strong></p>
<ul>
<li><em>Definition:</em> Whether each observation is recorded only once.</li>
<li><em>Why it matters:</em> Duplicate records inflate usage counts and distort demand predictions.</li>
<li><em>Example:</em> If the same rental transaction is logged twice, it looks like demand is higher than it really was.</li>
</ul>
</li>
</ol>
<p>Together, these five dimensions reveal how data quality problems can undermine predictions in different ways. Recognizing these distinct aspects helps you target specific problems rather than applying generic "data cleaning" approaches.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=f37bb73b"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="2.2.-Missing-Data-Patterns-and-Business-Implications">2.2. Missing Data Patterns and Business Implications<a class="anchor-link" href="#2.2.-Missing-Data-Patterns-and-Business-Implications">¶</a></h3><p>Not all missing data is created equal. In transportation systems, gaps in the dataset often occur under very specific conditions—the very conditions you want to analyze. Understanding when and why data goes missing helps you choose the right handling strategies and communicate risks to clients.</p>
<p><strong>Weather-Driven Data Loss</strong></p>
<ul>
<li>The most common pattern involves sensor failures during extreme weather events. Storms, heavy rain, and temperature extremes can knock out monitoring equipment precisely when weather has the strongest influence on bike usage. This creates a double problem: you lose data exactly when you need it most, and standard statistical assumptions about "random" missingness don't apply.</li>
</ul>
<p><strong>Operational and Maintenance Gaps</strong></p>
<ul>
<li>Planned maintenance creates predictable but significant gaps in transportation data. These periods often overlap with major infrastructure changes—like opening new stations or updating software systems—meaning that ignoring the operational context could hide important business insights about system growth and performance.</li>
</ul>
<p><strong>Network Effects and Cascade Failures</strong></p>
<ul>
<li>Transportation systems are interconnected. When a high-demand station goes offline, neighboring stations typically experience unusual demand spikes. Without data from the offline station, it becomes difficult to distinguish between genuine demand growth and temporary displacement of riders to nearby locations.</li>
</ul>
<p><strong>Peak Period Vulnerabilities</strong></p>
<ul>
<li>Finally, data failures during rush hours pose special challenges because peak-period predictions drive critical business decisions. Missing data during these high-stakes periods requires more sophisticated handling strategies than gaps occurring during quiet off-peak hours when the business impact is minimal.</li>
</ul>
<p>These four patterns demonstrate why missing data analysis goes beyond simple counts and percentages. Each pattern creates specific risks for demand forecasting and requires tailored handling strategies. By understanding when and why data disappears, you can make informed decisions about imputation, communicate limitations clearly to clients, and avoid building models on unreliable foundations.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=be5e1cd4"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="3.-Data-Quality-Assessment-Process">3. Data Quality Assessment Process<a class="anchor-link" href="#3.-Data-Quality-Assessment-Process">¶</a></h2><p>As a consultant, clients will expect you to follow a systematic, defensible process for data quality assessment — not ad-hoc checking. The 4-step process we'll use gives you a professional framework that you can explain and justify to any client:</p>
<ol>
<li><strong>Quick Data Quality Checks</strong> – your first diagnostic scan to flag obvious issues.</li>
<li><strong>Time Series Integrity Check</strong> – systematic analysis of temporal continuity.</li>
<li><strong>Outlier Detection</strong> – comprehensive detection of anomalies.</li>
<li><strong>Missing Data Detection</strong> – detailed analysis of completeness.</li>
</ol>
<p>This systematic approach demonstrates expertise and builds client confidence from day one. Steps 1, 3, and 4 apply universally across domains. Step 2 becomes critical for time-series data, like the one we usually see in transportation problems.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=94637644"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="3.1.-Quick-Data-Quality-Checks">3.1. Quick Data Quality Checks<a class="anchor-link" href="#3.1.-Quick-Data-Quality-Checks">¶</a></h3><p>Quick data quality checks are rapid diagnostic scans that assess whether a dataset is fundamentally sound before investing time in detailed analysis or modeling.</p>
<p>Think of this like a consultant's "triage" — in just a few minutes, you want to know whether the dataset looks broadly reliable, where the biggest risks lie, and which areas deserve closer investigation. When you receive a new dataset from a client, this scan is your first step, not modeling.</p>
<p>These lightweight checks flag obvious issues across structure, value ranges, and cross-variable plausibility. We won't yet explain problems in depth or attempt fixes — that comes later. The goal is rapid risk assessment.</p>
<p>Our quick quality assessment will be based on three steps:</p>
<ol>
<li>Structural Snapshot</li>
<li>Value Sanity Checks</li>
<li>Cross-Variable Plausibility</li>
</ol>
<p><strong>1. Structural Snapshot</strong></p>
<p>The first thing we do is take a <strong>structural snapshot</strong> of the dataset: how many rows and columns it has, and whether the variables are of the expected type. This step sounds simple, but it’s one of the fastest ways to detect import errors, unexpected row counts, or inconsistencies in data types — all of which can indicate bigger problems lurking beneath the surface.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered" id="cell-id=8fe22df6">
<div class="input">
<div class="prompt input_prompt">In [1]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="c1"># Load the Washington D.C. bike-sharing dataset (intentionally messy version)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">"https://raw.githubusercontent.com/pmarcelino/predictive-modeling/main/datasets/dataset-teaching-lec-04.csv"</span><span class="p">)</span>

<span class="c1"># Check dataset dimensions and data types</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Rows: </span><span class="si">{</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">, Columns: </span><span class="si">{</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">info</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Rows: 10886, Columns: 12
&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 10886 entries, 0 to 10885
Data columns (total 12 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   datetime    10886 non-null  object 
 1   season      10886 non-null  int64  
 2   holiday     10341 non-null  float64
 3   workingday  10886 non-null  int64  
 4   weather     10815 non-null  float64
 5   temp        10814 non-null  float64
 6   atemp       10814 non-null  float64
 7   humidity    10814 non-null  float64
 8   windspeed   10814 non-null  float64
 9   casual      10740 non-null  float64
 10  registered  10740 non-null  float64
 11  count       10740 non-null  float64
dtypes: float64(9), int64(2), object(1)
memory usage: 1020.7+ KB
None
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=a687a7c6"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote>
<p><strong>Note:</strong> You may have noticed something unusual here: the results don't look exactly like what we saw in the previous lecture. That's intentional. From this point forward, we'll sometimes work with a slightly modified version of the Washington D.C. dataset. We've made it "messy" on purpose so you can practice handling real-world problems. As a consultant, you'll rarely get a dataset that's perfectly clean — each phase of the course will bring new challenges for you to detect and resolve.</p>
</blockquote>
<p>When we run this quick check, a few important concerns stand out immediately:</p>
<ul>
<li>The <strong><code>holiday</code> column has missing values</strong>. This means that not every day is properly labeled as a holiday or not — a detail that could easily distort demand forecasts, since holiday patterns differ sharply from regular weekdays.</li>
<li>The <strong>weather-related variables</strong> such as <code>temp</code>, <code>humidity</code>, and <code>windspeed</code> also contain gaps. Because these are some of the most important explanatory variables in our forecasting model, missingness here reduces our ability to explain variation in bike rentals.</li>
<li>Most critically, the <strong><code>count</code> column — our target variable — is missing in several rows</strong>. This is a red flag: every missing entry in <code>count</code> means lost training data, and the reliability of our model hinges on how much usable demand history we have.</li>
</ul>
<p>This single, simple scan already tells us that the dataset cannot be used “as is” for modeling. More importantly, it shows why <strong>structural checks are powerful</strong>: with just one command, we’ve uncovered problems in both our explanatory variables and our target.</p>
<p>This is exactly the kind of insight to highlight at the project start: <em>"Before we can move into forecasting, we've already identified major gaps in the dataset that could affect both explanatory power and prediction accuracy."</em></p>
<p><strong>2. Value Sanity Checks</strong></p>
<p>After confirming the dataset’s structure, the next step is to ask: <em>“Do the values themselves make sense?”</em></p>
<p>Every variable has <strong>natural boundaries</strong> defined by either business rules or physical limits:</p>
<ul>
<li>Bike rentals cannot be negative.</li>
<li>Humidity must fall between 0% and 100%.</li>
<li>Local temperatures should stay within climate-appropriate ranges.</li>
</ul>
<p>Values that fall outside these ranges are not just unusual — they are almost always errors caused by faulty sensors, bad data entry, or processing mistakes.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered" id="cell-id=73bb03fa">
<div class="input">
<div class="prompt input_prompt">In [2]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="c1"># Basic range checks</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Negative rentals:"</span><span class="p">,</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">"count"</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Humidity out of range:"</span><span class="p">,</span> <span class="p">((</span><span class="n">df</span><span class="p">[</span><span class="s2">"humidity"</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">"humidity"</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">100</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Temperature min/max:"</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s2">"temp"</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">df</span><span class="p">[</span><span class="s2">"temp"</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Negative rentals: 6
Humidity out of range: 10
Temperature min/max: 0.82 100.0
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=6b55987b"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Running these quick checks reveals three immediate red flags:</p>
<ul>
<li>We find <strong>6 cases of negative rentals</strong>, which is logically impossible — you can’t rent fewer than zero bikes. This is most likely a logging or entry error.</li>
<li>We spot <strong>10 humidity values above 100%</strong>, which is physically impossible. This usually points to a faulty sensor reading or an ingestion problem.</li>
<li>Finally, the <strong>temperature maximum is close to 100°C</strong>. While summers in Washington D.C. can be hot, they certainly don’t reach boiling point! This extreme value is almost certainly an error that could distort averages or mislead a forecasting model.</li>
</ul>
<p>Together, these findings show why <strong>range validation is essential</strong>. With a few simple checks, we can identify values that clearly break real-world rules — and if left undetected, they could slip into analysis, biasing results and damaging credibility with clients.</p>
<p>This step builds trust: you demonstrate that you're not just running models blindly, but verifying whether the data itself reflects reality.</p>
<p><strong>3. Cross-Variable Plausibility</strong></p>
<p>Numbers can look fine in isolation but make no sense once you compare them across variables. That’s why a good quick check also includes a <strong>plausibility scan across related variables</strong>. In transportation data, the most important relationship to test is usually between <strong>demand</strong> and <strong>context variables</strong> like weather.</p>
<p>For example, common sense (and business experience) tells us that <strong>bike rentals should fall when weather conditions worsen</strong>. If the dataset shows the opposite, that’s a red flag.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered" id="cell-id=6ec34054">
<div class="input">
<div class="prompt input_prompt">In [3]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="c1"># Quick plausibility check: average rentals by weather condition</span>
<span class="n">avg_rentals_by_weather</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">"weather"</span><span class="p">)[</span><span class="s2">"count"</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">avg_rentals_by_weather</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>weather
1.0    208.579986
2.0    182.556386
3.0    119.877214
4.0    628.562500
Name: count, dtype: float64
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=b6d85939"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote>
<p><strong>Note:</strong> The weather variable is coded as follows:</p>
<ul>
<li><strong>1</strong>: Clear, Few clouds, Partly cloudy</li>
<li><strong>2</strong>: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist</li>
<li><strong>3</strong>: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds</li>
<li><strong>4</strong>: Heavy Rain + Ice Pellets + Thunderstorm + Mist, Snow + Fog</li>
</ul>
</blockquote>
<p>At first glance, the results follow expectations:</p>
<ul>
<li>Rentals are <strong>highest on clear days (weather = 1)</strong>.</li>
<li>They gradually decrease as conditions worsen to misty or light rain.</li>
</ul>
<p>But the final category is suspicious. Under <strong>heavy rain or storms (weather = 4)</strong>, the dataset shows an <strong>average of more than 600 rentals per hour</strong> — even higher than on sunny days.</p>
<p>This makes little business sense: real-world demand should drop sharply in severe weather, not skyrocket. Such an inconsistency usually points to:</p>
<ul>
<li><strong>Mislabelled weather codes</strong>, or</li>
<li>A <strong>misalignment between weather feeds and rental logs</strong>.</li>
</ul>
<p>Left uncorrected, such errors could lead to false conclusions like <em>"bike demand is resilient during storms"</em> — which in turn could drive poor operational decisions, such as overstocking bikes or overscheduling staff during extreme weather events.</p>
<p>This kind of cross-variable check is a reminder: <strong>some errors only appear when you look at relationships, not just single columns</strong>. That’s why you should test whether the data’s “story” matches real-world logic.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=1b16d761"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="3.2.-Temporal-Continuity-Check">3.2. Temporal Continuity Check<a class="anchor-link" href="#3.2.-Temporal-Continuity-Check">¶</a></h3><p>Temporal continuity refers to whether your time-series data has a complete, consistent timeline without gaps, duplicates, or misaligned sequences.</p>
<p>Transportation data is inherently time-based. If the timeline itself is broken, then any further cleaning, imputation, or modeling will rest on shaky foundations. Missing hours create false patterns, duplicates skew averages, and misaligned sequences break seasonal analysis.</p>
<p>Before we tackle outliers or missing values, we must verify the timeline's integrity to ensure reliable foundations for all subsequent work. To do so, we run a timeline diagnostic that tells us:</p>
<ul>
<li>The first and last timestamp in the dataset.</li>
<li>How many hours should exist in that range.</li>
<li>How many unique hours actually exist.</li>
<li>How many are missing.</li>
<li>How many duplicate rows we have for the same hour.</li>
</ul>
<p>This gives us a quick sense of whether the dataset is complete and well-aligned, or whether we’re missing entire blocks of time.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered" id="cell-id=869db380">
<div class="input">
<div class="prompt input_prompt">In [4]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="c1"># Ensure datetime is properly parsed</span>
<span class="n">data_path</span> <span class="o">=</span> <span class="s2">"https://raw.githubusercontent.com/pmarcelino/predictive-modeling/main/datasets/dataset-teaching-lec-04.csv"</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">data_path</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s2">"datetime"</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">"datetime"</span><span class="p">],</span> <span class="n">errors</span><span class="o">=</span><span class="s2">"coerce"</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s2">"datetime"</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Identify coverage</span>
<span class="n">t_min</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">"datetime"</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
<span class="n">t_max</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">"datetime"</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>

<span class="c1"># Duplicated timestamps</span>
<span class="n">n_dup_rows</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">duplicated</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s2">"datetime"</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

<span class="c1"># Build expected hourly range</span>
<span class="n">expected</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">date_range</span><span class="p">(</span><span class="n">t_min</span><span class="p">,</span> <span class="n">t_max</span><span class="p">,</span> <span class="n">freq</span><span class="o">=</span><span class="s2">"h"</span><span class="p">)</span>
<span class="n">actual</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Index</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">"datetime"</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>

<span class="n">n_expected</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">expected</span><span class="p">)</span>
<span class="n">n_actual</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">actual</span><span class="p">)</span>
<span class="n">n_missing_hours</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">expected</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span><span class="n">actual</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"=== Timeline quick check ==="</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"time_min:"</span><span class="p">,</span> <span class="n">t_min</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"time_max:"</span><span class="p">,</span> <span class="n">t_max</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"expected_hours:"</span><span class="p">,</span> <span class="n">n_expected</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"present_unique_hours:"</span><span class="p">,</span> <span class="n">n_actual</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"missing_hours:"</span><span class="p">,</span> <span class="n">n_missing_hours</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"duplicate_rows:"</span><span class="p">,</span> <span class="n">n_dup_rows</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>=== Timeline quick check ===
time_min: 2011-01-01 00:00:00
time_max: 2012-12-19 23:00:00
expected_hours: 17256
present_unique_hours: 10862
missing_hours: 6394
duplicate_rows: 24
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=630d3fd2"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As we can see, between January 2011 and December 2012, the dataset should contain <strong>17 256 hourly rows</strong>. In reality, it only contains <strong>10 862 unique hours</strong>, leaving <strong>6 394 hours missing</strong>. That's more than a third of the timeline absent — a major structural gap. We also see <strong>24 duplicate rows</strong>, meaning some hours are represented more than once.</p>
<p>This is a critical insight: the raw data cannot be trusted as a continuous timeline. Large gaps undermine seasonal analysis, and duplicates risk double-counting demand. Before any modeling, we need to fix both problems. We will show how to do that in <a href="#4-data-cleaning-strategies-and-implementation">Chapter 4</a>.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=617e069a"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="3.3.-Outlier-Detection">3.3. Outlier Detection<a class="anchor-link" href="#3.3.-Outlier-Detection">¶</a></h3><p>Outlier detection identifies data points that deviate significantly from the expected pattern — values that are unusually high, unusually low, or inconsistent with the rest of the dataset.</p>
<p>In transportation data, outliers can represent legitimate extreme events (like snowstorms causing demand drops), data collection errors (like negative bike rentals), or operational anomalies (like maintenance affecting normal patterns). Each type requires different treatment strategies.</p>
<p>The goal is not just to detect outliers, but to classify them correctly so that legitimate events are preserved while errors are corrected. This ensures models learn from real patterns rather than data quality issues.</p>
<p>Now that we understand what outliers are, let’s look at the different ways to detect them. Outlier detection methods generally fall into three categories:</p>
<ol>
<li>Statistical Methods</li>
<li>Business Logic Methods</li>
<li>Temporal Methods</li>
</ol>
<p><strong>1. Statistical Methods</strong></p>
<p>Statistical methods use mathematical formulas to identify unusual values. They don’t require prior knowledge of the transportation system - they just look at how far a data point is from what is “normal” in the dataset.</p>
<p>There are several statistical approaches, such as:</p>
<ul>
<li>Z-Score Analysis</li>
<li>Interquartile Range (IQR) Method</li>
<li>Modified Z-Score</li>
</ul>
<p>In this lecture, we will focus on just one example: <strong>Z-Score Analysis</strong>.</p>
<p>A <strong>Z-score</strong> tells us how many “standard steps” (standard deviations) a data point is away from the average.</p>
<p>$$
Z = \frac{x - \mu}{\sigma}
$$</p>
<p>where:</p>
<ul>
<li>$x$ = the value we’re checking</li>
<li>$\mu$ = the mean (average) of the data</li>
<li>$\sigma$ = the standard deviation (how spread out the data is)</li>
</ul>
<p>Think of the average bike rentals per day like the “center of gravity” of the data. Most days will be close to that average. The Z-score is like a distance meter: it tells us how far a particular day is from the typical pattern.</p>
<ul>
<li>A Z-score of <strong>0</strong> → exactly average.</li>
<li>A Z-score of <strong>+2</strong> → two steps above average (busier than normal).</li>
<li>A Z-score of <strong>–3</strong> → three steps below average (quieter than normal).</li>
</ul>
<p>When a Z-score is bigger than 3 or smaller than –3, the value is far enough from the average that we should pause and ask: <em>Is this a real event, or is it an error?</em></p>
<p>We use Z-scores because they:</p>
<ul>
<li><strong>Standardize values</strong> so we can compare across variables.</li>
<li><strong>Give a simple rule of thumb</strong>: beyond 3 = unusual.</li>
<li><strong>Provide a quick first filter</strong> before applying more advanced techniques.</li>
</ul>
<p>Let’s see how this works in practice using the Washington D.C. bike-sharing dataset. We’ll calculate the Z-scores for daily demand (<code>count</code>) and flag potential outliers.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered" id="cell-id=a0b7da97">
<div class="input">
<div class="prompt input_prompt">In [5]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># Load the Washington D.C. bike-sharing dataset</span>
<span class="n">data_path</span> <span class="o">=</span> <span class="s2">"https://raw.githubusercontent.com/pmarcelino/predictive-modeling/main/datasets/dataset-teaching-lec-04.csv"</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">data_path</span><span class="p">)</span>

<span class="c1"># Convert datetime column to pandas datetime type</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'datetime'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'datetime'</span><span class="p">])</span>

<span class="c1"># Aggregate rentals by day</span>
<span class="n">daily_rentals</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'datetime'</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">date</span><span class="p">)[</span><span class="s1">'count'</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>

<span class="c1"># Calculate mean and std</span>
<span class="n">mean</span> <span class="o">=</span> <span class="n">daily_rentals</span><span class="p">[</span><span class="s1">'count'</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">std</span> <span class="o">=</span> <span class="n">daily_rentals</span><span class="p">[</span><span class="s1">'count'</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>

<span class="c1"># Compute Z-scores</span>
<span class="n">daily_rentals</span><span class="p">[</span><span class="s1">'z_score'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">daily_rentals</span><span class="p">[</span><span class="s1">'count'</span><span class="p">]</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">std</span>

<span class="c1"># Flag outliers (|Z| &gt; 3)</span>
<span class="n">outliers</span> <span class="o">=</span> <span class="n">daily_rentals</span><span class="p">[</span><span class="n">daily_rentals</span><span class="p">[</span><span class="s1">'z_score'</span><span class="p">]</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">3</span><span class="p">]</span>

<span class="n">outliers</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt output_prompt">Out[5]:</div>
<div class="output_html rendered_html output_subarea output_execute_result"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th></th>
<th>datetime</th>
<th>count</th>
<th>z_score</th>
</tr>
</thead>
<tbody>
<tr>
<th>90</th>
<td>2011-05-15</td>
<td>21301.0</td>
<td>7.389985</td>
</tr>
<tr>
<th>191</th>
<td>2011-11-03</td>
<td>21887.0</td>
<td>7.649137</td>
</tr>
</tbody>
</table>
</div></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=1f1a4f55"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Both May 15 and November 3 show exceptionally high rental counts, far beyond typical daily demand. These are unlikely to be ordinary fluctuations. They could represent special city-wide events or anomalies in how trips were logged. As consultants, we need to cross-check these dates with event calendars and system logs to confirm whether these spikes reflect genuine demand or possible data quality issues.</p>
<p><strong>2. Business Logic Methods</strong></p>
<p>While statistical methods rely purely on mathematical rules, <strong>business logic methods</strong> use knowledge of the system and its physical constraints to detect outliers. Instead of asking, “Does this number look statistically unusual?”, we ask, “Is this number even possible given how the transportation system works?”</p>
<p>Business logic methods build rules like these based on:</p>
<ul>
<li><strong>Physical constraints</strong>: e.g., a bike station cannot have negative bikes, nor can it rent more bikes than its maximum capacity.</li>
<li><strong>Historical ranges</strong>: e.g., demand has never exceeded 1,200 rentals in a day; a value above this threshold is suspicious.</li>
<li><strong>Cross-variable checks</strong>: e.g., it shouldn’t be possible to record “heavy rain” alongside “record-high bike usage.”</li>
</ul>
<p>Let's apply business logic to detect outliers by checking for physical constraint violations in wind speed measurements.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered" id="cell-id=baf99b63">
<div class="input">
<div class="prompt input_prompt">In [6]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="c1"># Load the Washington D.C. bike-sharing dataset</span>
<span class="n">data_path</span> <span class="o">=</span> <span class="s2">"https://raw.githubusercontent.com/pmarcelino/predictive-modeling/main/datasets/dataset-teaching-lec-04.csv"</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">data_path</span><span class="p">)</span>

<span class="c1"># Convert datetime column to pandas datetime type</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'datetime'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'datetime'</span><span class="p">])</span>

<span class="c1"># Check for physical constraint violations in windspeed</span>
<span class="n">invalid_windspeed</span> <span class="o">=</span> <span class="n">df</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="s1">'windspeed'</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'windspeed'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">60</span><span class="p">)]</span>

<span class="n">invalid_windspeed</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt output_prompt">Out[6]:</div>
<div class="output_html rendered_html output_subarea output_execute_result"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th></th>
<th>datetime</th>
<th>season</th>
<th>holiday</th>
<th>workingday</th>
<th>weather</th>
<th>temp</th>
<th>atemp</th>
<th>humidity</th>
<th>windspeed</th>
<th>casual</th>
<th>registered</th>
<th>count</th>
</tr>
</thead>
<tbody>
<tr>
<th>1077</th>
<td>2011-03-09 10:00:00</td>
<td>1</td>
<td>0.0</td>
<td>1</td>
<td>2.0</td>
<td>12.30</td>
<td>14.395</td>
<td>75.0</td>
<td>200.0</td>
<td>8.0</td>
<td>49.0</td>
<td>57.0</td>
</tr>
<tr>
<th>1159</th>
<td>2011-03-12 23:00:00</td>
<td>1</td>
<td>0.0</td>
<td>0</td>
<td>1.0</td>
<td>15.58</td>
<td>19.695</td>
<td>66.0</td>
<td>200.0</td>
<td>11.0</td>
<td>38.0</td>
<td>49.0</td>
</tr>
<tr>
<th>1991</th>
<td>2011-05-09 21:00:00</td>
<td>2</td>
<td>0.0</td>
<td>1</td>
<td>1.0</td>
<td>21.32</td>
<td>25.000</td>
<td>59.0</td>
<td>200.0</td>
<td>28.0</td>
<td>128.0</td>
<td>156.0</td>
</tr>
<tr>
<th>2730</th>
<td>2011-07-02 16:00:00</td>
<td>3</td>
<td>0.0</td>
<td>0</td>
<td>1.0</td>
<td>36.08</td>
<td>37.120</td>
<td>22.0</td>
<td>200.0</td>
<td>206.0</td>
<td>192.0</td>
<td>398.0</td>
</tr>
<tr>
<th>4820</th>
<td>2011-11-14 22:00:00</td>
<td>4</td>
<td>0.0</td>
<td>1</td>
<td>1.0</td>
<td>23.78</td>
<td>27.275</td>
<td>56.0</td>
<td>200.0</td>
<td>17.0</td>
<td>96.0</td>
<td>113.0</td>
</tr>
</tbody>
</table>
</div></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=d0d31684"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The flagged records show windspeed values of <code>200.0</code>, which are far beyond any physically possible measurement for this system. These values clearly indicate sensor or recording errors rather than real-world weather conditions. If left uncorrected, they could distort downstream models, for example by falsely associating extreme winds with normal rental demand.</p>
<p><strong>3. Temporal Methods</strong></p>
<p>Transportation data is inherently tied to <strong>time</strong>. Unlike static datasets, values change depending on the hour, day, season, or long-term trends. <strong>Temporal outlier detection methods</strong> focus on identifying unusual data points that break these expected time-based patterns. For example:</p>
<ul>
<li>A sudden drop in rentals during a weekday morning rush hour might indicate a system outage.</li>
<li>A sharp jump in rentals during winter could mean a special event.</li>
<li>A long-term shift in demand may signal that the system has grown or changed in some way.</li>
</ul>
<p>Some common temporal approaches include:</p>
<ul>
<li><strong>Change Point Detection</strong>: Identifying sudden structural shifts in the data (e.g., a new station or policy).</li>
<li><strong>Seasonal Anomaly Detection</strong>: Checking if values align with expected seasonal patterns.</li>
<li><strong>Trend Deviation Analysis</strong>: Comparing current values to long-term growth or decline.</li>
</ul>
<p>Let's see an example of a seasonal anomaly detection. We'll identify days where demand deviates significantly from seasonal expectations by comparing winter and summer rental patterns, then flagging winter days with unusually high demand and summer days with unusually low demand.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered" id="cell-id=38648aaf">
<div class="input">
<div class="prompt input_prompt">In [7]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="c1"># Load the Washington D.C. bike-sharing dataset</span>
<span class="n">data_path</span> <span class="o">=</span> <span class="s2">"https://raw.githubusercontent.com/pmarcelino/predictive-modeling/main/datasets/dataset-teaching-lec-04.csv"</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">data_path</span><span class="p">)</span>

<span class="c1"># Convert datetime and build daily_rentals with a month column</span>
<span class="n">df</span><span class="p">[</span><span class="s2">"datetime"</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">"datetime"</span><span class="p">])</span>
<span class="n">daily_rentals</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">"datetime"</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">date</span><span class="p">)[</span><span class="s2">"count"</span><span class="p">]</span>
      <span class="o">.</span><span class="n">sum</span><span class="p">()</span>
      <span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
      <span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s2">"datetime"</span><span class="p">:</span> <span class="s2">"date"</span><span class="p">})</span>
<span class="p">)</span>
<span class="n">daily_rentals</span><span class="p">[</span><span class="s2">"date"</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">daily_rentals</span><span class="p">[</span><span class="s2">"date"</span><span class="p">])</span>
<span class="n">daily_rentals</span><span class="p">[</span><span class="s2">"month"</span><span class="p">]</span> <span class="o">=</span> <span class="n">daily_rentals</span><span class="p">[</span><span class="s2">"date"</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">month</span>

<span class="c1"># Define "winter" as Dec-Feb and "summer" as Jun-Aug</span>
<span class="n">winter_months</span> <span class="o">=</span> <span class="p">[</span><span class="mi">12</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">summer_months</span> <span class="o">=</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>

<span class="n">winter_avg</span> <span class="o">=</span> <span class="n">daily_rentals</span><span class="p">[</span><span class="n">daily_rentals</span><span class="p">[</span><span class="s1">'month'</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">winter_months</span><span class="p">)][</span><span class="s1">'count'</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">summer_avg</span> <span class="o">=</span> <span class="n">daily_rentals</span><span class="p">[</span><span class="n">daily_rentals</span><span class="p">[</span><span class="s1">'month'</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">summer_months</span><span class="p">)][</span><span class="s1">'count'</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="c1"># Flag unusual winter days (too close to summer levels)</span>
<span class="n">winter_anomalies</span> <span class="o">=</span> <span class="n">daily_rentals</span><span class="p">[</span>
    <span class="p">(</span><span class="n">daily_rentals</span><span class="p">[</span><span class="s1">'month'</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">winter_months</span><span class="p">))</span> <span class="o">&amp;</span> 
    <span class="p">(</span><span class="n">daily_rentals</span><span class="p">[</span><span class="s1">'count'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">summer_avg</span> <span class="o">*</span> <span class="mf">0.8</span><span class="p">)</span>
<span class="p">]</span>

<span class="c1"># Flag unusual summer days (too close to winter levels)</span>
<span class="n">summer_anomalies</span> <span class="o">=</span> <span class="n">daily_rentals</span><span class="p">[</span>
    <span class="p">(</span><span class="n">daily_rentals</span><span class="p">[</span><span class="s1">'month'</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">summer_months</span><span class="p">))</span> <span class="o">&amp;</span> 
    <span class="p">(</span><span class="n">daily_rentals</span><span class="p">[</span><span class="s1">'count'</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">winter_avg</span> <span class="o">*</span> <span class="mf">1.2</span><span class="p">)</span>
<span class="p">]</span>

<span class="n">seasonal_anomalies</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">winter_anomalies</span><span class="p">,</span> <span class="n">summer_anomalies</span><span class="p">])</span>
<span class="n">seasonal_anomalies</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt output_prompt">Out[7]:</div>
<div class="output_html rendered_html output_subarea output_execute_result"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th></th>
<th>date</th>
<th>count</th>
<th>month</th>
</tr>
</thead>
<tbody>
<tr>
<th>233</th>
<td>2012-01-07</td>
<td>4521.0</td>
<td>1</td>
</tr>
<tr>
<th>246</th>
<td>2012-02-01</td>
<td>4579.0</td>
<td>2</td>
</tr>
<tr>
<th>252</th>
<td>2012-02-07</td>
<td>4375.0</td>
<td>2</td>
</tr>
<tr>
<th>436</th>
<td>2012-12-01</td>
<td>5191.0</td>
<td>12</td>
</tr>
<tr>
<th>437</th>
<td>2012-12-02</td>
<td>4649.0</td>
<td>12</td>
</tr>
</tbody>
</table>
</div></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=45b02ebf"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The detected anomalies highlight days in winter months (January and February) with demand levels much closer to what we’d expect in summer. For example, January 7 shows more than double the average rentals for that month. These could indicate unusually warm days that encouraged cycling, or they might reflect special events. In practice, such findings should be validated with weather data or event calendars. This illustrates how seasonal anomaly detection helps identify values that break expected seasonal patterns, providing valuable clues about real-world influences on demand.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=c3bf4cef"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="3.4.-Missing-Data-Detection">3.4. Missing Data Detection<a class="anchor-link" href="#3.4.-Missing-Data-Detection">¶</a></h3><p>Missing data detection is the systematic analysis of gaps in your dataset to understand their patterns, causes, and potential impact on modeling and analysis.</p>
<p>Unlike outliers which are individual problematic values, missing data represents systematic gaps that can undermine entire analyses. Missingness often follows patterns — clustering in certain periods, affecting groups of variables together, or reflecting underlying system failures like sensor outages.</p>
<p>We analyze missing data through three systematic analyses:</p>
<ul>
<li>Quantitative assessment</li>
<li>Temporal pattern analysis</li>
<li>Cross-variable analysis</li>
</ul>
<p><strong>1. Quantitative Assessment of Missing Data</strong></p>
<p>A <strong>quantitative assessment</strong> inventories missing values across all columns, showing both you and the client the scale and location of gaps.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered" id="cell-id=56a54a62">
<div class="input">
<div class="prompt input_prompt">In [8]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="c1"># Load dataset</span>
<span class="n">url</span> <span class="o">=</span> <span class="s2">"https://raw.githubusercontent.com/pmarcelino/predictive-modeling/main/datasets/dataset-teaching-lec-04.csv"</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'datetime'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'datetime'</span><span class="p">],</span> <span class="n">errors</span><span class="o">=</span><span class="s1">'coerce'</span><span class="p">)</span>

<span class="c1"># Count missing values and calculate percentages</span>
<span class="n">missing_counts</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">missing_percentages</span> <span class="o">=</span> <span class="p">(</span><span class="n">missing_counts</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span> <span class="o">*</span> <span class="mi">100</span>

<span class="c1"># Display side by side for clarity</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">"Missing"</span><span class="p">:</span> <span class="n">missing_counts</span><span class="p">,</span> <span class="s2">"Percentage"</span><span class="p">:</span> <span class="n">missing_percentages</span><span class="p">})</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt output_prompt">Out[8]:</div>
<div class="output_html rendered_html output_subarea output_execute_result"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th></th>
<th>Missing</th>
<th>Percentage</th>
</tr>
</thead>
<tbody>
<tr>
<th>datetime</th>
<td>0</td>
<td>0.000000</td>
</tr>
<tr>
<th>season</th>
<td>0</td>
<td>0.000000</td>
</tr>
<tr>
<th>holiday</th>
<td>545</td>
<td>5.006430</td>
</tr>
<tr>
<th>workingday</th>
<td>0</td>
<td>0.000000</td>
</tr>
<tr>
<th>weather</th>
<td>71</td>
<td>0.652214</td>
</tr>
<tr>
<th>temp</th>
<td>72</td>
<td>0.661400</td>
</tr>
<tr>
<th>atemp</th>
<td>72</td>
<td>0.661400</td>
</tr>
<tr>
<th>humidity</th>
<td>72</td>
<td>0.661400</td>
</tr>
<tr>
<th>windspeed</th>
<td>72</td>
<td>0.661400</td>
</tr>
<tr>
<th>casual</th>
<td>146</td>
<td>1.341172</td>
</tr>
<tr>
<th>registered</th>
<td>146</td>
<td>1.341172</td>
</tr>
<tr>
<th>count</th>
<td>146</td>
<td>1.341172</td>
</tr>
</tbody>
</table>
</div></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=d7072333"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Our scan shows three main areas of concern:</p>
<ul>
<li>First, the <code>holiday</code> column is missing in about <strong>5% of rows</strong>, which means we can't always tell whether a given day was a holiday — a potentially important driver of demand.</li>
<li>Second, weather-related variables (<code>temp</code>, <code>atemp</code>, <code>humidity</code>, <code>windspeed</code>) are missing in around <strong>0.6% of cases each</strong>. That may sound small, but if they go missing together, it likely reflects a sensor or reporting problem.</li>
<li>Finally, and most importantly, the <strong>target variables</strong> (<code>count</code>, <code>casual</code>, <code>registered</code>) are missing in <strong>146 rows</strong>, or about <strong>1.3% of the dataset</strong>.</li>
</ul>
<p>Any missing demand values directly reduce the amount of training data available for forecasting, which is bad.</p>
<p><strong>2. Temporal Pattern Analysis</strong></p>
<p>In transportation datasets, missing data often clusters in specific periods. This makes <strong>temporal analysis</strong> essential: by grouping missingness across months or seasons, we can check whether the gaps are random or systematically tied to certain time periods.</p>
<p>This matters for forecasting because if missingness is concentrated in peak demand months, any model we build will be biased or incomplete in those periods.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered" id="cell-id=13d4e6d8">
<div class="input">
<div class="prompt input_prompt">In [9]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="c1"># Load dataset</span>
<span class="n">url</span> <span class="o">=</span> <span class="s2">"https://raw.githubusercontent.com/pmarcelino/predictive-modeling/main/datasets/dataset-teaching-lec-04.csv"</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'datetime'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'datetime'</span><span class="p">],</span> <span class="n">errors</span><span class="o">=</span><span class="s1">'coerce'</span><span class="p">)</span>

<span class="c1"># Extract year and month into a new column</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'year_month'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'datetime'</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s1">'%Y-%m'</span><span class="p">)</span>

<span class="c1"># Group by the new 'year_month' column and calculate missing values</span>
<span class="n">missing_by_month</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">'year_month'</span><span class="p">])[</span><span class="s1">'count'</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">missing_by_month</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>year_month
2011-01     0
2011-02     0
2011-03     0
2011-04     0
2011-05     0
2011-06     0
2011-07    74
2011-08     0
2011-09     0
2011-10     0
2011-11     0
2011-12     0
2012-01     0
2012-02     0
2012-03     0
2012-04     0
2012-05     0
2012-06     0
2012-07    72
2012-08     0
2012-09     0
2012-10     0
2012-11     0
2012-12     0
Name: count, dtype: int64
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=6ed89a4a"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The temporal scan reveals that missing demand values are not evenly spread across the dataset. Instead, they cluster heavily in <strong>July 2011 and July 2012</strong>. This points to a systematic issue, such as a recurring sensor outage or reporting gap during summer months. For the client, this has a clear implication: forecasts for peak-season demand may be less reliable unless these gaps are addressed. It’s not just random noise — it’s a structural weakness in the dataset that could distort decision-making during the busiest time of year.</p>
<p><strong>3. Cross-Variable Analysis of Missing Data</strong></p>
<p>Sometimes, missingness in one variable aligns with gaps in others. This is an important diagnostic step because it helps distinguish between isolated issues (e.g., a single column not recorded) and <strong>system-wide failures</strong> (e.g., a weather station outage affecting several variables at once).</p>
<p>By checking which variables tend to go missing together, we can form a more realistic hypothesis about the underlying cause.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered" id="cell-id=cf9780a1">
<div class="input">
<div class="prompt input_prompt">In [10]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="c1"># Load dataset</span>
<span class="n">url</span> <span class="o">=</span> <span class="s2">"https://raw.githubusercontent.com/pmarcelino/predictive-modeling/main/datasets/dataset-teaching-lec-04.csv"</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s2">"datetime"</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">"datetime"</span><span class="p">],</span> <span class="n">errors</span><span class="o">=</span><span class="s2">"coerce"</span><span class="p">)</span>

<span class="c1"># Check rows where at least one weather-related variable is missing</span>
<span class="n">weather_missing</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[[</span><span class="s2">"temp"</span><span class="p">,</span> <span class="s2">"humidity"</span><span class="p">,</span> <span class="s2">"windspeed"</span><span class="p">]]</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">weather_missing</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>               datetime  season  holiday  workingday  weather  temp  atemp  \
680 2011-02-11 16:00:00       1      0.0           1      NaN   NaN    NaN   
681 2011-02-11 17:00:00       1      0.0           1      NaN   NaN    NaN   
682 2011-02-11 18:00:00       1      0.0           1      NaN   NaN    NaN   
683 2011-02-11 19:00:00       1      0.0           1      4.0   NaN    NaN   
684 2011-02-11 20:00:00       1      0.0           1      NaN   NaN    NaN   

     humidity  windspeed  casual  registered  count  
680       NaN        NaN    14.0       111.0  125.0  
681       NaN        NaN    18.0       193.0  211.0  
682       NaN        NaN     9.0       165.0  174.0  
683       NaN        NaN   105.0       476.0  581.0  
684       NaN        NaN     2.0        61.0   63.0  
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=fd873326"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The cross-variable check confirms that missingness is not isolated — entire blocks of weather data (<code>temp</code>, <code>atemp</code>, <code>humidity</code>, <code>windspeed</code>) disappear at the same time. For example, on <strong>February 11, 2011</strong>, several consecutive hours show all weather variables missing together. This strongly suggests a <strong>weather station outage or reporting failure</strong>, not random gaps. Recognizing that these variables fail together allows us to design a coordinated cleaning strategy rather than treating each column as an independent problem.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=5c8498ff"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="4.-Data-Cleaning-Strategies-and-Implementation">4. Data Cleaning Strategies and Implementation<a class="anchor-link" href="#4.-Data-Cleaning-Strategies-and-Implementation">¶</a></h2><p>We've diagnosed the problems in our bike-sharing dataset: impossible values, extreme outliers, missing data blocks, and timeline gaps. <strong>Now comes the treatment stage</strong> — this is where clients see the real consulting value.</p>
<p>Diagnosis impresses clients with your analytical rigor, but <strong>cleaning delivers the reliable data foundation</strong> they need for business decisions. While assessment shows what's wrong, cleaning demonstrates how you solve problems systematically and transparently.</p>
<p>This transition from "finding issues" to "fixing issues" represents the shift from diagnostic consultant to solution provider. Clients pay for datasets they can trust, models they can deploy, and insights they can act on.</p>
<p><strong>Data cleaning</strong> is not cosmetic work to make datasets "look nice." It's a structured process that:</p>
<ul>
<li>Distinguishes <strong>errors</strong> from <strong>real events</strong></li>
<li>Applies <strong>consistent, rule-based fixes</strong> where possible</li>
<li>Decides when to <strong>impute or drop</strong> values that cannot be fixed</li>
<li>Keeps every change <strong>transparent and auditable</strong></li>
</ul>
<p>This systematic approach ensures that your cleaning decisions can be explained, defended, and replicated — critical requirements for professional consulting work.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=a174858e"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="4.1.-The-Unified-Cleaning-Workflow">4.1. The Unified Cleaning Workflow<a class="anchor-link" href="#4.1.-The-Unified-Cleaning-Workflow">¶</a></h3><p>Since we are working with time-series data, we will start by <strong>standardizing the timeline</strong> and fixing its structural problems — this is a critical first step that ensures we have a reliable temporal foundation.</p>
<p>From there, we will follow a <strong>standard data cleaning workflow</strong> that, while always dependent on the specific dataset and business context, can be generalized into a systematic process that learners can apply to their own projects. Once the timeline is reliable, every suspicious value — whether it’s extreme, impossible, or missing — is treated with the same <strong>three-step decision tree</strong>:</p>
<ol>
<li><p><strong>Is this an event or an error?</strong></p>
<ul>
<li><em>Event</em> → keep, but <strong>flag</strong> (e.g., snowstorm, festival).</li>
<li><em>Error</em> → continue.</li>
</ul>
</li>
<li><p><strong>If error: Can I fix it with a rule?</strong></p>
<ul>
<li>Examples: cap humidity to 100, relabel mis-coded weather categories, set negative rentals to <code>NaN</code>.</li>
<li>If yes → <strong>fix and flag</strong>.</li>
<li>If no → continue.</li>
</ul>
</li>
<li><p><strong>If cannot fix: Should I impute or drop?</strong></p>
<ul>
<li><strong>Predictors (features):</strong> impute if valuable, drop if not.</li>
<li><strong>Target (<code>count</code>):</strong> never impute for modeling → drop missing rows.</li>
<li>Always <strong>flag</strong> imputations or dropped ranges.</li>
</ul>
</li>
</ol>
<blockquote>
<p><strong>Note 1:</strong> <strong>Predictors</strong> are the input variables we use to make predictions (like weather conditions, time of day, or season), while the <strong>target</strong> is the outcome variable we're trying to predict (in our case, bike rental counts).</p>
</blockquote>
<blockquote>
<p><strong>Note 2:</strong> Why flag? We flag because it ensures that every change is <strong>visible, auditable, and explainable</strong>. Flags allow you to:</p>
<ul>
<li>Compare model performance with and without imputed values.</li>
<li>Communicate risks to clients (<em>“July demand is less reliable: 20% of weather values were imputed.”</em>).</li>
<li>Keep a record of what changed and why.</li>
</ul>
</blockquote>
<p>This mindset — <em>event or error? fix, impute, or drop? always flag</em> — is the backbone of professional data cleaning.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=a33a7709"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="4.2.-Standardizing-the-Timeline">4.2. Standardizing the Timeline<a class="anchor-link" href="#4.2.-Standardizing-the-Timeline">¶</a></h3><p>In the previous chapters, we discovered that our timeline is not fully reliable: some hours are missing, while others are duplicated. To move forward confidently, we need to standardize the timeline so that every hour has exactly one valid record.</p>
<p>We will do so by:</p>
<ol>
<li>Collapsing duplicate rows</li>
<li>Reindexing to a continuous hourly timeline</li>
</ol>
<p><strong>1. Collapsing Duplicate Rows</strong></p>
<p>The bike-sharing system should record <strong>exactly one entry per hour</strong>. If we find multiple rows for the same timestamp, something has gone wrong. These duplicates can arise for several reasons:</p>
<ul>
<li><strong>Data collection partitioning</strong>: Different sensors or stations reporting separately for the same hour</li>
<li><strong>System processing delays</strong>: Multiple data collection cycles within the same hour</li>
<li><strong>Data pipeline issues</strong>: ETL processes creating duplicate records</li>
</ul>
<p>In all of these situations, the extra rows are not separate time periods but <strong>fragments of the same underlying hour</strong>. This is why we adopt the working assumption that duplicates represent <strong>partial data for a single hour</strong>.</p>
<p>Instead of discarding these rows, we will <strong>combine them into one consolidated record</strong>. This approach is practical for our project, but remember that in real consulting work you should always <strong>validate the duplication patterns before applying aggregation</strong>, to confirm that duplicates really are fragments and not a sign of a different data issue.</p>
<p>Since we assume that duplicates are <strong>partial fragments of the same hour</strong>, we can combine them into a single record using the following aggregation policy:</p>
<ul>
<li>For <strong>targets</strong> (<code>count</code>, <code>casual</code>, <code>registered</code>): use the <strong>SUM</strong>, because bike rentals accumulate across fragments. Two partial records for the same hour simply add up to the true total demand.</li>
<li>For <strong>numeric predictors</strong> (e.g., weather variables): take the <strong>MEAN</strong>, since these are measured as continuous conditions. Averaging across fragments best represents the overall hourly state.</li>
<li>For <strong>categorical variables</strong> (<code>holiday</code>, <code>weather</code>, <code>season</code>): take the <strong>FIRST</strong> value, because these codes should remain stable within an hour. A duplicated categorical code does not add new information.</li>
</ul>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered" id="cell-id=1154ab80">
<div class="input">
<div class="prompt input_prompt">In [11]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># Load dataset and parse datetime</span>
<span class="n">data_path</span> <span class="o">=</span> <span class="s2">"https://raw.githubusercontent.com/pmarcelino/predictive-modeling/main/datasets/dataset-teaching-lec-04.csv"</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">data_path</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s2">"datetime"</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">"datetime"</span><span class="p">],</span> <span class="n">errors</span><span class="o">=</span><span class="s2">"coerce"</span><span class="p">)</span>

<span class="c1"># Identify duplicated timestamps</span>
<span class="n">rows_per_ts</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">"datetime"</span><span class="p">)</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="s2">"n_rows_per_ts"</span><span class="p">)</span>
<span class="n">duplicated_ts</span> <span class="o">=</span> <span class="n">rows_per_ts</span><span class="p">[</span><span class="n">rows_per_ts</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">index</span>
<span class="n">n_dup_timestamps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">duplicated_ts</span><span class="p">)</span>
<span class="n">n_dup_rows</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">rows_per_ts</span><span class="p">[</span><span class="n">rows_per_ts</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Duplicated timestamps: </span><span class="si">{</span><span class="n">n_dup_timestamps</span><span class="si">}</span><span class="s2"> | Extra duplicate rows to collapse: </span><span class="si">{</span><span class="n">n_dup_rows</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Build aggregation policy</span>
<span class="n">numeric_cols</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">number</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">agg_map</span> <span class="o">=</span> <span class="p">{</span><span class="n">c</span><span class="p">:</span> <span class="s2">"mean"</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">numeric_cols</span><span class="p">}</span>

<span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">"count"</span><span class="p">,</span> <span class="s2">"casual"</span><span class="p">,</span> <span class="s2">"registered"</span><span class="p">]:</span>
    <span class="k">if</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">agg_map</span><span class="p">:</span>
        <span class="n">agg_map</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="s2">"sum"</span>

<span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">"holiday"</span><span class="p">,</span> <span class="s2">"weather"</span><span class="p">,</span> <span class="s2">"season"</span><span class="p">]:</span>
    <span class="k">if</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
        <span class="n">agg_map</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="s2">"first"</span>

<span class="c1"># Aggregate to one row per hour</span>
<span class="n">df</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">"datetime"</span><span class="p">,</span> <span class="n">as_index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
      <span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="n">agg_map</span><span class="p">)</span>
      <span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s2">"datetime"</span><span class="p">)</span>
      <span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Add a flag for hours that were collapsed from duplicates</span>
<span class="n">df</span><span class="p">[</span><span class="s2">"flag_collapsed_from_duplicates"</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">"datetime"</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">duplicated_ts</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Collapse complete → policy: SUM targets, MEAN numeric predictors, FIRST categoricals."</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Hours affected:"</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">"flag_collapsed_from_duplicates"</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()))</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Duplicated timestamps: 24 | Extra duplicate rows to collapse: 24
Collapse complete → policy: SUM targets, MEAN numeric predictors, FIRST categoricals.
Hours affected: 24
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=127da27a"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We collapsed <strong>24 duplicated hours</strong>, removing 24 extra rows from the dataset. The aggregation policy ensures that:</p>
<ul>
<li>Demand counts remain correct (no double-counting).</li>
<li>Weather predictors reflect average conditions.</li>
<li>Categorical codes remain stable.</li>
</ul>
<p>The flag <code>flag_collapsed_from_duplicates</code> marks these hours so we can always trace which rows were affected. For transparency, this is important: if a client later asks why certain hours look unusual, we can point to the duplication issue.</p>
<p><strong>2. Reindexing to a Continuous Hourly Timeline</strong></p>
<p>Finally, we enforce a <strong>continuous hourly index</strong>. Right now, the dataset simply skips missing hours — they aren’t represented at all. This makes gaps invisible and impossible to handle systematically.</p>
<p>By reindexing:</p>
<ul>
<li>We insert a row for <strong>every missing hour</strong>.</li>
<li>Those rows will contain <code>NaN</code>s for predictors and/or target.</li>
<li>We add a flag to mark which rows were <strong>inserted</strong>.</li>
</ul>
<p>Next, we'll enforce a continuous hourly timeline by inserting rows for missing hours. This makes all gaps explicit and manageable.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered" id="cell-id=0d805ae8">
<div class="input">
<div class="prompt input_prompt">In [12]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="c1"># Load dataset and parse datetime</span>
<span class="n">data_path</span> <span class="o">=</span> <span class="s2">"https://raw.githubusercontent.com/pmarcelino/predictive-modeling/main/datasets/dataset-teaching-lec-04.csv"</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">data_path</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s2">"datetime"</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">"datetime"</span><span class="p">],</span> <span class="n">errors</span><span class="o">=</span><span class="s2">"coerce"</span><span class="p">)</span>

<span class="c1"># Collapse duplicate timestamps (SUM targets, MEAN numeric predictors, FIRST categoricals)</span>
<span class="k">if</span> <span class="n">df</span><span class="p">[</span><span class="s2">"datetime"</span><span class="p">]</span><span class="o">.</span><span class="n">duplicated</span><span class="p">()</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
    <span class="n">numeric_cols</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="s2">"number"</span><span class="p">)</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    <span class="n">agg_map</span> <span class="o">=</span> <span class="p">{</span><span class="n">c</span><span class="p">:</span> <span class="s2">"mean"</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">numeric_cols</span><span class="p">}</span>
    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">"count"</span><span class="p">,</span> <span class="s2">"casual"</span><span class="p">,</span> <span class="s2">"registered"</span><span class="p">]:</span>
        <span class="k">if</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">agg_map</span><span class="p">:</span>
            <span class="n">agg_map</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="s2">"sum"</span>
    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">"holiday"</span><span class="p">,</span> <span class="s2">"weather"</span><span class="p">,</span> <span class="s2">"season"</span><span class="p">]:</span>
        <span class="k">if</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
            <span class="n">agg_map</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="s2">"first"</span>
    <span class="n">df</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">"datetime"</span><span class="p">,</span> <span class="n">as_index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
          <span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="n">agg_map</span><span class="p">)</span>
          <span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s2">"datetime"</span><span class="p">)</span>
          <span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="p">)</span>

<span class="c1"># Build the full hourly index</span>
<span class="n">time_min</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">"datetime"</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
<span class="n">time_max</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">"datetime"</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
<span class="n">full_hours</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">date_range</span><span class="p">(</span><span class="n">time_min</span><span class="p">,</span> <span class="n">time_max</span><span class="p">,</span> <span class="n">freq</span><span class="o">=</span><span class="s2">"h"</span><span class="p">)</span>

<span class="c1"># Keep original set of hours</span>
<span class="n">original_hours</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Index</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">"datetime"</span><span class="p">])</span>

<span class="c1"># Reindex and flag</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s2">"datetime"</span><span class="p">)</span><span class="o">.</span><span class="n">reindex</span><span class="p">(</span><span class="n">full_hours</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s2">"datetime"</span>
<span class="n">df</span><span class="p">[</span><span class="s2">"flag_missing_timestamp"</span><span class="p">]</span> <span class="o">=</span> <span class="o">~</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">original_hours</span><span class="p">)</span>

<span class="c1"># Audit</span>
<span class="n">inserted_hours</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">"flag_missing_timestamp"</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
<span class="n">total_hours</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">present_hours</span> <span class="o">=</span> <span class="n">total_hours</span> <span class="o">-</span> <span class="n">inserted_hours</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"=== Reindex audit ==="</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"time_min:"</span><span class="p">,</span> <span class="n">time_min</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"time_max:"</span><span class="p">,</span> <span class="n">time_max</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"total_hours_after_reindex:"</span><span class="p">,</span> <span class="n">total_hours</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"present_hours_from_source:"</span><span class="p">,</span> <span class="n">present_hours</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"inserted_missing_hours:"</span><span class="p">,</span> <span class="n">inserted_hours</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>=== Reindex audit ===
time_min: 2011-01-01 00:00:00
time_max: 2012-12-19 23:00:00
total_hours_after_reindex: 17256
present_hours_from_source: 10862
inserted_missing_hours: 6394
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=2ec78a9a"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>After reindexing, the dataset now has <strong>17 256 rows</strong> — one for each expected hour. Of these, <strong>6 394 rows were inserted</strong> to represent missing hours. These rows currently contain <code>NaN</code>s, which is exactly what we want: the gaps are now explicit and can be handled in the cleaning workflow.</p>
<p>From here:</p>
<ul>
<li>For <strong>predictors</strong>, missing values can be imputed using interpolation or seasonal medians.</li>
<li>For the <strong>target (<code>count</code>)</strong>, rows with missing demand must be dropped before model training.</li>
<li>The flag <code>flag_missing_timestamp</code> allows us to communicate clearly to clients how much of the dataset is reconstructed rather than observed.</li>
</ul>
<p>With these two steps, we’ve established a <strong>reliable timeline</strong>. The dataset now has exactly one row per hour, duplicates resolved, and missing periods made explicit. This creates the solid foundation we need before applying the unified cleaning workflow to outliers and missing data.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=c9f7b497"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="4.3.-Applying-the-Workflow-to-Outliers">4.3. Applying the Workflow to Outliers<a class="anchor-link" href="#4.3.-Applying-the-Workflow-to-Outliers">¶</a></h3><p>Earlier we learned to detect outliers; now we'll apply the unified workflow to treat them systematically. The key shift is from detection to decision-making.</p>
<p>Let's work through the three-step workflow systematically with our detected outliers:</p>
<p><strong>Step 1: Is this an event or an error?</strong></p>
<p>First, we examine each outlier to determine its nature. This step requires both data analysis and business context.</p>
<p><em>Physically Impossible Values</em></p>
<p>Some outliers are easy to classify because they are <strong>physically impossible</strong>:</p>
<ul>
<li>Negative rentals (<code>count &lt; 0</code>) — cannot exist in any transportation system</li>
<li>Humidity above 100% — violates physical laws</li>
<li>Temperatures above 100°C in Washington, D.C. — impossible for the local climate</li>
</ul>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered" id="cell-id=8d7002c1">
<div class="input">
<div class="prompt input_prompt">In [13]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># Identify impossible values across different variables</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"=== Step 1: Identifying impossible values (clear errors) ==="</span><span class="p">)</span>

<span class="c1"># Check negative rentals</span>
<span class="n">negative_rentals</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">"count"</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Negative rental counts: </span><span class="si">{</span><span class="n">negative_rentals</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Check invalid humidity</span>
<span class="n">invalid_humidity</span> <span class="o">=</span> <span class="p">((</span><span class="n">df</span><span class="p">[</span><span class="s2">"humidity"</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">"humidity"</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">100</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Humidity outside 0-100%: </span><span class="si">{</span><span class="n">invalid_humidity</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Check extreme temperatures (conservative cutoff for Washington climate)</span>
<span class="n">extreme_temps</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">"temp"</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">60</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Temperatures above 60°C: </span><span class="si">{</span><span class="n">extreme_temps</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>=== Step 1: Identifying impossible values (clear errors) ===
Negative rental counts: 6
Humidity outside 0-100%: 10
Temperatures above 60°C: 5
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=9c854c3d"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Decision:</strong> These are <strong>always errors</strong> — they cannot represent real-world events. Move to Step 2.</p>
<p><em>Extreme-but-Possible Values</em></p>
<p>Other outliers are statistically extreme but could potentially be real events:</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered" id="cell-id=464e7093">
<div class="input">
<div class="prompt input_prompt">In [14]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="c1"># Check for extreme daily rental patterns using Z-scores</span>
<span class="n">daily_rentals</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">df</span><span class="p">[</span><span class="s2">"count"</span><span class="p">]</span>
    <span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">date</span><span class="p">)</span>
    <span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="s2">"daily_count"</span><span class="p">)</span>
    <span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">mean</span> <span class="o">=</span> <span class="n">daily_rentals</span><span class="p">[</span><span class="s2">"daily_count"</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">std</span> <span class="o">=</span> <span class="n">daily_rentals</span><span class="p">[</span><span class="s2">"daily_count"</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
<span class="n">daily_rentals</span><span class="p">[</span><span class="s2">"z_score"</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">daily_rentals</span><span class="p">[</span><span class="s2">"daily_count"</span><span class="p">]</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">std</span>

<span class="c1"># Flag potential outliers (|Z| &gt; 3)</span>
<span class="n">extreme_days</span> <span class="o">=</span> <span class="n">daily_rentals</span><span class="p">[</span><span class="n">daily_rentals</span><span class="p">[</span><span class="s2">"z_score"</span><span class="p">]</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">3</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">=== Extreme daily rental patterns ==="</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Days with |Z-score| &gt; 3: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">extreme_days</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="n">extreme_days</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>
=== Extreme daily rental patterns ===
Days with |Z-score| &gt; 3: 2
</pre>
</div>
</div>
<div class="output_area">
<div class="prompt output_prompt">Out[14]:</div>
<div class="output_html rendered_html output_subarea output_execute_result"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th></th>
<th>index</th>
<th>daily_count</th>
<th>z_score</th>
</tr>
</thead>
<tbody>
<tr>
<th>134</th>
<td>2011-05-15</td>
<td>21301.0</td>
<td>6.449117</td>
</tr>
<tr>
<th>306</th>
<td>2011-11-03</td>
<td>21887.0</td>
<td>6.654553</td>
</tr>
</tbody>
</table>
</div></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=c7cf631a"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Decision:</strong> These require investigation. Could be:</p>
<ul>
<li><strong>Events</strong>: Festival days, unusual weather patterns, special promotions</li>
<li><strong>Errors</strong>: Duplicated logs, sensor malfunctions, data processing issues</li>
</ul>
<p>For this example, we'll assume days with extreme rentals could be legitimate events (holidays, festivals) and should be kept but flagged for transparency.</p>
<p><strong>Step 2: If error, can I fix it with a rule?</strong></p>
<p>For the values we've classified as errors, we apply rule-based fixes where possible. If not, we mark as <code>NaN</code> and continue to step 3.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered" id="cell-id=1803ee04">
<div class="input">
<div class="prompt input_prompt">In [15]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">"=== Step 2: Applying rule-based fixes to errors ==="</span><span class="p">)</span>

<span class="c1"># Fix impossible values using business rules</span>

<span class="c1"># Negative rentals: Set to NaN (cannot be fixed with a rule)</span>
<span class="n">df</span><span class="p">[</span><span class="s2">"flag_negative_count"</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">"count"</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">0</span>
<span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s2">"flag_negative_count"</span><span class="p">],</span> <span class="s2">"count"</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Negative rentals set to NaN: </span><span class="si">{</span><span class="n">df</span><span class="p">[</span><span class="s1">'flag_negative_count'</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Humidity outside valid range: Set to NaN (cannot determine correct value)</span>
<span class="n">df</span><span class="p">[</span><span class="s2">"flag_humidity_invalid"</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">"humidity"</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">"humidity"</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s2">"flag_humidity_invalid"</span><span class="p">],</span> <span class="s2">"humidity"</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Invalid humidity values set to NaN: </span><span class="si">{</span><span class="n">df</span><span class="p">[</span><span class="s1">'flag_humidity_invalid'</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Extreme temperatures: Set to NaN (cannot determine correct value)</span>
<span class="n">df</span><span class="p">[</span><span class="s2">"flag_temp_invalid"</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">"temp"</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">60</span>
<span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s2">"flag_temp_invalid"</span><span class="p">],</span> <span class="s2">"temp"</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Extreme temperatures set to NaN: </span><span class="si">{</span><span class="n">df</span><span class="p">[</span><span class="s1">'flag_temp_invalid'</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>=== Step 2: Applying rule-based fixes to errors ===
Negative rentals set to NaN: 6
Invalid humidity values set to NaN: 10
Extreme temperatures set to NaN: 5
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=a0d39769"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Decision:</strong> These impossible values cannot be fixed with business rules (we don't know what the correct values should be), so they move to Step 3.</p>
<p><strong>Step 3: If cannot fix, should I impute or drop?</strong></p>
<p>For values that cannot be rule-based fixed, we decide between imputation and dropping based on variable type:</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered" id="cell-id=2835b502">
<div class="input">
<div class="prompt input_prompt">In [16]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">=== Step 3: Impute or drop unfixable errors ==="</span><span class="p">)</span>

<span class="c1"># For PREDICTORS (weather variables): These can be imputed</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Weather predictors with NaN values after error correction:"</span><span class="p">)</span>
<span class="n">weather_vars</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"temp"</span><span class="p">,</span> <span class="s2">"humidity"</span><span class="p">,</span> <span class="s2">"windspeed"</span><span class="p">]</span>
<span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">weather_vars</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
        <span class="n">nan_count</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">var</span><span class="p">]</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  </span><span class="si">{</span><span class="n">var</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">nan_count</span><span class="si">}</span><span class="s2"> NaN values → will be imputed later"</span><span class="p">)</span>

<span class="c1"># For TARGET (count): Never impute for modeling - these rows will be dropped</span>
<span class="n">target_nan</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">"count"</span><span class="p">]</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Target variable 'count': </span><span class="si">{</span><span class="n">target_nan</span><span class="si">}</span><span class="s2"> NaN values → rows will be dropped before modeling"</span><span class="p">)</span>

<span class="c1"># Flag extreme events that we're keeping</span>
<span class="n">df</span><span class="p">[</span><span class="s2">"flag_extreme_but_kept"</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
<span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">extreme_days</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">extreme_dates</span> <span class="o">=</span> <span class="n">extreme_days</span><span class="p">[</span><span class="s2">"index"</span><span class="p">]</span>  <span class="c1"># column is named 'index' after reset_index()</span>
    <span class="n">df_dates</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">date</span><span class="p">)</span>  <span class="c1"># convert numpy array to pandas Series</span>
    <span class="n">df</span><span class="p">[</span><span class="s2">"flag_extreme_but_kept"</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_dates</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">extreme_dates</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Extreme-but-possible days flagged for transparency: </span><span class="si">{</span><span class="n">df</span><span class="p">[</span><span class="s1">'flag_extreme_but_kept'</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>
=== Step 3: Impute or drop unfixable errors ===
Weather predictors with NaN values after error correction:
  temp: 6471 NaN values → will be imputed later
  humidity: 6476 NaN values → will be imputed later
  windspeed: 6466 NaN values → will be imputed later

Target variable 'count': 6400 NaN values → rows will be dropped before modeling
Extreme-but-possible days flagged for transparency: 0
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=96327243"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Summary of workflow application:</strong></p>
<ol>
<li><p><strong>Step 1 (Event or Error):</strong></p>
<ul>
<li>Impossible values → Classified as errors</li>
<li>Extreme-but-possible values → Classified as potential events, kept with flags</li>
</ul>
</li>
<li><p><strong>Step 2 (Fix with rule):</strong></p>
<ul>
<li>Impossible values → No business rule available, set to NaN and flagged</li>
</ul>
</li>
<li><p><strong>Step 3 (Impute or drop):</strong></p>
<ul>
<li>Predictor variables with NaN → Will be imputed in preprocessing</li>
<li>Target variable with NaN → Rows will be dropped before modeling</li>
<li>Extreme events → Kept with transparency flags</li>
</ul>
</li>
</ol>
<p>Following the unified workflow ensures that every outlier treatment decision is systematic, auditable, and defensible. Impossible values were identified as clear errors and set to missing, extreme-but-possible values were preserved with transparency flags, and the treatment strategy differs appropriately between predictors (impute) and targets (drop). Every intervention is flagged, ensuring complete traceability for client communications.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=93487abe"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="4.4.-Applying-the-Workflow-to-Missing-Data">4.4. Applying the Workflow to Missing Data<a class="anchor-link" href="#4.4.-Applying-the-Workflow-to-Missing-Data">¶</a></h3><p>Earlier we systematically detected missing data patterns; now we'll apply the unified workflow to treat them strategically. Missing data presents different challenges than outliers because absence itself can be meaningful information.</p>
<p>The key distinction is understanding <strong>why</strong> data is missing: system failures during storms tell a different story than random sensor glitches, and each requires different treatment strategies.</p>
<p>Let's work through the three-step workflow systematically with our detected missing data patterns:</p>
<p><strong>Step 1: Is this an event or an error?</strong></p>
<p>Missing data can result from legitimate operational events or system errors. Understanding the cause determines our treatment approach.</p>
<p><em>Systematic Operational Gaps</em></p>
<p>First, let's examine the temporal clustering we identified earlier — missing data concentrated in July periods:</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered" id="cell-id=7599160c">
<div class="input">
<div class="prompt input_prompt">In [17]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="c1"># Analyze missing data patterns by year-month</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"=== Step 1: Analyzing missingness patterns ==="</span><span class="p">)</span>

<span class="c1"># Load dataset</span>
<span class="n">url</span> <span class="o">=</span> <span class="s2">"https://raw.githubusercontent.com/pmarcelino/predictive-modeling/main/datasets/dataset-teaching-lec-04.csv"</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s2">"datetime"</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">"datetime"</span><span class="p">],</span> <span class="n">errors</span><span class="o">=</span><span class="s2">"coerce"</span><span class="p">)</span>

<span class="c1"># Focus on the target variable and key predictors</span>
<span class="n">key_vars</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"count"</span><span class="p">,</span> <span class="s2">"temp"</span><span class="p">,</span> <span class="s2">"humidity"</span><span class="p">,</span> <span class="s2">"windspeed"</span><span class="p">,</span> <span class="s2">"holiday"</span><span class="p">]</span>
<span class="n">missing_analysis</span> <span class="o">=</span> <span class="p">{}</span>

<span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">key_vars</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
        <span class="c1"># Monthly missingness pattern</span>
        <span class="n">monthly_missing</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">"datetime"</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">to_period</span><span class="p">(</span><span class="s1">'M'</span><span class="p">))[</span><span class="n">var</span><span class="p">]</span>
            <span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
            <span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">var</span><span class="si">}</span><span class="s2">_missing"</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">missing_analysis</span><span class="p">[</span><span class="n">var</span><span class="p">]</span> <span class="o">=</span> <span class="n">monthly_missing</span>

<span class="c1"># Display July patterns specifically</span>
<span class="n">july_months</span> <span class="o">=</span> <span class="p">[</span><span class="n">period</span> <span class="k">for</span> <span class="n">period</span> <span class="ow">in</span> <span class="n">monthly_missing</span><span class="o">.</span><span class="n">index</span> <span class="k">if</span> <span class="n">period</span><span class="o">.</span><span class="n">month</span> <span class="o">==</span> <span class="mi">7</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Missing data in July periods:"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">month</span> <span class="ow">in</span> <span class="n">july_months</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">month</span><span class="si">}</span><span class="s2">:"</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">key_vars</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">missing_analysis</span><span class="p">:</span>
            <span class="n">count</span> <span class="o">=</span> <span class="n">missing_analysis</span><span class="p">[</span><span class="n">var</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">month</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  </span><span class="si">{</span><span class="n">var</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">count</span><span class="si">}</span><span class="s2"> missing hours"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>=== Step 1: Analyzing missingness patterns ===

Missing data in July periods:
2011-07:
  count: 74 missing hours
  temp: 0 missing hours
  humidity: 0 missing hours
  windspeed: 0 missing hours
  holiday: 20 missing hours
2012-07:
  count: 72 missing hours
  temp: 0 missing hours
  humidity: 0 missing hours
  windspeed: 0 missing hours
  holiday: 32 missing hours
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=f4b81e2e"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Decision:</strong> The July clustering suggests <strong>systematic operational events</strong> — likely planned maintenance windows or sensor replacement cycles. This is normal system operation, not an error.</p>
<p><em>Weather Station Outages</em></p>
<p>Next, examine simultaneous missingness across weather variables:</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered" id="cell-id=63b98e8f">
<div class="input">
<div class="prompt input_prompt">In [18]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="c1"># Check for simultaneous weather variable failures</span>
<span class="n">weather_vars</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"temp"</span><span class="p">,</span> <span class="s2">"atemp"</span><span class="p">,</span> <span class="s2">"humidity"</span><span class="p">,</span> <span class="s2">"windspeed"</span><span class="p">]</span>
<span class="n">available_weather_vars</span> <span class="o">=</span> <span class="p">[</span><span class="n">var</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">weather_vars</span> <span class="k">if</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>

<span class="c1"># Count rows where multiple weather variables are missing together</span>
<span class="n">weather_missing_counts</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">available_weather_vars</span><span class="p">]</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">simultaneous_failures</span> <span class="o">=</span> <span class="p">(</span><span class="n">weather_missing_counts</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Simultaneous weather failures:"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Hours with 2+ weather variables missing: </span><span class="si">{</span><span class="n">simultaneous_failures</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Sample some simultaneous failure periods</span>
<span class="n">simultaneous_missing_rows</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">weather_missing_counts</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Example simultaneous failures:"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">simultaneous_missing_rows</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
    <span class="n">missing_vars</span> <span class="o">=</span> <span class="p">[</span><span class="n">var</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">available_weather_vars</span> <span class="k">if</span> <span class="n">pd</span><span class="o">.</span><span class="n">isna</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="n">var</span><span class="p">])]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  </span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">missing_vars</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>
Simultaneous weather failures:
Hours with 2+ weather variables missing: 72

Example simultaneous failures:
  680: ['temp', 'atemp', 'humidity', 'windspeed']
  681: ['temp', 'atemp', 'humidity', 'windspeed']
  682: ['temp', 'atemp', 'humidity', 'windspeed']
  683: ['temp', 'atemp', 'humidity', 'windspeed']
  684: ['temp', 'atemp', 'humidity', 'windspeed']
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=aa4e4a89"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Decision:</strong> Simultaneous weather failures indicate <strong>weather station outages</strong> — operational events, not errors. These represent real system limitations during specific periods.</p>
<p><em>Holiday Information Gaps</em></p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered" id="cell-id=2ec84630">
<div class="input">
<div class="prompt input_prompt">In [19]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="c1"># Analyze holiday missingness pattern</span>
<span class="k">if</span> <span class="s2">"holiday"</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="n">holiday_missing</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">"holiday"</span><span class="p">]</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">total_rows</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
    <span class="n">holiday_missing_pct</span> <span class="o">=</span> <span class="p">(</span><span class="n">holiday_missing</span> <span class="o">/</span> <span class="n">total_rows</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Holiday information gaps:"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Missing holiday labels: </span><span class="si">{</span><span class="n">holiday_missing</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">holiday_missing_pct</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%)"</span><span class="p">)</span>
    
    <span class="c1"># Check if missing holidays cluster around known holiday periods</span>
    <span class="n">holiday_missing_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s2">"holiday"</span><span class="p">]</span><span class="o">.</span><span class="n">isna</span><span class="p">()]</span>
    <span class="n">holiday_missing_months</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">holiday_missing_df</span>
        <span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">holiday_missing_df</span><span class="p">[</span><span class="s2">"datetime"</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">to_period</span><span class="p">(</span><span class="s1">'M'</span><span class="p">))</span>
        <span class="o">.</span><span class="n">size</span><span class="p">()</span>
        <span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Holiday missingness by month (top 5):"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">holiday_missing_months</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>
Holiday information gaps:
Missing holiday labels: 545 (5.0%)
Holiday missingness by month (top 5):
datetime
2011-08    33
2012-07    32
2011-12    30
2012-10    28
2012-09    28
Freq: M, dtype: int64
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=ba33cb40"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Decision:</strong> Missing holiday labels are likely <strong>data processing gaps</strong> rather than operational events. These can potentially be filled using external holiday calendars.</p>
<p><strong>Step 2: If error, can I fix it with a rule?</strong></p>
<p>Since we classified July clustering and weather station outages as <strong>operational events</strong> (not errors) in Step 1, only the holiday information gaps require rule-based fixing:</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered" id="cell-id=0ced1e36">
<div class="input">
<div class="prompt input_prompt">In [20]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">=== Step 2: Applying rule-based fixes to errors ==="</span><span class="p">)</span>

<span class="c1"># Fix holiday information using business rules</span>
<span class="k">if</span> <span class="s2">"holiday"</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="c1"># Create a simple holiday calendar for major US federal holidays</span>
    <span class="c1"># In practice, you'd use a comprehensive holiday library</span>
    <span class="n">known_holidays</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">'2011-01-01'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">'2011-07-04'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">'2011-12-25'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
        <span class="s1">'2012-01-01'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">'2012-07-04'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">'2012-12-25'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
        <span class="c1"># Add more holidays as needed</span>
    <span class="p">}</span>
    
    <span class="c1"># Flag original missing holidays</span>
    <span class="n">df</span><span class="p">[</span><span class="s2">"flag_holiday_originally_missing"</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">"holiday"</span><span class="p">]</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span>
    
    <span class="c1"># Fill known holidays</span>
    <span class="n">holiday_fixes</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">date_str</span><span class="p">,</span> <span class="n">holiday_val</span> <span class="ow">in</span> <span class="n">known_holidays</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">date</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">date_str</span><span class="p">)</span>
        <span class="c1"># Fill all rows on that date</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">"datetime"</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">date</span> <span class="o">==</span> <span class="n">date</span><span class="o">.</span><span class="n">date</span><span class="p">()</span>
        <span class="n">fixes_here</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">mask</span><span class="p">,</span> <span class="s2">"holiday"</span><span class="p">]</span> <span class="o">=</span> <span class="n">holiday_val</span>
        <span class="n">holiday_fixes</span> <span class="o">+=</span> <span class="nb">int</span><span class="p">(</span><span class="n">fixes_here</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Holiday values filled using calendar rules (rows): </span><span class="si">{</span><span class="n">holiday_fixes</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    
    <span class="c1"># Remaining missing holidays default to 0 (non-holiday)</span>
    <span class="n">remaining_missing</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">"holiday"</span><span class="p">]</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">df</span><span class="p">[</span><span class="s2">"holiday"</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">"holiday"</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Remaining missing holidays set to 0 (non-holiday): </span><span class="si">{</span><span class="n">remaining_missing</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>
=== Step 2: Applying rule-based fixes to errors ===
Holiday values filled using calendar rules (rows): 96
Remaining missing holidays set to 0 (non-holiday): 537
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=b91a67c9"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Decision:</strong> Holiday information gaps were successfully addressed using external calendar rules. Weather station outages and maintenance periods are legitimate operational events that require imputation rather than rule-based fixes.</p>
<p><strong>Step 3: If cannot fix, should I impute or drop?</strong></p>
<p>For unfixable missing values, we decide based on variable type and modeling requirements:</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered" id="cell-id=b20862bd">
<div class="input">
<div class="prompt input_prompt">In [21]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">=== Step 3: Impute or drop strategy ==="</span><span class="p">)</span>

<span class="c1"># Recompute available weather vars</span>
<span class="n">weather_vars</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"temp"</span><span class="p">,</span> <span class="s2">"atemp"</span><span class="p">,</span> <span class="s2">"humidity"</span><span class="p">,</span> <span class="s2">"windspeed"</span><span class="p">]</span>
<span class="n">available_weather_vars</span> <span class="o">=</span> <span class="p">[</span><span class="n">var</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">weather_vars</span> <span class="k">if</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>

<span class="c1"># Strategy for PREDICTORS (weather and other features)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Weather predictors with missing values after error correction:"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">available_weather_vars</span><span class="p">:</span>
    <span class="n">missing_count</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">var</span><span class="p">]</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">missing_count</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># Create flag for transparency</span>
        <span class="n">flag_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"flag_</span><span class="si">{</span><span class="n">var</span><span class="si">}</span><span class="s2">_missing"</span>
        <span class="n">df</span><span class="p">[</span><span class="n">flag_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">var</span><span class="p">]</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  </span><span class="si">{</span><span class="n">var</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">missing_count</span><span class="si">}</span><span class="s2"> missing values → will be imputed later"</span><span class="p">)</span>

<span class="c1"># Strategy for TARGET variable</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Missing target variable - DROPPING strategy:"</span><span class="p">)</span>
<span class="n">target_missing</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">"count"</span><span class="p">]</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  'count': </span><span class="si">{</span><span class="n">target_missing</span><span class="si">}</span><span class="s2"> rows with missing target → will be dropped before modeling"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Reason: Never impute target variables for supervised learning"</span><span class="p">)</span>

<span class="c1"># Operational gaps audit (quantify without relying on prior flags)</span>
<span class="n">rows_per_ts</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">"datetime"</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="s1">'h'</span><span class="p">))</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="s2">"n_rows_per_ts"</span><span class="p">)</span>
<span class="n">duplicates_to_collapse</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">rows_per_ts</span><span class="p">[</span><span class="n">rows_per_ts</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>

<span class="n">full_hours</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">date_range</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">"datetime"</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">df</span><span class="p">[</span><span class="s2">"datetime"</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">freq</span><span class="o">=</span><span class="s1">'h'</span><span class="p">)</span>
<span class="n">actual_hours</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Index</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">"datetime"</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="s1">'h'</span><span class="p">)</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
<span class="n">inserted_missing_hours</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">full_hours</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span><span class="n">actual_hours</span><span class="p">)))</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Operational gaps to preserve with context:"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Hours represented by duplicate fragments: </span><span class="si">{</span><span class="n">duplicates_to_collapse</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Missing hourly slots to be inserted during reindex: </span><span class="si">{</span><span class="n">inserted_missing_hours</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>
=== Step 3: Impute or drop strategy ===
Weather predictors with missing values after error correction:
  temp: 72 missing values → will be imputed later
  atemp: 72 missing values → will be imputed later
  humidity: 72 missing values → will be imputed later
  windspeed: 72 missing values → will be imputed later

Missing target variable - DROPPING strategy:
  'count': 146 rows with missing target → will be dropped before modeling
  Reason: Never impute target variables for supervised learning

Operational gaps to preserve with context:
  Hours represented by duplicate fragments: 24
  Missing hourly slots to be inserted during reindex: 6394
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=7312a057"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Summary of workflow application:</strong></p>
<ol>
<li><p><strong>Step 1 (Event or Error):</strong></p>
<ul>
<li>July clustering → Operational maintenance events, preserved with context</li>
<li>Weather station outages → Operational limitations, imputation needed</li>
<li>Holiday gaps → Data processing errors, fixable with rules</li>
</ul>
</li>
<li><p><strong>Step 2 (Fix with rule):</strong></p>
<ul>
<li>Holiday information → Partially fixed using calendar rules</li>
</ul>
</li>
<li><p><strong>Step 3 (Impute or drop):</strong></p>
<ul>
<li>Predictor variables → Flagged for later imputation during preprocessing</li>
<li>Target variable → Rows with missing targets dropped (never impute)</li>
<li>Operational gaps → Quantified for client transparency</li>
</ul>
</li>
</ol>
<p>The missing data workflow ensures that every gap is handled appropriately based on its cause and variable type. Operational events are preserved with context, fixable gaps are corrected systematically, and remaining missingness is flagged for later preprocessing (predictors) or dropping (targets) with complete transparency. This approach maintains data integrity while deferring sophisticated imputation to the preprocessing phase where it belongs.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=ac12d32a"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="4.5.-Professional-Data-Cleaning-Checklist">4.5. Professional Data Cleaning Checklist<a class="anchor-link" href="#4.5.-Professional-Data-Cleaning-Checklist">¶</a></h3><p>Here's your consultant-ready workflow for any data cleaning project:</p>
<p><strong>Phase 1: Foundation</strong></p>
<ul>
<li class="task-list-item"><input class="task-list-item-checkbox" disabled="" type="checkbox"/>Standardize timeline (collapse duplicates, enforce continuity)</li>
<li class="task-list-item"><input class="task-list-item-checkbox" disabled="" type="checkbox"/>Add flags for all structural changes</li>
</ul>
<p><strong>Phase 2: The Three-Step Decision Process</strong>
For every suspicious value:</p>
<ul>
<li class="task-list-item"><input class="task-list-item-checkbox" disabled="" type="checkbox"/><strong>Step 1:</strong> Event or error? (Context check)</li>
<li class="task-list-item"><input class="task-list-item-checkbox" disabled="" type="checkbox"/><strong>Step 2:</strong> If error, can I fix with a rule? (Apply fix + flag)</li>
<li class="task-list-item"><input class="task-list-item-checkbox" disabled="" type="checkbox"/><strong>Step 3:</strong> If unfixable, impute or drop? (Predictors vs. targets)</li>
</ul>
<p><strong>Phase 3: Documentation</strong></p>
<ul>
<li class="task-list-item"><input class="task-list-item-checkbox" disabled="" type="checkbox"/>Flag every intervention with clear labels</li>
<li class="task-list-item"><input class="task-list-item-checkbox" disabled="" type="checkbox"/>Document aggregation policies and business logic</li>
<li class="task-list-item"><input class="task-list-item-checkbox" disabled="" type="checkbox"/>Quantify impact ("15% of weather data imputed")</li>
<li class="task-list-item"><input class="task-list-item-checkbox" disabled="" type="checkbox"/>Prepare client communication on data limitations</li>
</ul>
<p><strong>Quality Gates:</strong></p>
<ul>
<li>✅ No impossible values remain</li>
<li>✅ Timeline is continuous and complete</li>
<li>✅ Every change is flagged and traceable</li>
<li>✅ Client can understand what was done and why</li>
</ul>
<p>This checklist ensures your cleaning is not just thorough, but <strong>defendable to clients and auditable by colleagues</strong>.</p>
<hr/>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" id="cell-id=c9af29d9"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Summary-and-Transition-to-Feature-Engineering-Implementation">Summary and Transition to Feature Engineering Implementation<a class="anchor-link" href="#Summary-and-Transition-to-Feature-Engineering-Implementation">¶</a></h2><p>You've mastered essential data quality assessment and cleaning techniques: systematic missing data analysis, outlier detection, and validation workflows. These skills transform messy real-world datasets into reliable, analytical-grade information.</p>
<p>Your expertise in data completeness assessment, systematic cleaning procedures, and quality validation creates the trustworthy foundation needed for all advanced analysis. This technical rigor combined with business judgment enables you to work confidently with complex transportation datasets while maintaining analytical integrity.</p>
<p>In our next lecture, we'll build on this clean data foundation by learning advanced feature engineering and preprocessing techniques that prepare your data for machine learning models. You'll see how quality data translates into effective model-ready features for predictive analytics.</p>
</div>
</div>
</div>
</div>
</div>
</main>

        </div>
    </div>
</body>
</html>
