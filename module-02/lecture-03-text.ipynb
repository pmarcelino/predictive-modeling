{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aad4a8ea",
   "metadata": {},
   "source": [
    "# Lecture 3: Introduction to Pandas & Data Structures - Building Your Foundation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed90651a",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "By the end of this lecture, you will be able to:\n",
    "\n",
    "- Import and understand the pandas library for data manipulation\n",
    "- Work with pandas Series and DataFrame structures effectively\n",
    "- Load and inspect the Washington D.C. bike-sharing dataset\n",
    "- Understand basic data types and structures in Python data analysis\n",
    "- Apply fundamental pandas operations for basic data exploration\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee13cef7",
   "metadata": {},
   "source": [
    "## 1. Your Journey as a Data Consultant Begins\n",
    "\n",
    "Welcome to your first day as a junior data consultant! Your client, a growing bike-sharing startup, has asked you to help them understand their data and build better demand forecasting capabilities. Like any professional consultant, you need to start with the fundamentals - understanding your tools and your data.\n",
    "\n",
    "Think of this like learning to be a craftsperson. Before a carpenter builds a house, they master their tools: saws, hammers, measuring devices. As a data consultant, your primary tools are programming languages and libraries - and pandas is the most essential tool for data work in Python.\n",
    "\n",
    "Today, you'll learn **pandas** not as an abstract programming concept, but as the foundation that will enable you to help your client make better business decisions. Every technique you master here will directly contribute to solving real transportation challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68600935",
   "metadata": {},
   "source": [
    "## 2. The Pandas Library: Your Data Manipulation Powerhouse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57db502",
   "metadata": {},
   "source": [
    "### 2.1. What is Pandas and Why Do You Need It?\n",
    "\n",
    "Pandas is like having a powerful Swiss Army knife for working with data. Just as a mechanic wouldn't try to fix a car with just their bare hands, you wouldn't want to analyze data without pandas. It provides the tools you need to load, clean, and manipulate data efficiently.\n",
    "\n",
    "For your bike-sharing client, this means pandas will help you in tasks such as:\n",
    "\n",
    "- Load their historical rental data from files\n",
    "- Clean and prepare messy real-world data\n",
    "- Transform raw operational data into actionable insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6637e5",
   "metadata": {},
   "source": [
    "### 2.2. Understanding Your Data Toolkit Components\n",
    "\n",
    "Pandas provides two fundamental structures for organizing data, much like how a workshop has different types of containers for different purposes:\n",
    "\n",
    "1. **Series**: Like a single column of a spreadsheet. Perfect for storing one type of information (like all the temperatures recorded).\n",
    "2. **DataFrame**: Like a complete spreadsheet with rows and columns. This is where you'll store your full bike-sharing dataset with all variables together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e591d653",
   "metadata": {},
   "source": [
    "### Importing Pandas: Setting Up Your Workshop\n",
    "\n",
    "Before you can use any tool, you need to make it available in your workspace. In Python, this means importing pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c4f7a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0513d690",
   "metadata": {},
   "source": [
    "> **Note:** This is your first chance to try out Google Colab. Click **\"Open in Colab\"**, select this cell, and press **Shift+Enter** to run it. Nothing visible will happen yet—that’s normal! This step simply loads the **pandas** library. The notebook already shows executed results, but we encourage you to run the code yourself.\n",
    "\n",
    "This simple line does several important things:\n",
    "\n",
    "- Makes all pandas functions available to use\n",
    "- Creates the shorthand `pd` so you don't have to type `pandas` every time\n",
    "- Follows the standard convention that all Python data analysts use\n",
    "\n",
    "The `as pd` part is like giving pandas a nickname that everyone in the data science community recognizes. When you see `pd.` in code, you immediately know you're working with pandas operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbe81da",
   "metadata": {},
   "source": [
    "## 3. Series: Your First Data Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b07f60a",
   "metadata": {},
   "source": [
    "### 3.1. Understanding Series Through Bike-Sharing Examples\n",
    "\n",
    "A Series is like a single column of data with labels for each value. Imagine you're tracking the number of bikes rented each hour during a typical Monday morning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0184ab17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     15\n",
      "1     23\n",
      "2     45\n",
      "3     67\n",
      "4     89\n",
      "5    156\n",
      "6    234\n",
      "7    287\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "hourly_rentals = pd.Series([15, 23, 45, 67, 89, 156, 234, 287])\n",
    "print(hourly_rentals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c84bbc",
   "metadata": {},
   "source": [
    "Explanation of the code:\n",
    "\n",
    "- `pd.Series([15, 23, 45, 67, 89, 156, 234, 287])` creates a pandas Series and saves it to the variable `hourly_rentals`. The numbers inside the list represent the bike rentals for each hour in sequence. For example, the first value `15` represents the number of bikes rented at the first hour.\n",
    "- By default, pandas automatically assigns an **index** to each value, starting at 0. So the first value `15` gets index 0, the second value `23` gets index 1, and so on.\n",
    "- `print(hourly_rentals)` displays the Series, showing both the index and the values side by side, as you can see in the presented output below the code.\n",
    "\n",
    "Now let’s make the example more realistic by using actual time labels instead of default numeric indexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ec129a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 AM      23\n",
      "7 AM      67\n",
      "8 AM     156\n",
      "9 AM      89\n",
      "10 AM     45\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "morning_hours = ['6 AM', '7 AM', '8 AM', '9 AM', '10 AM']\n",
    "morning_rentals = pd.Series([23, 67, 156, 89, 45], index=morning_hours)\n",
    "print(morning_rentals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c377301",
   "metadata": {},
   "source": [
    "What’s new here:\n",
    "\n",
    "- We added a custom index using the list `morning_hours = ['6 AM', '7 AM', '8 AM', '9 AM', '10 AM']`.\n",
    "- By passing this list as the `index` argument, each rental value is now linked to a specific time label (e.g., `8 AM → 156`).\n",
    "\n",
    "This makes the Series easier to interpret. For example, you can instantly see that **8 AM has the highest rental count (156 bikes)**, which matches the expected morning commute peak."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e047e4d",
   "metadata": {},
   "source": [
    "### 3.2. Why Series Matter for Your Consulting Work\n",
    "\n",
    "Series are more than just lists - they're intelligent containers that:\n",
    "\n",
    "- Keep related information together (values and their meanings)\n",
    "- Enable mathematical operations (calculating averages, totals, trends)\n",
    "- Support easy filtering and selection (finding peak hours, low-demand periods)\n",
    "\n",
    "For transportation consulting, Series help you organize time-based patterns, station-specific metrics, and categorical data like weather conditions or user types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421e53ef",
   "metadata": {},
   "source": [
    "## 4. DataFrame: Your Complete Data Laboratory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9dd356",
   "metadata": {},
   "source": [
    "### 4.1. Understanding DataFrames as Digital Spreadsheets\n",
    "\n",
    "If Series are like single columns, DataFrames are like complete spreadsheets with multiple columns and rows. For your bike-sharing client, a DataFrame would contain all the information about each rental period: time, weather, bike counts, user types, and more.\n",
    "\n",
    "Think of a DataFrame as a comprehensive record where each row represents one time period (like one hour) and each column represents one type of measurement (like temperature, humidity, bike count).\n",
    "\n",
    "Let's build a small DataFrame that represents what your client's data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ace893b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   hour  temperature  rentals        weather\n",
      "0  6 AM           45       23          Clear\n",
      "1  7 AM           47       67          Clear\n",
      "2  8 AM           52      156  Partly Cloudy\n",
      "3  9 AM           55       89          Clear\n"
     ]
    }
   ],
   "source": [
    "bike_data = pd.DataFrame({\n",
    "    'hour': ['6 AM', '7 AM', '8 AM', '9 AM'],\n",
    "    'temperature': [45, 47, 52, 55],\n",
    "    'rentals': [23, 67, 156, 89],\n",
    "    'weather': ['Clear', 'Clear', 'Partly Cloudy', 'Clear']\n",
    "})\n",
    "print(bike_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f276bd9f",
   "metadata": {},
   "source": [
    "Explanation of the code:\n",
    "\n",
    "- `bike_data = pd.DataFrame({...})` This line creates a pandas `DataFrame` with the name `bike_data`.\n",
    "- Inside the curly braces `{ ... }`, we define the DataFrame as a dictionary:\n",
    "  - Each **key** (e.g., `hour`, `temperature`, `rentals`, `weather`) becomes a **column name**.\n",
    "  - Each **list of values** associated with the key (e.g., `[45, 47, 52, 55]` for temperature) becomes the **column data**.\n",
    "  - All lists must be the **same length**, because each position across the lists corresponds to one row in the table.\n",
    "- In this example:\n",
    "  - `'hour'` marks the time of day.\n",
    "  - `'temperature'` gives the measured temperature (we used Fahrenheit in this example).\n",
    "  - `'rentals'` shows the number of bikes rented.\n",
    "  - `'weather'` describes conditions during that hour.\n",
    "- `print(bike_data)` displays the DataFrame in a structured, tabular format - as  you can see in the presented output below the code - where each row represents one observation (an hour of operations), and each column represents one variable being tracked.\n",
    "\n",
    "This DataFrame builds on what you just learned about Series. Instead of working with a single column of data, you now have **multiple Series combined side by side** in one structured table. Each row corresponds to a specific hour, while each column captures a different type of measurement (time, temperature, rentals, weather). This way, all the related information for each hour stays neatly aligned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee21519",
   "metadata": {},
   "source": [
    "### 4.2. Why DataFrame Matter for Your Consulting Work\n",
    "\n",
    "Every DataFrame has key components that make it powerful for business analysis:\n",
    "\n",
    "- **Columns**: Each variable you're tracking (temperature, rentals, weather conditions). These become the factors you'll analyze to understand demand patterns.\n",
    "- **Rows**: Each observation or time period. In transportation, this is usually time-based (hourly, daily) but could be trip-based or station-based.\n",
    "- **Index**: The row identifiers. By default, these are numbers (0, 1, 2), but you can use dates, station IDs, or other meaningful identifiers.\n",
    "- **Values**: The actual data inside the table. This is the business information you'll analyze to generate insights and predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5793b3cd",
   "metadata": {},
   "source": [
    "## 5. Loading Real-World Data: Working with the Washington D.C. Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb11c8d1",
   "metadata": {},
   "source": [
    "### 5.1. Understanding Your Client's Data Source\n",
    "\n",
    "Now that you’re familiar with Series and DataFrame structures, it’s time to put them into action. Your bike-sharing startup client has provided you with historical data from the Washington D.C. bike-sharing system. This dataset will serve as the foundation for your consulting work throughout the course.\n",
    "\n",
    "What makes this dataset valuable is that it mirrors the complexity of real consulting projects:\n",
    "\n",
    "- **Multiple variables** capturing different aspects of the system (e.g., temperature, weather conditions, user types)\n",
    "- **Mixed data types** that require careful handling\n",
    "- **Time series information** essential for demand prediction\n",
    "- And, of course, the **messiness of real-world operations**\n",
    "\n",
    "By working with this data, you’ll gain hands-on experience tackling the same challenges professionals face when preparing transportation datasets for machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3885db1",
   "metadata": {},
   "source": [
    "### 5.2. The Data Loading Process\n",
    "\n",
    "Loading data from files is the first step of the consulting process. In this case, your client's data is stored in CSV (Comma-Separated Values) format, a standard way of sharing tabular data between systems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f0d2ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to your data file\n",
    "data_path = \"https://raw.githubusercontent.com/pmarcelino/predictive-modeling/main/dataset/dataset.csv\"\n",
    "\n",
    "# Load the data into a DataFrame\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd314ba1",
   "metadata": {},
   "source": [
    "The command `pd.read_csv()` tells pandas to:\n",
    "\n",
    "1. **Read** the file located at the given path (`data_path` in this case), line by line.\n",
    "2. **Break** each row of text into separate pieces of information whenever it finds a comma (each piece becomes a column value).\n",
    "3. **Store** the resulting table in a **DataFrame**, pandas’ main data structure for tabular data.\n",
    "\n",
    "In other words, this function converts raw CSV text into a structured DataFrame you can immediately start analyzing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e62c6ca",
   "metadata": {},
   "source": [
    "## 6. Essential DataFrame Operations for Transportation Analysis\n",
    "\n",
    "Once your data is loaded, the next step is to get familiar with it. As a consultant, you don’t dive straight into modeling — you first **inspect and summarize** the dataset. This quick overview not only builds your own understanding but also helps you explain the data’s scope and quality to your client.\n",
    "\n",
    "Let's go through some of the most important operations to start with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb95fc2",
   "metadata": {},
   "source": [
    "### 6.1. Shape of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bda09cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 10886 rows and 12 columns\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset contains {df.shape[0]} rows and {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174a839f",
   "metadata": {},
   "source": [
    "This tells us that the dataset contains **10,886 hourly records** and **12 variables**. For your client, this means there is a solid amount of historical data available — enough to build models that can capture patterns across different times and conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b10a5e0",
   "metadata": {},
   "source": [
    "### 6.2. Column Information and Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7843580d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10886 entries, 0 to 10885\n",
      "Data columns (total 12 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   datetime    10886 non-null  object \n",
      " 1   season      10886 non-null  int64  \n",
      " 2   holiday     10886 non-null  int64  \n",
      " 3   workingday  10886 non-null  int64  \n",
      " 4   weather     10886 non-null  int64  \n",
      " 5   temp        10886 non-null  float64\n",
      " 6   atemp       10886 non-null  float64\n",
      " 7   humidity    10886 non-null  int64  \n",
      " 8   windspeed   10886 non-null  float64\n",
      " 9   casual      10886 non-null  int64  \n",
      " 10  registered  10886 non-null  int64  \n",
      " 11  count       10886 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(1)\n",
      "memory usage: 1020.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47f276d",
   "metadata": {},
   "source": [
    "The `.info()` method shows all the variables, their data types, and whether they contain missing values.\n",
    "\n",
    "- We see that every column has **10,886 non-null entries**, meaning no missing data — excellent news for reliability.\n",
    "- Variables like season, holiday, and count are stored as integers, while temperature-related variables are floats.\n",
    "- The datetime column is still an object (text), which we’ll later convert to a proper date-time format for time-based analysis.\n",
    "\n",
    "This overview helps you spot potential issues early, such as incorrect data types or missing values that could affect modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e670dc",
   "metadata": {},
   "source": [
    "### 6.3. Previewing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "de380fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              datetime  season  holiday  workingday  weather  temp   atemp  \\\n",
      "0  2011-01-01 00:00:00       1        0           0        1  9.84  14.395   \n",
      "1  2011-01-01 01:00:00       1        0           0        1  9.02  13.635   \n",
      "2  2011-01-01 02:00:00       1        0           0        1  9.02  13.635   \n",
      "3  2011-01-01 03:00:00       1        0           0        1  9.84  14.395   \n",
      "4  2011-01-01 04:00:00       1        0           0        1  9.84  14.395   \n",
      "\n",
      "   humidity  windspeed  casual  registered  count  \n",
      "0        81        0.0       3          13     16  \n",
      "1        80        0.0       8          32     40  \n",
      "2        80        0.0       5          27     32  \n",
      "3        75        0.0       3          10     13  \n",
      "4        75        0.0       0           1      1  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560e7ec8",
   "metadata": {},
   "source": [
    "The `.head()` command lets you **peek at the first rows** of the dataset. Here you can immediately recognize the structure: a datetime stamp, contextual variables (season, weather), and usage metrics (casual, registered, and total count). This helps you explain to your client what kind of data is being tracked."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a92176",
   "metadata": {},
   "source": [
    "### 6.4. Quick Statistical Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c8c7dc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             season       holiday    workingday       weather         temp  \\\n",
      "count  10886.000000  10886.000000  10886.000000  10886.000000  10886.00000   \n",
      "mean       2.506614      0.028569      0.680875      1.418427     20.23086   \n",
      "std        1.116174      0.166599      0.466159      0.633839      7.79159   \n",
      "min        1.000000      0.000000      0.000000      1.000000      0.82000   \n",
      "25%        2.000000      0.000000      0.000000      1.000000     13.94000   \n",
      "50%        3.000000      0.000000      1.000000      1.000000     20.50000   \n",
      "75%        4.000000      0.000000      1.000000      2.000000     26.24000   \n",
      "max        4.000000      1.000000      1.000000      4.000000     41.00000   \n",
      "\n",
      "              atemp      humidity     windspeed        casual    registered  \\\n",
      "count  10886.000000  10886.000000  10886.000000  10886.000000  10886.000000   \n",
      "mean      23.655084     61.886460     12.799395     36.021955    155.552177   \n",
      "std        8.474601     19.245033      8.164537     49.960477    151.039033   \n",
      "min        0.760000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%       16.665000     47.000000      7.001500      4.000000     36.000000   \n",
      "50%       24.240000     62.000000     12.998000     17.000000    118.000000   \n",
      "75%       31.060000     77.000000     16.997900     49.000000    222.000000   \n",
      "max       45.455000    100.000000     56.996900    367.000000    886.000000   \n",
      "\n",
      "              count  \n",
      "count  10886.000000  \n",
      "mean     191.574132  \n",
      "std      181.144454  \n",
      "min        1.000000  \n",
      "25%       42.000000  \n",
      "50%      145.000000  \n",
      "75%      284.000000  \n",
      "max      977.000000  \n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7b5d85",
   "metadata": {},
   "source": [
    "The `.describe()` method provides summary statistics for each numeric column.\n",
    "\n",
    "- Bike demand (count) ranges from **1 to 977 bikes/hour**, with an average of ~192.\n",
    "- The distribution is skewed: the median is 145, but the maximum is over 6× higher.\n",
    "- Weather variables look realistic too — temperatures span from near freezing (0.8°C) to hot summer levels (41°C).\n",
    "\n",
    "This quick check reassures both you and your client that the dataset is complete and values are plausible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c43ff6f",
   "metadata": {},
   "source": [
    "## 7. Data Types and Their Business Implications\n",
    "\n",
    "In the previous section, you learned how to take a **first snapshot of the dataset** using commands like `.shape`, `.info()`, `.head()`, and `.describe()`. One of the key things you might have noticed in the `.info()` output is that each column has a data type — for example, integers for `season`, floats for `temperature`, and text (object) for `datetime`.\n",
    "\n",
    "Data types are not just technical details. They define **what kind of analysis you can perform** and **what kind of business questions you can answer**. Misinterpreting them can lead to misleading results — for instance, treating a categorical variable like `season` as if it were a continuous number would distort any trend analysis.\n",
    "\n",
    "In transportation datasets, we usually encounter three main types of data: numerical, categorical, and temporal. Let’s look more closely at each of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852c04cc",
   "metadata": {},
   "source": [
    "### 7.1. Numerical Data\n",
    "\n",
    "Numerical data represents information that can be measured or counted. In our dataset, examples include `temp`, `humidity`, and `count`.\n",
    "\n",
    "- **Continuous variables** like temperature or humidity can take on any value within a range. These are useful for finding patterns such as *“bike usage increases gradually as temperature rises up to 25°C, but then falls in very hot conditions.”*\n",
    "- **Discrete variables** like the `count` of bikes or the number of `casual` users can only take whole numbers. These are central to forecasting business outcomes, for example, *“predicting how many bikes will be rented in the next hour.”*\n",
    "\n",
    "Because numerical variables support arithmetic, they allow for statistical summaries (means, correlations) and predictive modeling that directly inform demand forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbaf6db",
   "metadata": {},
   "source": [
    "### 7.2. Categorical Data\n",
    "\n",
    "Categorical data represents **groups or categories** rather than numeric scales. In our dataset, examples include `season`, `weather`, and `holiday`.\n",
    "\n",
    "- **Nominal categories** like `season` (spring, summer, fall, winter) have no inherent order. They are ideal for comparing performance across conditions, for example, *“Does bike demand differ between summer and winter, or are spring and fall similar in usage patterns?”*\n",
    "- **Ordinal categories** have a natural order, such as the weather severity codes (1 = clear, 2 = misty, 3 = light rain, 4 = heavy rain). These allow for ordered comparisons, like *“demand decreases steadily as weather severity worsens.”*\n",
    "\n",
    "Categorical variables are crucial for **segmentation** — helping your client understand different user groups or conditions that influence demand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b308c2",
   "metadata": {},
   "source": [
    "### 7.3. Temporal Data\n",
    "\n",
    "Temporal data captures the **dimension of time**, such as the `datetime` column in our dataset. This type of data enables consultants to uncover trends and seasonality that are invisible in static snapshots.\n",
    "\n",
    "For example:\n",
    "\n",
    "- Hourly patterns can reveal peak commuting periods.\n",
    "- Monthly or seasonal trends can guide capacity planning.\n",
    "- Long-term patterns help forecast growth and support strategic decisions, such as when to expand the fleet.\n",
    "\n",
    "Unlike other data types, temporal variables connect the dataset into a **time series**, allowing you to move from descriptive statistics toward forecasting future demand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eef3efb",
   "metadata": {},
   "source": [
    "### 7.4. Why Data Types Matter for Consultants\n",
    "\n",
    "By recognizing the role of each data type, you can match business questions with the right analytical tools:\n",
    "\n",
    "- Numerical data supports **measurement, comparison, and prediction**.\n",
    "- Categorical data enables **segmentation and condition-based insights**.\n",
    "- Temporal data allows **trend analysis and forecasting**.\n",
    "\n",
    "Together, these categories transform the dataset from raw information into a structured foundation for business recommendations.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebc6df4",
   "metadata": {},
   "source": [
    "## Summary and Transition to Data Quality Implementation\n",
    "\n",
    "Your mastery of pandas fundamentals establishes the technical foundation essential for professional transportation consulting. Understanding Series and DataFrame structures, data loading procedures, data operations, and data types provides the analytical infrastructure necessary for sophisticated business applications.\n",
    "\n",
    "The ability to load the Washington D.C. bike-sharing dataset, navigate DataFrame operations, and understand data types creates the operational foundation for all advanced analysis you'll perform as a transportation consultant in this course.\n",
    "\n",
    "In our next lecture, we'll build on this foundation by learning how to clean and prepare messy real-world data for analysis, turning the raw information into reliable insights your clients can act upon."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
