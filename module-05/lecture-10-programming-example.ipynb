{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "844b5aae",
   "metadata": {},
   "source": [
    "# Lecture 10: End-to-End Machine Learning Pipeline - Programming Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285a4396",
   "metadata": {},
   "source": [
    "## Introduction: Building a Complete Production-Ready Forecasting System\n",
    "\n",
    "Welcome to your final lecture! Over the past lectures, you've mastered essential machine learning (ML) skills: data cleaning, feature engineering, statistical analysis, visualization, linear regression, and ensemble methods. Today, you'll integrate all these skills into **one complete end-to-end pipeline** - taking Capital City Bikes from raw operational data through to production-ready demand forecasting models with rigorous evaluation and deployment recommendations.\n",
    "\n",
    "Think of this as your graduation project: you'll work through the exact workflow professional ML engineers follow daily. Starting with data validation and ending with deployment decisions, you'll see how every skill you've learned fits into the bigger picture. This isn't just about building models - it's about building **trust in your predictions** through systematic data preparation, thoughtful feature engineering, rigorous evaluation, and transparent business communication.\n",
    "\n",
    "Your client, Capital City Bikes, needs more than accurate forecasts - they need a complete system they can trust, explain to investors, and deploy confidently for their $2.3M municipal contract. Your end-to-end pipeline will demonstrate the professional rigor that justifies Series B funding rounds.\n",
    "\n",
    "> **ðŸš€ Interactive Learning Alert**\n",
    ">\n",
    "> This is a comprehensive hands-on capstone project integrating all course concepts. For the best experience:\n",
    ">\n",
    "> - **Click \"Open in Colab\"** at the bottom to run code interactively\n",
    "> - **Execute each code cell** by pressing **Shift + Enter**\n",
    "> - **Complete the challenges** to reinforce your end-to-end ML skills\n",
    "> - **Think like a professional consultant** - every decision impacts deployment success\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98506cb2",
   "metadata": {},
   "source": [
    "## Step 1: Data Quality Assessment and Cleaning\n",
    "\n",
    "Before rushing into modeling, professional consultants always validate data quality. Even with \"clean\" datasets, we systematically verify integrity, check for edge cases, and ensure our foundation is solid. This disciplined approach prevents downstream surprises and builds stakeholder confidence.\n",
    "\n",
    "**From the lecture \"Data Quality & Cleaning Essentials\"**, we learned the unified cleaning workflow: assess quality, identify issues, apply systematic fixes with transparency. Let's apply these principles to establish our reliable data foundation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19408730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the Washington D.C. bike-sharing dataset\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/pmarcelino/predictive-modeling/main/datasets/dataset.csv\")\n",
    "\n",
    "print(\"=== STEP 1: DATA QUALITY ASSESSMENT ===\\n\")\n",
    "\n",
    "# Convert datetime and sort chronologically for time series integrity\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "df = df.sort_values('datetime').reset_index(drop=True)\n",
    "\n",
    "# Quick data quality checks\n",
    "print(\"--- Structural Overview ---\")\n",
    "print(f\"Dataset shape: {df.shape[0]} rows Ã— {df.shape[1]} columns\")\n",
    "print(f\"Time range: {df['datetime'].min()} to {df['datetime'].max()}\")\n",
    "print(f\"Total hours: {len(df):,}\\n\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"--- Missing Data Assessment ---\")\n",
    "missing_summary = df.isnull().sum()\n",
    "missing_pct = (missing_summary / len(df)) * 100\n",
    "missing_df = pd.DataFrame({'Missing_Count': missing_summary, 'Missing_%': missing_pct})\n",
    "print(missing_df[missing_df['Missing_Count'] > 0])\n",
    "\n",
    "if missing_df['Missing_Count'].sum() == 0:\n",
    "    print(\"âœ“ No missing values detected - excellent data quality!\\n\")\n",
    "else:\n",
    "    print(f\"âš  Found missing values - will handle in cleaning step\\n\")\n",
    "\n",
    "# Value range validation\n",
    "print(\"--- Value Range Validation ---\")\n",
    "reasonable_ranges = {\n",
    "    'temp': (-20, 45),\n",
    "    'humidity': (0, 100),\n",
    "    'windspeed': (0, 50),\n",
    "    'count': (0, 1000)\n",
    "}\n",
    "\n",
    "issues_found = False\n",
    "for column, (min_val, max_val) in reasonable_ranges.items():\n",
    "    if column in df.columns:\n",
    "        below = (df[column] < min_val).sum()\n",
    "        above = (df[column] > max_val).sum()\n",
    "        \n",
    "        if below > 0 or above > 0:\n",
    "            issues_found = True\n",
    "            print(f\"âš  {column}: {below} values too low, {above} values too high\")\n",
    "        else:\n",
    "            print(f\"âœ“ {column}: All values within expected range [{min_val}, {max_val}]\")\n",
    "\n",
    "if not issues_found:\n",
    "    print(\"\\nâœ“ All values within reasonable ranges - data validated!\")\n",
    "\n",
    "print(f\"\\n--- Timeline Continuity Check ---\")\n",
    "# Check for duplicate timestamps\n",
    "duplicates = df['datetime'].duplicated().sum()\n",
    "print(f\"Duplicate timestamps: {duplicates}\")\n",
    "\n",
    "# Check for missing hours\n",
    "time_min, time_max = df['datetime'].min(), df['datetime'].max()\n",
    "expected_hours = pd.date_range(time_min, time_max, freq='h')\n",
    "actual_hours = df['datetime'].unique()\n",
    "missing_hours = len(expected_hours) - len(actual_hours)\n",
    "print(f\"Missing hours in timeline: {missing_hours}\")\n",
    "\n",
    "if duplicates == 0 and missing_hours == 0:\n",
    "    print(\"âœ“ Perfect timeline continuity - ready for time series analysis!\\n\")\n",
    "\n",
    "# Create clean dataset for subsequent analysis\n",
    "print(\"--- Creating Clean Dataset ---\")\n",
    "df_clean = df.copy()\n",
    "print(f\"âœ“ df_clean created: {df_clean.shape[0]} rows Ã— {df_clean.shape[1]} columns\")\n",
    "print(\"âœ“ Data quality validated and ready for feature engineering!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affd5c08",
   "metadata": {},
   "source": [
    "**What this does:**\n",
    "- Loads dataset and validates data quality systematically\n",
    "- Checks for missing values, impossible values, timeline continuity\n",
    "- Creates `df_clean` as validated foundation for the next steps\n",
    "\n",
    "**Business value:**\n",
    "This systematic validation ensures Capital City Bikes can trust their data foundation. Any quality issues are identified and resolved transparently before they contaminate modeling results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2497188",
   "metadata": {},
   "source": [
    "### Challenge 1: Outlier Detection and Investigation\n",
    "\n",
    "Your client asks: \"Are there any unusual windspeed conditions we should investigate before modeling?\" Implement outlier detection using the IQR method to identify extreme windspeed periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbcf1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - detect outliers using IQR method\n",
    "\n",
    "# Calculate IQR (Interquartile Range) for windspeed\n",
    "Q1 = df_clean['_____'].quantile(_____)  # 25th percentile\n",
    "Q3 = df_clean['_____'].quantile(_____)  # 75th percentile\n",
    "IQR = _____ - _____\n",
    "\n",
    "# Define outlier boundaries\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Identify outliers\n",
    "outliers = df_clean[(df_clean['windspeed'] < _____) | (df_clean['windspeed'] > _____)]\n",
    "\n",
    "print(f\"=== OUTLIER DETECTION (IQR METHOD) ===\")\n",
    "print(f\"Q1 (25th percentile): {Q1:.2f} (scaled)\")\n",
    "print(f\"Q3 (75th percentile): {Q3:.2f} (scaled)\")\n",
    "print(f\"IQR: {IQR:.2f} (scaled)\")\n",
    "print(f\"Lower bound: {lower_bound:.2f} (scaled)\")\n",
    "print(f\"Upper bound: {upper_bound:.2f} (scaled)\")\n",
    "print(f\"Outliers detected: {len(outliers)} observations ({len(outliers)/len(df_clean)*100:.1f}%)\")\n",
    "\n",
    "# Examine top outliers\n",
    "if len(outliers) > 0:\n",
    "    print(\"\\nTop 5 high-windspeed outliers:\")\n",
    "    print(outliers.nlargest(5, 'windspeed')[['datetime', 'temp', 'windspeed', 'weather', 'count']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f79918",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ðŸ’¡ <strong>Tip</strong> (click to expand)</summary>\n",
    "\n",
    "The IQR method uses quartiles to define outlier boundaries: Q1 (25th percentile) and Q3 (75th percentile) define the \"box\" in a box plot, IQR = Q3 - Q1 is the box height. Standard outlier boundaries are Q1 - 1.5Ã—IQR (lower) and Q3 + 1.5Ã—IQR (upper). Use `.quantile(0.25)` for Q1 and `.quantile(0.75)` for Q3. Filter outliers with boolean indexing: `df[(df['windspeed'] < lower_bound) | (df['windspeed'] > upper_bound)]`. The `|` operator means \"OR\" - values below lower bound OR above upper bound. Examine outliers using `.nlargest(5, 'windspeed')` to see if they're legitimate events (storms, extreme weather) or measurement errors. At this stage, windspeed is still in original units (0-67 normalized scale from the dataset), so outlier boundaries will be in these original units. High windspeed outliers may indicate extreme weather events that significantly impact bike demand, so we typically flag them for transparency in reporting to clients.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aea9b8",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ðŸ¤« <strong>Solution</strong> (click to expand)</summary>\n",
    "\n",
    "```python\n",
    "# Calculate IQR for windspeed\n",
    "Q1 = df_clean['windspeed'].quantile(0.25)\n",
    "Q3 = df_clean['windspeed'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define outlier boundaries\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Identify outliers\n",
    "outliers = df_clean[(df_clean['windspeed'] < lower_bound) | (df_clean['windspeed'] > upper_bound)]\n",
    "\n",
    "print(f\"=== OUTLIER DETECTION (IQR METHOD) ===\")\n",
    "print(f\"Q1 (25th percentile): {Q1:.2f} (scaled)\")\n",
    "print(f\"Q3 (75th percentile): {Q3:.2f} (scaled)\")\n",
    "print(f\"IQR: {IQR:.2f} (scaled)\")\n",
    "print(f\"Lower bound: {lower_bound:.2f} (scaled)\")\n",
    "print(f\"Upper bound: {upper_bound:.2f} (scaled)\")\n",
    "print(f\"Outliers detected: {len(outliers)} observations ({len(outliers)/len(df_clean)*100:.1f}%)\")\n",
    "\n",
    "# Examine top outliers\n",
    "if len(outliers) > 0:\n",
    "    print(\"\\nTop 5 high-windspeed outliers:\")\n",
    "    print(outliers.nlargest(5, 'windspeed')[['datetime', 'temp', 'windspeed', 'weather', 'count']])\n",
    "    \n",
    "    # Add outlier flag for transparency\n",
    "    df_clean['is_windspeed_outlier'] = ((df_clean['windspeed'] < lower_bound) | (df_clean['windspeed'] > upper_bound)).astype(int)\n",
    "    print(f\"\\nâœ“ Windspeed outliers flagged for transparency in analysis\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9652f35",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5a5d23",
   "metadata": {},
   "source": [
    "## Step 2: Feature Engineering and Preprocessing\n",
    "\n",
    "With validated data, we now engineer features that expose patterns for machine learning. **From the lectures in the module \"Data Preparation\"**, we learned categorical encoding, feature scaling, cyclical time encoding, and temporal features. These transformations convert raw data into optimized machine learning inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe95f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import preprocessing tools\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(\"=== STEP 2: FEATURE ENGINEERING ===\\n\")\n",
    "\n",
    "# Extract temporal components from datetime\n",
    "print(\"--- Temporal Feature Extraction ---\")\n",
    "df_clean['hour'] = df_clean['datetime'].dt.hour\n",
    "df_clean['dayofweek'] = df_clean['datetime'].dt.dayofweek\n",
    "df_clean['month'] = df_clean['datetime'].dt.month\n",
    "\n",
    "print(f\"âœ“ Extracted: hour (0-23), dayofweek (0-6), month (1-12)\")\n",
    "\n",
    "# Binary indicators for business-critical conditions\n",
    "print(\"\\n--- Binary Indicator Creation ---\")\n",
    "rush_hours = [7, 8, 9, 17, 18, 19]\n",
    "df_clean['is_rush_hour'] = df_clean['hour'].isin(rush_hours).astype(int)\n",
    "df_clean['is_weekend'] = df_clean['dayofweek'].isin([5, 6]).astype(int)\n",
    "df_clean['is_night'] = ((df_clean['hour'] >= 22) | (df_clean['hour'] <= 5)).astype(int)\n",
    "\n",
    "print(f\"âœ“ is_rush_hour: {df_clean['is_rush_hour'].mean()*100:.1f}% of hours\")\n",
    "print(f\"âœ“ is_weekend: {df_clean['is_weekend'].mean()*100:.1f}% of hours\")\n",
    "print(f\"âœ“ is_night: {df_clean['is_night'].mean()*100:.1f}% of hours\")\n",
    "\n",
    "# Cyclical encoding for continuous time (hour and day cycles)\n",
    "print(\"\\n--- Cyclical Time Encoding ---\")\n",
    "df_clean['hour_sin'] = np.sin(2 * np.pi * df_clean['hour'] / 24)\n",
    "df_clean['hour_cos'] = np.cos(2 * np.pi * df_clean['hour'] / 24)\n",
    "df_clean['day_sin'] = np.sin(2 * np.pi * df_clean['dayofweek'] / 7)\n",
    "df_clean['day_cos'] = np.cos(2 * np.pi * df_clean['dayofweek'] / 7)\n",
    "\n",
    "print(f\"âœ“ Hour cycle: hour_sin, hour_cos (24-hour continuity)\")\n",
    "print(f\"âœ“ Day cycle: day_sin, day_cos (7-day continuity)\")\n",
    "\n",
    "# Verify cyclical encoding works (hour 23 should be close to hour 0)\n",
    "hour_23_encoding = df_clean[df_clean['hour'] == 23][['hour_sin', 'hour_cos']].iloc[0]\n",
    "hour_0_encoding = df_clean[df_clean['hour'] == 0][['hour_sin', 'hour_cos']].iloc[0]\n",
    "print(f\"\\nVerification - Hour 23: sin={hour_23_encoding['hour_sin']:.3f}, cos={hour_23_encoding['hour_cos']:.3f}\")\n",
    "print(f\"Verification - Hour 0:  sin={hour_0_encoding['hour_sin']:.3f}, cos={hour_0_encoding['hour_cos']:.3f}\")\n",
    "print(\"âœ“ Values are close - cyclical continuity preserved!\")\n",
    "\n",
    "# Feature scaling for weather variables\n",
    "print(\"\\n--- Feature Scaling (Weather Variables) ---\")\n",
    "weather_features = ['temp', 'atemp', 'humidity', 'windspeed']\n",
    "\n",
    "print(\"Before scaling:\")\n",
    "print(df_clean[weather_features].describe().loc[['mean', 'std']].round(2))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_clean[weather_features] = scaler.fit_transform(df_clean[weather_features])\n",
    "\n",
    "print(\"\\nAfter scaling:\")\n",
    "print(df_clean[weather_features].describe().loc[['mean', 'std']].round(3))\n",
    "print(\"âœ“ Weather features standardized (meanâ‰ˆ0, stdâ‰ˆ1)\")\n",
    "\n",
    "# Lag features for sequential patterns\n",
    "print(\"\\n--- Lag Feature Creation ---\")\n",
    "df_clean['demand_lag_1h'] = df_clean['count'].shift(1)\n",
    "df_clean['demand_lag_24h'] = df_clean['count'].shift(24)\n",
    "\n",
    "# Handle NaN values created by shift\n",
    "df_clean['demand_lag_1h'] = df_clean['demand_lag_1h'].fillna(df_clean['count'].mean())\n",
    "df_clean['demand_lag_24h'] = df_clean['demand_lag_24h'].fillna(df_clean['count'].mean())\n",
    "\n",
    "print(f\"âœ“ demand_lag_1h: Previous hour's demand (captures momentum)\")\n",
    "print(f\"âœ“ demand_lag_24h: Same hour yesterday (captures daily patterns)\")\n",
    "\n",
    "# Check lag feature correlations\n",
    "corr_1h = df_clean['count'].corr(df_clean['demand_lag_1h'])\n",
    "corr_24h = df_clean['count'].corr(df_clean['demand_lag_24h'])\n",
    "print(f\"\\nLag correlations with current demand:\")\n",
    "print(f\"  1-hour lag:  r = {corr_1h:.3f}\")\n",
    "print(f\"  24-hour lag: r = {corr_24h:.3f}\")\n",
    "\n",
    "print(f\"\\nâœ“ Feature engineering complete: {len(df_clean.columns)} total columns\")\n",
    "print(\"âœ“ Ready for exploratory analysis and modeling!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899a59f1",
   "metadata": {},
   "source": [
    "**What this does:**\n",
    "- Extracts temporal components (hour, day, month) from datetime\n",
    "- Creates binary indicators for operational segments (rush hour, weekend, night)\n",
    "- Implements cyclical encoding ensuring time continuity (11pm â†’ midnight)\n",
    "- Scales weather features to comparable ranges (mean=0, std=1)\n",
    "- Generates lag features capturing sequential demand patterns\n",
    "- Validates feature quality through correlation analysis\n",
    "\n",
    "**Business value:**\n",
    "These engineered features transform raw measurements into ML-ready predictors that expose temporal patterns, operational contexts, and sequential dependencies - the patterns that drive accurate demand forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4ea626",
   "metadata": {},
   "source": [
    "### Challenge 2: Create Rolling Window Features\n",
    "\n",
    "Your client asks: \"Can we capture demand trends over recent hours? I'd like to understand short-term and daily patterns.\" Implement rolling window features that summarize recent demand history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b36b276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - create rolling window features\n",
    "\n",
    "# 3-hour rolling average (short-term trend)\n",
    "df_clean['demand_3h_avg'] = df_clean['count'].shift(1).rolling(window=_____, min_periods=1)._____()\n",
    "\n",
    "# 24-hour rolling average (daily baseline)\n",
    "df_clean['demand_24h_avg'] = df_clean['count'].shift(1).rolling(window=_____, min_periods=1)._____()\n",
    "\n",
    "print(\"=== ROLLING WINDOW FEATURES ===\")\n",
    "print(f\"âœ“ demand_3h_avg: Rolling average of past 3 hours (short-term trend)\")\n",
    "print(f\"âœ“ demand_24h_avg: Rolling average of past 24 hours (daily baseline)\")\n",
    "\n",
    "# Visualize rolling patterns\n",
    "print(f\"\\n3-hour rolling average statistics:\")\n",
    "print(f\"  Mean: {df_clean['demand_3h_avg'].mean():.2f}\")\n",
    "print(f\"  Std: {df_clean['demand_3h_avg'].std():.2f}\")\n",
    "\n",
    "print(f\"\\n24-hour rolling average statistics:\")\n",
    "print(f\"  Mean: {df_clean['demand_24h_avg'].mean():.2f}\")\n",
    "print(f\"  Std: {df_clean['demand_24h_avg'].std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbb8440",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ðŸ’¡ <strong>Tip</strong> (click to expand)</summary>\n",
    "\n",
    "Rolling window features use pandas `.rolling(window=n)` to calculate statistics over the past n observations. ALWAYS use `.shift(1)` before `.rolling()` to prevent data leakage - without it, the current value you're trying to predict gets included in the \"past\" window! The pattern is: `df['count'].shift(1).rolling(window=3).mean()` for a 3-hour average. Use `window=3` for short-term trends and `window=24` for daily baselines. Set `min_periods=1` to handle the first few rows where full windows aren't available. The 3-hour average captures immediate trends (is demand rising or falling in the past few hours?), while the 24-hour average provides a stable daily baseline that accounts for typical patterns at each hour. These features help models understand not just current conditions but recent demand trajectories. For example, if demand_3h_avg is significantly higher than demand_24h_avg, it signals an unusual surge requiring proactive bike rebalancing.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52645f01",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ðŸ¤« <strong>Solution</strong> (click to expand)</summary>\n",
    "\n",
    "```python\n",
    "# 3-hour rolling average (short-term trend)\n",
    "df_clean['demand_3h_avg'] = df_clean['count'].shift(1).rolling(window=3, min_periods=1).mean()\n",
    "\n",
    "# 24-hour rolling average (daily baseline)\n",
    "df_clean['demand_24h_avg'] = df_clean['count'].shift(1).rolling(window=24, min_periods=1).mean()\n",
    "\n",
    "print(\"=== ROLLING WINDOW FEATURES ===\")\n",
    "print(f\"âœ“ demand_3h_avg: Rolling average of past 3 hours (short-term trend)\")\n",
    "print(f\"âœ“ demand_24h_avg: Rolling average of past 24 hours (daily baseline)\")\n",
    "\n",
    "# Visualize rolling patterns\n",
    "print(f\"\\n3-hour rolling average statistics:\")\n",
    "print(f\"  Mean: {df_clean['demand_3h_avg'].mean():.2f}\")\n",
    "print(f\"  Std: {df_clean['demand_3h_avg'].std():.2f}\")\n",
    "\n",
    "print(f\"\\n24-hour rolling average statistics:\")\n",
    "print(f\"  Mean: {df_clean['demand_24h_avg'].mean():.2f}\")\n",
    "print(f\"  Std: {df_clean['demand_24h_avg'].std():.2f}\")\n",
    "\n",
    "# Show correlation with current demand\n",
    "corr_3h = df_clean['count'].corr(df_clean['demand_3h_avg'])\n",
    "corr_24h = df_clean['count'].corr(df_clean['demand_24h_avg'])\n",
    "print(f\"\\nCorrelation with current demand:\")\n",
    "print(f\"  3-hour rolling avg:  r = {corr_3h:.3f}\")\n",
    "print(f\"  24-hour rolling avg: r = {corr_24h:.3f}\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff7da9a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e50383",
   "metadata": {},
   "source": [
    "## Step 3: Exploratory Data Analysis and Visualization\n",
    "\n",
    "Before modeling, we explore our engineered features to validate they capture real patterns. **From the lectures in module \"Data Exploration\"**, we learned statistical analysis and visualization techniques. This exploration builds confidence in our feature engineering and reveals insights that guide modeling decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d436bad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== STEP 3: EXPLORATORY DATA ANALYSIS ===\\n\")\n",
    "\n",
    "# Descriptive statistics for key variables\n",
    "print(\"--- Descriptive Statistics ---\")\n",
    "key_metrics = ['temp', 'humidity', 'windspeed', 'count']\n",
    "stats_summary = df_clean[key_metrics].describe().round(2)\n",
    "print(stats_summary)\n",
    "\n",
    "# Seasonal demand comparison\n",
    "print(\"\\n--- Seasonal Demand Patterns ---\")\n",
    "season_names = {1: 'Spring', 2: 'Summer', 3: 'Fall', 4: 'Winter'}\n",
    "df_clean['season_name'] = df_clean['season'].map(season_names)\n",
    "\n",
    "seasonal_stats = df_clean.groupby('season_name')['count'].agg(['mean', 'std', 'count']).round(1)\n",
    "print(seasonal_stats)\n",
    "\n",
    "peak_season = seasonal_stats['mean'].idxmax()\n",
    "low_season = seasonal_stats['mean'].idxmin()\n",
    "print(f\"\\nPeak season: {peak_season} ({seasonal_stats.loc[peak_season, 'mean']:.0f} bikes/hour)\")\n",
    "print(f\"Low season: {low_season} ({seasonal_stats.loc[low_season, 'mean']:.0f} bikes/hour)\")\n",
    "\n",
    "# Correlation analysis with engineered features\n",
    "print(\"\\n--- Correlation Analysis ---\")\n",
    "correlation_features = ['temp', 'humidity', 'hour', 'dayofweek', 'month',\n",
    "                        'is_rush_hour', 'is_weekend', 'demand_lag_1h', 'demand_lag_24h', 'count']\n",
    "\n",
    "# Calculate correlations with target variable\n",
    "correlations = df_clean[correlation_features].corr()['count'].sort_values(ascending=False)\n",
    "print(\"\\nFeatures ranked by correlation with demand:\")\n",
    "print(correlations.round(3))\n",
    "\n",
    "print(f\"\\nStrongest positive predictor: {correlations.index[1]} (r = {correlations.iloc[1]:.3f})\")\n",
    "print(f\"Strongest negative predictor: {correlations[correlations < 0].index[0]} (r = {correlations[correlations < 0].iloc[0]:.3f})\")\n",
    "\n",
    "# Create visualizations showcasing engineered features\n",
    "print(\"\\n--- Creating Visualizations ---\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Panel 1: Lag Feature Autocorrelation - 1-hour lag\n",
    "from scipy import stats\n",
    "slope_1h, intercept_1h, r_1h, _, _ = stats.linregress(df_clean['demand_lag_1h'], df_clean['count'])\n",
    "axes[0, 0].scatter(df_clean['demand_lag_1h'], df_clean['count'], \n",
    "                   alpha=0.3, s=10, color='steelblue', edgecolors='none')\n",
    "axes[0, 0].plot(df_clean['demand_lag_1h'], \n",
    "                slope_1h * df_clean['demand_lag_1h'] + intercept_1h,\n",
    "                'r--', linewidth=2.5, label=f'Linear fit (r = {r_1h:.3f})')\n",
    "axes[0, 0].set_xlabel('Previous Hour Demand (bikes)', fontsize=11)\n",
    "axes[0, 0].set_ylabel('Current Hour Demand (bikes)', fontsize=11)\n",
    "axes[0, 0].set_title('1-Hour Lag Correlation (Momentum)', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 2: Lag Feature Autocorrelation - 24-hour lag\n",
    "slope_24h, intercept_24h, r_24h, _, _ = stats.linregress(df_clean['demand_lag_24h'], df_clean['count'])\n",
    "axes[0, 1].scatter(df_clean['demand_lag_24h'], df_clean['count'], \n",
    "                   alpha=0.3, s=10, color='darkgreen', edgecolors='none')\n",
    "axes[0, 1].plot(df_clean['demand_lag_24h'], \n",
    "                slope_24h * df_clean['demand_lag_24h'] + intercept_24h,\n",
    "                'r--', linewidth=2.5, label=f'Linear fit (r = {r_24h:.3f})')\n",
    "axes[0, 1].set_xlabel('Same Hour Yesterday Demand (bikes)', fontsize=11)\n",
    "axes[0, 1].set_ylabel('Current Hour Demand (bikes)', fontsize=11)\n",
    "axes[0, 1].set_title('24-Hour Lag Correlation (Daily Pattern)', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 3: Binary Feature Impact - Combined view\n",
    "binary_features_data = [\n",
    "    ('Rush\\nHour', df_clean[df_clean['is_rush_hour'] == 0]['count'], \n",
    "     df_clean[df_clean['is_rush_hour'] == 1]['count']),\n",
    "    ('Weekend', df_clean[df_clean['is_weekend'] == 0]['count'], \n",
    "     df_clean[df_clean['is_weekend'] == 1]['count']),\n",
    "    ('Night\\nTime', df_clean[df_clean['is_night'] == 0]['count'], \n",
    "     df_clean[df_clean['is_night'] == 1]['count'])\n",
    "]\n",
    "\n",
    "positions = [1, 2, 4, 5, 7, 8]\n",
    "colors = ['lightblue', 'lightcoral', 'lightblue', 'lightcoral', 'lightblue', 'lightcoral']\n",
    "data_to_plot = []\n",
    "for _, no, yes in binary_features_data:\n",
    "    data_to_plot.extend([no, yes])\n",
    "\n",
    "bp = axes[1, 0].boxplot(data_to_plot, positions=positions, widths=0.6,\n",
    "                        patch_artist=True, showmeans=True,\n",
    "                        boxprops=dict(facecolor='white', edgecolor='black'),\n",
    "                        medianprops=dict(color='red', linewidth=2),\n",
    "                        meanprops=dict(marker='D', markerfacecolor='green', markersize=6))\n",
    "\n",
    "# Color the boxes\n",
    "for patch, color in zip(bp['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.7)\n",
    "\n",
    "axes[1, 0].set_xticks([1.5, 4.5, 7.5])\n",
    "axes[1, 0].set_xticklabels([name for name, _, _ in binary_features_data])\n",
    "axes[1, 0].set_ylabel('Hourly Demand (bikes)', fontsize=11)\n",
    "axes[1, 0].set_title('Binary Feature Impact on Demand Distribution', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "axes[1, 0].legend([bp['boxes'][0], bp['boxes'][1]], ['No (0)', 'Yes (1)'], \n",
    "                  loc='upper right', fontsize=9)\n",
    "\n",
    "# Panel 4: Correlation Heatmap of Engineered Features\n",
    "heatmap_features = ['temp', 'humidity', 'windspeed', 'hour_sin', 'hour_cos', \n",
    "                    'is_rush_hour', 'is_weekend', 'is_night', \n",
    "                    'demand_lag_1h', 'demand_lag_24h', 'count']\n",
    "corr_matrix = df_clean[heatmap_features].corr()\n",
    "\n",
    "im = axes[1, 1].imshow(corr_matrix, cmap='RdBu_r', aspect='auto', vmin=-1, vmax=1)\n",
    "axes[1, 1].set_xticks(range(len(heatmap_features)))\n",
    "axes[1, 1].set_yticks(range(len(heatmap_features)))\n",
    "axes[1, 1].set_xticklabels(heatmap_features, rotation=45, ha='right', fontsize=9)\n",
    "axes[1, 1].set_yticklabels(heatmap_features, fontsize=9)\n",
    "axes[1, 1].set_title('Feature Correlation Matrix', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Add correlation values for top/bottom relationships with target\n",
    "for i in range(len(heatmap_features)):\n",
    "    for j in range(len(heatmap_features)):\n",
    "        if abs(corr_matrix.iloc[i, j]) > 0.5 or (i == len(heatmap_features)-1) or (j == len(heatmap_features)-1):\n",
    "            text = axes[1, 1].text(j, i, f'{corr_matrix.iloc[i, j]:.2f}',\n",
    "                                  ha='center', va='center', fontsize=8,\n",
    "                                  color='white' if abs(corr_matrix.iloc[i, j]) > 0.5 else 'black')\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(im, ax=axes[1, 1], fraction=0.046, pad=0.04)\n",
    "cbar.set_label('Correlation', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ Visualizations complete - engineered features validated!\")\n",
    "print(f\"âœ“ Lag features show strong predictive power: 1h (r={r_1h:.3f}), 24h (r={r_24h:.3f})\")\n",
    "print(f\"âœ“ Binary features create meaningful demand segmentation\")\n",
    "print(f\"âœ“ Feature correlation matrix reveals relationships and independence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e044b27",
   "metadata": {},
   "source": [
    "**What this does:**\n",
    "- Creates four visualization panels\n",
    "- **Lag correlation scatters** (panels 1-2): Validate that demand_lag_1h and demand_lag_24h strongly predict current demand (r â‰ˆ 0.8-0.9), proving sequential patterns are captured\n",
    "- **Binary feature box plots** (panel 3): Show how is_rush_hour, is_weekend, and is_night create distinct demand distributions - visual evidence these flags segment operational contexts effectively\n",
    "- **Correlation heatmap** (panel 4): Reveals relationships among ALL engineered features - identifies redundant features (high inter-feature correlation) vs. complementary features (low inter-feature correlation but high correlation with target)\n",
    "\n",
    "**Business value:**\n",
    "These visualizations prove that Step 2 feature engineering works BEFORE investing in modeling. Strong lag correlations justify real-time demand monitoring systems. Binary feature segmentation guides operational policy (different strategies for rush hour vs. night). Correlation matrix prevents redundant data collection and identifies most cost-effective monitoring investments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba64b848",
   "metadata": {},
   "source": [
    "### Challenge 3: Create Diverse Visualization Types\n",
    "\n",
    "Your client requests: \"Can you create additional visualizations showing demand distributions and multi-dimensional patterns? We want to understand variability and combined effects.\" Create box plots and heatmaps to reveal distribution patterns and interaction effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb5eaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - create box plots and heatmap\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Panel 1: Box plot - demand distribution by weather condition\n",
    "weather_labels = {1: 'Clear', 2: 'Mist', 3: 'Light Rain', 4: 'Heavy Rain'}\n",
    "df_clean['weather_label'] = df_clean['weather'].map(weather_labels)\n",
    "\n",
    "# Create box plot showing distribution for each weather type\n",
    "weather_data = [df_clean[df_clean['weather'] == i]['count'] for i in [_____, _____, _____, _____]]\n",
    "axes[0].boxplot(weather_data, tick_labels=_____)\n",
    "axes[0].set_xlabel('Weather Condition', fontsize=11)\n",
    "axes[0].set_ylabel('Hourly Demand (bikes)', fontsize=11)\n",
    "axes[0].set_title('Demand Distribution by Weather', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Panel 2: Heatmap - demand by hour and day of week\n",
    "hourly_daily = df_clean.pivot_table(values='_____', index='_____', columns='_____', aggfunc='mean')\n",
    "sns.heatmap(hourly_daily, cmap='YlOrRd', ax=axes[1], cbar_kws={'label': 'Avg Demand'})\n",
    "axes[1].set_xlabel('Day of Week (0=Mon, 6=Sun)', fontsize=11)\n",
    "axes[1].set_ylabel('Hour of Day', fontsize=11)\n",
    "axes[1].set_title('Demand Heatmap: Hour Ã— Day Patterns', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=== ADVANCED VISUALIZATION INSIGHTS ===\")\n",
    "print(\"Box plot: Shows demand variability across weather conditions\")\n",
    "print(\"Heatmap: Reveals hour-day interaction patterns (weekday rush hours vs weekend leisure)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be02361a",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ðŸ’¡ <strong>Tip</strong> (click to expand)</summary>\n",
    "\n",
    "Box plots show distribution characteristics: the box spans Q1 to Q3 (middle 50%), the line inside is the median, whiskers extend to typical min/max, and dots are outliers. Create data list using list comprehension: `[df_clean[df_clean['weather'] == i]['count'] for i in [1, 2, 3, 4]]` gives you four arrays (one per weather type). Pass this list to `plt.boxplot()` with `labels=['Clear', 'Mist', 'Light Rain', 'Heavy Rain']`. For heatmaps, use `df.pivot_table(values='count', index='hour', columns='dayofweek', aggfunc='mean')` to create a matrix where rows=hours, columns=days, cells=average demand. Then `sns.heatmap()` with `cmap='YlOrRd'` creates color-coded visualization where darker colors = higher demand. The heatmap will instantly reveal weekday morning/evening peaks versus weekend midday patterns - visual confirmation of temporal feature importance!\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8db686",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ðŸ¤« <strong>Solution</strong> (click to expand)</summary>\n",
    "\n",
    "```python\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Panel 1: Box plot - demand distribution by weather condition\n",
    "weather_labels = {1: 'Clear', 2: 'Mist', 3: 'Light Rain', 4: 'Heavy Rain'}\n",
    "df_clean['weather_label'] = df_clean['weather'].map(weather_labels)\n",
    "\n",
    "weather_data = [df_clean[df_clean['weather'] == i]['count'] for i in [1, 2, 3, 4]]\n",
    "axes[0].boxplot(weather_data, tick_labels=['Clear', 'Mist', 'Light Rain', 'Heavy Rain'])\n",
    "axes[0].set_xlabel('Weather Condition', fontsize=11)\n",
    "axes[0].set_ylabel('Hourly Demand (bikes)', fontsize=11)\n",
    "axes[0].set_title('Demand Distribution by Weather', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Panel 2: Heatmap - demand by hour and day of week\n",
    "hourly_daily = df_clean.pivot_table(values='count', index='hour', columns='dayofweek', aggfunc='mean')\n",
    "sns.heatmap(hourly_daily, cmap='YlOrRd', ax=axes[1], cbar_kws={'label': 'Avg Demand'}, fmt='.0f')\n",
    "axes[1].set_xlabel('Day of Week (0=Mon, 6=Sun)', fontsize=11)\n",
    "axes[1].set_ylabel('Hour of Day', fontsize=11)\n",
    "axes[1].set_title('Demand Heatmap: Hour Ã— Day Patterns', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=== ADVANCED VISUALIZATION INSIGHTS ===\")\n",
    "print(\"âœ“ Box plot reveals: Clear weather has highest median and widest range\")\n",
    "print(\"âœ“ Heatmap shows: Weekday hours 8 & 17 are hottest (rush hours)\")\n",
    "print(\"âœ“ Pattern validated: Temporal features critical for accurate forecasting\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb72a7d7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088e39dc",
   "metadata": {},
   "source": [
    "## Step 4: Linear Regression Baseline Model\n",
    "\n",
    "With validated features, we build our baseline model. **From the lecture \"Linear Models for Prediction\"**, Linear Regression provides interpretable predictions with clear coefficient interpretation. This baseline establishes performance that advanced models must beat to justify their complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ab8cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modeling tools\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print(\"=== STEP 4: LINEAR REGRESSION BASELINE ===\\n\")\n",
    "\n",
    "# Define feature columns for modeling\n",
    "feature_columns = [\n",
    "    # Weather features (scaled)\n",
    "    'temp', 'atemp', 'humidity', 'windspeed',\n",
    "    # Temporal features (both raw and cyclical)\n",
    "    'hour', 'hour_sin', 'hour_cos', 'dayofweek', 'day_sin', 'day_cos', 'month', 'season',\n",
    "    # Categorical\n",
    "    'weather',\n",
    "    # Binary indicators\n",
    "    'workingday', 'holiday', 'is_rush_hour', 'is_weekend', 'is_night',\n",
    "    # Lag features\n",
    "    'demand_lag_1h', 'demand_lag_24h'\n",
    "]\n",
    "\n",
    "X = df_clean[feature_columns]\n",
    "y = df_clean['count']\n",
    "\n",
    "print(f\"Feature matrix: {X.shape[0]} observations Ã— {X.shape[1]} features\")\n",
    "print(f\"Features: {', '.join(feature_columns[:5])}... (and {len(feature_columns)-5} more)\")\n",
    "print(f\"Target: count (hourly bike rentals)\\n\")\n",
    "\n",
    "# Chronological train-test split (80/20)\n",
    "print(\"--- Chronological Train-Test Split ---\")\n",
    "split_index = int(len(df_clean) * 0.8)\n",
    "\n",
    "X_train = X.iloc[:split_index]\n",
    "X_test = X.iloc[split_index:]\n",
    "y_train = y.iloc[:split_index]\n",
    "y_test = y.iloc[split_index:]\n",
    "\n",
    "train_period = f\"{df_clean.iloc[:split_index]['datetime'].min()} to {df_clean.iloc[:split_index]['datetime'].max()}\"\n",
    "test_period = f\"{df_clean.iloc[split_index:]['datetime'].min()} to {df_clean.iloc[split_index:]['datetime'].max()}\"\n",
    "\n",
    "print(f\"Training set: {len(X_train):,} observations ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"  Period: {train_period}\")\n",
    "print(f\"Testing set:  {len(X_test):,} observations ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "print(f\"  Period: {test_period}\")\n",
    "print(\"âœ“ Chronological order preserved - training on past, testing on future\\n\")\n",
    "\n",
    "# Train Linear Regression model\n",
    "print(\"--- Training Linear Regression ---\")\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"âœ“ Linear model trained successfully!\")\n",
    "print(f\"Coefficients learned: {len(linear_model.coef_)} parameters\")\n",
    "\n",
    "# Show top 3 most influential features\n",
    "feature_importance_linear = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'coefficient': linear_model.coef_\n",
    "})\n",
    "feature_importance_linear['abs_coef'] = np.abs(feature_importance_linear['coefficient'])\n",
    "top_features = feature_importance_linear.nlargest(3, 'abs_coef')\n",
    "\n",
    "print(\"\\nTop 3 most influential features:\")\n",
    "for idx, row in top_features.iterrows():\n",
    "    print(f\"  {row['feature']}: {row['coefficient']:+.2f} (larger magnitude = stronger impact)\")\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"\\n--- Model Evaluation ---\")\n",
    "test_predictions_linear = linear_model.predict(X_test)\n",
    "test_r2_linear = r2_score(y_test, test_predictions_linear)\n",
    "\n",
    "print(f\"Test RÂ²: {test_r2_linear:.4f} ({test_r2_linear*100:.2f}% variance explained)\")\n",
    "\n",
    "if test_r2_linear > 0.80:\n",
    "    print(\"âœ“ Excellent performance - model explains >80% of demand variation\")\n",
    "elif test_r2_linear > 0.60:\n",
    "    print(\"âœ“ Good performance - model captures major demand patterns\")\n",
    "elif test_r2_linear > 0.40:\n",
    "    print(\"~ Moderate performance - room for improvement with advanced models\")\n",
    "else:\n",
    "    print(\"âš  Limited performance - advanced models likely needed\")\n",
    "\n",
    "# Show example predictions\n",
    "print(\"\\n--- Example Predictions (First 5 Test Observations) ---\")\n",
    "comparison = pd.DataFrame({\n",
    "    'Actual': y_test.iloc[:5].values,\n",
    "    'Predicted': test_predictions_linear[:5],\n",
    "    'Error': y_test.iloc[:5].values - test_predictions_linear[:5]\n",
    "})\n",
    "print(comparison.round(1))\n",
    "\n",
    "print(f\"\\nâœ“ Linear Regression baseline established: RÂ² = {test_r2_linear:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551d3773",
   "metadata": {},
   "source": [
    "**What this does:**\n",
    "- Selects 17 engineered features for modeling (weather, temporal, binary, lags)\n",
    "- Creates chronological 80/20 split preserving temporal integrity for honest evaluation\n",
    "- Trains LinearRegression on historical data (first 80% of timeline)\n",
    "- Evaluates on unseen future data (last 20% of timeline) using RÂ² metric\n",
    "- Shows example predictions with errors to understand model behavior\n",
    "\n",
    "**Business value:**\n",
    "Linear baseline provides interpretable performance benchmark and reveals which features have strongest linear relationships with demand. RÂ² indicates how much demand variation the simple linear model explains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75552e2",
   "metadata": {},
   "source": [
    "### Challenge 4: Feature Combination Experiments\n",
    "\n",
    "Your client asks: \"Which feature types matter most - weather or time? Can we get good performance with fewer features?\" Compare model performance using different feature combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b828a6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - compare feature combinations\n",
    "\n",
    "print(\"=== FEATURE COMBINATION EXPERIMENTS ===\\n\")\n",
    "\n",
    "# Define three feature sets to compare\n",
    "weather_features = ['temp', 'atemp', 'humidity', 'windspeed']\n",
    "time_features = ['hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'month', 'season',\n",
    "                 'is_rush_hour', 'is_weekend', 'is_night']\n",
    "full_features = feature_columns  # All 20 features\n",
    "\n",
    "# Train and evaluate models with each feature set\n",
    "feature_sets = {\n",
    "    'Weather Only': weather_features,\n",
    "    'Time Only': time_features,\n",
    "    'Full Feature Set': full_features\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, features in feature_sets.items():\n",
    "    # Train model\n",
    "    X_train_subset = X_train[_____]\n",
    "    X_test_subset = X_test[_____]\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(_____, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    predictions = model.predict(_____)\n",
    "    r2 = r2_score(y_test, _____)\n",
    "    \n",
    "    results.append({\n",
    "        'Feature Set': name,\n",
    "        'Num Features': len(_____),\n",
    "        'Test RÂ²': r2\n",
    "    })\n",
    "    \n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Features: {len(features)}\")\n",
    "    print(f\"  Test RÂ²: {r2:.4f} ({r2*100:.1f}% variance explained)\")\n",
    "    print()\n",
    "\n",
    "# Create comparison visualization\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(results_df['Feature Set'], results_df['Test RÂ²'], \n",
    "               color=['skyblue', 'lightcoral', 'lightgreen'], edgecolor='black', alpha=0.8)\n",
    "plt.ylabel('Test RÂ² Score', fontsize=12)\n",
    "plt.title('Feature Set Performance Comparison', fontsize=14, fontweight='bold')\n",
    "plt.ylim(0, max(results_df['Test RÂ²']) * 1.2)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar, r2 in zip(bars, results_df['Test RÂ²']):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, r2 + 0.01, \n",
    "             f'{r2:.3f}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Business insights\n",
    "best_set = results_df.loc[results_df['Test RÂ²'].idxmax(), 'Feature Set']\n",
    "print(f\"\\n=== INSIGHTS ===\")\n",
    "print(f\"Best performing set: {best_set}\")\n",
    "print(f\"Key finding: {'Time' if 'Time' in best_set else 'Weather' if 'Weather' in best_set else 'Combined'} features drive predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b454c2",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ðŸ’¡ <strong>Tip</strong> (click to expand)</summary>\n",
    "\n",
    "For each feature set, subset the training and testing data using `X_train[features]` where features is the list of column names. Train a fresh LinearRegression() model for each subset - don't reuse models! The pattern is: subset data â†’ create new model â†’ fit on subset training â†’ predict on subset testing â†’ calculate RÂ². Store results in a list of dictionaries for easy comparison. Weather-only features test whether environmental conditions alone can predict demand (typically rÂ² ~0.15-0.25). Time-only features test temporal patterns without weather (typically rÂ² ~0.40-0.60). Full feature set combines both (typically rÂ² ~0.65-0.80). The comparison reveals whether demand is primarily driven by when people ride (temporal) or what conditions encourage riding (weather). Business insight: If time features dominate, invest in temporal fleet positioning; if weather dominates, invest in weather-responsive operations; if combination is best, integrated strategy needed.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8910f2",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ðŸ¤« <strong>Solution</strong> (click to expand)</summary>\n",
    "\n",
    "```python\n",
    "print(\"=== FEATURE COMBINATION EXPERIMENTS ===\\n\")\n",
    "\n",
    "# Define three feature sets\n",
    "weather_features = ['temp', 'atemp', 'humidity', 'windspeed']\n",
    "time_features = ['hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'month', 'season',\n",
    "                 'is_rush_hour', 'is_weekend', 'is_night']\n",
    "full_features = feature_columns\n",
    "\n",
    "feature_sets = {\n",
    "    'Weather Only': weather_features,\n",
    "    'Time Only': time_features,\n",
    "    'Full Feature Set': full_features\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, features in feature_sets.items():\n",
    "    # Train model with feature subset\n",
    "    X_train_subset = X_train[features]\n",
    "    X_test_subset = X_test[features]\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_subset, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    predictions = model.predict(X_test_subset)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    \n",
    "    results.append({\n",
    "        'Feature Set': name,\n",
    "        'Num Features': len(features),\n",
    "        'Test RÂ²': r2\n",
    "    })\n",
    "    \n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Features: {len(features)}\")\n",
    "    print(f\"  Test RÂ²: {r2:.4f} ({r2*100:.1f}% variance explained)\")\n",
    "    print()\n",
    "\n",
    "# Visualization\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(results_df['Feature Set'], results_df['Test RÂ²'], \n",
    "               color=['skyblue', 'lightcoral', 'lightgreen'], edgecolor='black', alpha=0.8)\n",
    "plt.ylabel('Test RÂ² Score', fontsize=12)\n",
    "plt.title('Feature Set Performance Comparison', fontsize=14, fontweight='bold')\n",
    "plt.ylim(0, max(results_df['Test RÂ²']) * 1.2)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for bar, r2 in zip(bars, results_df['Test RÂ²']):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, r2 + 0.01, \n",
    "             f'{r2:.3f}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Insights\n",
    "best_set = results_df.loc[results_df['Test RÂ²'].idxmax(), 'Feature Set']\n",
    "time_r2 = results_df[results_df['Feature Set'] == 'Time Only']['Test RÂ²'].values[0]\n",
    "weather_r2 = results_df[results_df['Feature Set'] == 'Weather Only']['Test RÂ²'].values[0]\n",
    "\n",
    "print(f\"=== FEATURE SET INSIGHTS ===\")\n",
    "print(f\"âœ“ Best performing: {best_set}\")\n",
    "print(f\"âœ“ Time features alone: {time_r2:.1%} explanatory power\")\n",
    "print(f\"âœ“ Weather features alone: {weather_r2:.1%} explanatory power\")\n",
    "print(f\"âœ“ Full set: {results_df[results_df['Feature Set'] == 'Full Feature Set']['Test RÂ²'].values[0]:.1%}\")\n",
    "print(f\"\\nKey finding: {'Temporal patterns dominate' if time_r2 > weather_r2 else 'Weather conditions dominate'} bike demand\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6627a8e9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab965d1",
   "metadata": {},
   "source": [
    "## Step 5: Random Forest Ensemble Model\n",
    "\n",
    "Linear regression established our baseline. Now we deploy ensemble methods to capture non-linear patterns and feature interactions. **From the lecture \"Tree-Based Models\"**, Random Forest combines multiple decision trees to achieve superior accuracy while reducing overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346a85fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ensemble methods\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "print(\"=== STEP 5: RANDOM FOREST ENSEMBLE MODEL ===\\n\")\n",
    "\n",
    "# Train Random Forest (using same train-test split as Linear model)\n",
    "print(\"--- Training Random Forest ---\")\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100,      # 100 decision trees in the forest\n",
    "    max_depth=20,          # Limit depth to control overfitting\n",
    "    min_samples_split=20,  # Minimum samples required to split a node\n",
    "    random_state=42,\n",
    "    n_jobs=-1              # Use all CPU cores\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"âœ“ Random Forest trained: {rf_model.n_estimators} trees\")\n",
    "print(f\"âœ“ Tree depth limit: {rf_model.max_depth}\")\n",
    "print(f\"âœ“ Training completed on {len(X_train):,} observations\\n\")\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"--- Model Evaluation ---\")\n",
    "test_predictions_rf = rf_model.predict(X_test)\n",
    "test_r2_rf = r2_score(y_test, test_predictions_rf)\n",
    "\n",
    "# Also evaluate on training set to check overfitting\n",
    "train_predictions_rf = rf_model.predict(X_train)\n",
    "train_r2_rf = r2_score(y_train, train_predictions_rf)\n",
    "\n",
    "print(f\"Training RÂ²: {train_r2_rf:.4f} ({train_r2_rf*100:.2f}% variance explained)\")\n",
    "print(f\"Testing RÂ²:  {test_r2_rf:.4f} ({test_r2_rf*100:.2f}% variance explained)\")\n",
    "print(f\"Overfit gap: {train_r2_rf - test_r2_rf:.4f}\")\n",
    "\n",
    "if (train_r2_rf - test_r2_rf) < 0.10:\n",
    "    print(\"âœ“ Excellent generalization - minimal overfitting\")\n",
    "elif (train_r2_rf - test_r2_rf) < 0.20:\n",
    "    print(\"âœ“ Good generalization - acceptable overfitting\")\n",
    "else:\n",
    "    print(\"âš  Moderate overfitting - consider regularization\")\n",
    "\n",
    "# Compare to Linear baseline\n",
    "improvement = ((test_r2_rf - test_r2_linear) / test_r2_linear) * 100\n",
    "print(f\"\\n--- Performance vs Linear Baseline ---\")\n",
    "print(f\"Linear RÂ²:        {test_r2_linear:.4f}\")\n",
    "print(f\"Random Forest RÂ²: {test_r2_rf:.4f}\")\n",
    "print(f\"Improvement:      {improvement:+.1f}%\")\n",
    "\n",
    "if improvement > 10:\n",
    "    print(\"âœ“ Significant improvement - Random Forest captures non-linear patterns\")\n",
    "elif improvement > 5:\n",
    "    print(\"âœ“ Moderate improvement - ensemble methods add value\")\n",
    "else:\n",
    "    print(\"~ Marginal improvement - linear relationships dominate\")\n",
    "\n",
    "# Show example predictions\n",
    "print(\"\\n--- Example Predictions (First 5 Test Observations) ---\")\n",
    "comparison_rf = pd.DataFrame({\n",
    "    'Actual': y_test.iloc[:5].values,\n",
    "    'Linear': test_predictions_linear[:5],\n",
    "    'Random Forest': test_predictions_rf[:5],\n",
    "    'RF Error': y_test.iloc[:5].values - test_predictions_rf[:5]\n",
    "})\n",
    "print(comparison_rf.round(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c505235e",
   "metadata": {},
   "source": [
    "**What this does:**\n",
    "- Trains RandomForestRegressor with 100 trees using same train-test split as Linear model\n",
    "- Evaluates on test set with RÂ² metric for direct comparison\n",
    "- Checks train-test gap to assess overfitting (should be <0.20 for good generalization)\n",
    "- Visualizes top 10 features with horizontal bar chart for stakeholder communication\n",
    "\n",
    "**Business value:**\n",
    "Random Forest captures non-linear relationships and feature interactions Linear models miss. Feature importance guides strategic investments - showing whether to prioritize temporal optimization or weather-responsive operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68da42b1",
   "metadata": {},
   "source": [
    "### Challenge 5: Deep Feature Importance Analysis\n",
    "\n",
    "Your client asks: \"Can you analyze the feature importance patterns more deeply? I want to understand cumulative importance and identify the minimal feature set that retains most predictive power.\" Perform comprehensive feature importance analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60416f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature importance DataFrame from Random Forest model\n",
    "feature_importance_rf = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Calculate cumulative importance\n",
    "feature_importance_rf['cumulative'] = feature_importance_rf['importance'].cumsum()\n",
    "\n",
    "print(\"=== CUMULATIVE IMPORTANCE ANALYSIS ===\\n\")\n",
    "\n",
    "# Find thresholds\n",
    "for i in range(len(feature_importance_rf)):\n",
    "    cumulative = feature_importance_rf.iloc[i]['cumulative']\n",
    "    if i > 0:\n",
    "        prev_cumulative = feature_importance_rf.iloc[i-1]['cumulative']\n",
    "        if cumulative >= 0.80 and prev_cumulative < 0.80:\n",
    "            print(f\"Top {i+1} features capture 80% of predictive power\")\n",
    "        if cumulative >= 0.90 and prev_cumulative < 0.90:\n",
    "            print(f\"Top {i+1} features capture 90% of predictive power\")\n",
    "\n",
    "# Visualizations\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Panel 1: Individual importance\n",
    "top_12 = feature_importance_rf.head(12)\n",
    "colors_importance = plt.cm.RdYlGn(np.linspace(0.3, 0.9, len(top_12)))\n",
    "axes[0].barh(range(len(top_12)), top_12['importance'], color=colors_importance)\n",
    "axes[0].set_yticks(range(len(top_12)))\n",
    "axes[0].set_yticklabels(top_12['feature'])\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].set_xlabel('Importance Score', fontsize=11)\n",
    "axes[0].set_title('Individual Feature Importance', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Panel 2: Cumulative curve\n",
    "axes[1].plot(range(1, len(feature_importance_rf) + 1), \n",
    "             feature_importance_rf['cumulative'], \n",
    "             'o-', linewidth=2, markersize=6, color='darkblue')\n",
    "axes[1].axhline(y=0.80, color='orange', linestyle='--', linewidth=2, label='80%')\n",
    "axes[1].axhline(y=0.90, color='red', linestyle='--', linewidth=2, label='90%')\n",
    "axes[1].set_xlabel('Number of Top Features', fontsize=11)\n",
    "axes[1].set_ylabel('Cumulative Importance', fontsize=11)\n",
    "axes[1].set_title('Cumulative Feature Contribution', fontsize=12, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_ylim(0, 1.05)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Test reduced model\n",
    "top_features_list = feature_importance_rf.head(8)['feature'].tolist()\n",
    "\n",
    "rf_reduced = RandomForestRegressor(n_estimators=100, max_depth=20, random_state=42, n_jobs=-1)\n",
    "rf_reduced.fit(X_train[top_features_list], y_train)\n",
    "r2_reduced = r2_score(y_test, rf_reduced.predict(X_test[top_features_list]))\n",
    "\n",
    "print(f\"\\n=== REDUCED FEATURE SET TEST ===\")\n",
    "print(f\"Full model (20 features):     RÂ² = {test_r2_rf:.4f}\")\n",
    "print(f\"Reduced model (8 features):   RÂ² = {r2_reduced:.4f}\")\n",
    "print(f\"Performance retained:         {(r2_reduced/test_r2_rf)*100:.1f}%\")\n",
    "print(f\"Complexity reduction:         {((20-8)/20)*100:.0f}% fewer features\")\n",
    "\n",
    "print(f\"\\nâœ“ Top 8 features: {', '.join(top_features_list[:4])}...\")\n",
    "print(f\"{'âœ“ Recommend reduced model for production' if r2_reduced/test_r2_rf > 0.95 else 'âœ“ Recommend full model - all features provide value'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0c0794",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ðŸ’¡ <strong>Tip</strong> (click to expand)</summary>\n",
    "\n",
    "First create the feature importance DataFrame from `rf_model.feature_importances_` paired with `feature_columns`: `pd.DataFrame({'feature': feature_columns, 'importance': rf_model.feature_importances_})`. Sort by importance descending and reset the index. Cumulative importance shows how much predictive power accumulates as you add features ranked by importance. Calculate with `.cumsum()` on the sorted importance column. The cumulative curve typically shows diminishing returns: top 3 features might capture 60%, top 6 capture 80%, top 10 capture 90%. To find thresholds, iterate through cumulative values checking when they cross 0.80 and 0.90. For the reduced model test, use the top N features list: `top_features_list = feature_importance_rf.head(N)['feature'].tolist()`, then subset X_train and X_test with this list. Train a fresh Random Forest and compare its RÂ² to the full model. Business question: Can we get 95%+ of performance with 50% fewer features? If yes, the simplified model is easier to maintain and deploy. If no, all features justify their complexity. Practical rule: If top 8 features give you 95% of performance, drop the bottom 12 for production simplicity.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aead668",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ðŸ¤« <strong>Solution</strong> (click to expand)</summary>\n",
    "\n",
    "```python\n",
    "# Create feature importance DataFrame from Random Forest model\n",
    "feature_importance_rf = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Calculate cumulative importance\n",
    "feature_importance_rf['cumulative'] = feature_importance_rf['importance'].cumsum()\n",
    "\n",
    "print(\"=== CUMULATIVE IMPORTANCE ANALYSIS ===\\n\")\n",
    "\n",
    "# Find thresholds\n",
    "for i in range(len(feature_importance_rf)):\n",
    "    cumulative = feature_importance_rf.iloc[i]['cumulative']\n",
    "    if i > 0:\n",
    "        prev_cumulative = feature_importance_rf.iloc[i-1]['cumulative']\n",
    "        if cumulative >= 0.80 and prev_cumulative < 0.80:\n",
    "            print(f\"Top {i+1} features capture 80% of predictive power\")\n",
    "        if cumulative >= 0.90 and prev_cumulative < 0.90:\n",
    "            print(f\"Top {i+1} features capture 90% of predictive power\")\n",
    "\n",
    "# Visualizations\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Panel 1: Individual importance\n",
    "top_12 = feature_importance_rf.head(12)\n",
    "colors_importance = plt.cm.RdYlGn(np.linspace(0.3, 0.9, len(top_12)))\n",
    "axes[0].barh(range(len(top_12)), top_12['importance'], color=colors_importance)\n",
    "axes[0].set_yticks(range(len(top_12)))\n",
    "axes[0].set_yticklabels(top_12['feature'])\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].set_xlabel('Importance Score', fontsize=11)\n",
    "axes[0].set_title('Individual Feature Importance', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Panel 2: Cumulative curve\n",
    "axes[1].plot(range(1, len(feature_importance_rf) + 1), \n",
    "             feature_importance_rf['cumulative'], \n",
    "             'o-', linewidth=2, markersize=6, color='darkblue')\n",
    "axes[1].axhline(y=0.80, color='orange', linestyle='--', linewidth=2, label='80%')\n",
    "axes[1].axhline(y=0.90, color='red', linestyle='--', linewidth=2, label='90%')\n",
    "axes[1].set_xlabel('Number of Top Features', fontsize=11)\n",
    "axes[1].set_ylabel('Cumulative Importance', fontsize=11)\n",
    "axes[1].set_title('Cumulative Feature Contribution', fontsize=12, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_ylim(0, 1.05)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Test reduced model\n",
    "top_features_list = feature_importance_rf.head(8)['feature'].tolist()\n",
    "\n",
    "rf_reduced = RandomForestRegressor(n_estimators=100, max_depth=20, random_state=42, n_jobs=-1)\n",
    "rf_reduced.fit(X_train[top_features_list], y_train)\n",
    "r2_reduced = r2_score(y_test, rf_reduced.predict(X_test[top_features_list]))\n",
    "\n",
    "print(f\"\\n=== REDUCED FEATURE SET TEST ===\")\n",
    "print(f\"Full model (20 features):     RÂ² = {test_r2_rf:.4f}\")\n",
    "print(f\"Reduced model (8 features):   RÂ² = {r2_reduced:.4f}\")\n",
    "print(f\"Performance retained:         {(r2_reduced/test_r2_rf)*100:.1f}%\")\n",
    "print(f\"Complexity reduction:         {((20-8)/20)*100:.0f}% fewer features\")\n",
    "\n",
    "print(f\"\\nâœ“ Top 8 features: {', '.join(top_features_list[:4])}...\")\n",
    "print(f\"{'âœ“ Recommend reduced model for production' if r2_reduced/test_r2_rf > 0.95 else 'âœ“ Recommend full model - all features provide value'}\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505aa2b2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec41f3f",
   "metadata": {},
   "source": [
    "## Step 6: Comprehensive Model Comparison and Deployment Decision\n",
    "\n",
    "We've trained both a Linear Regression baseline and a Random Forest ensemble model. Now we face the critical question: **which model should we deploy to production?** This decision requires more than comparing RÂ² scores from a single train-test splitâ€”we need statistical confidence that one model consistently outperforms the other across different time periods.\n",
    "\n",
    "**From the lecture \"Model Evaluation & Performance Assessment\"**, we learned that rigorous model selection requires: (1) multiple evaluation metrics (MAE, RMSE, RÂ²), (2) cross-validation for statistical confidence, and (3) business impact translation. We implement this framework using **TimeSeriesSplit cross-validation**, which respects temporal ordering by training on historical data and testing on future dataâ€”mimicking real-world deployment where we predict tomorrow using yesterday's patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8761b4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import comprehensive evaluation metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "\n",
    "print(\"=== STEP 6: COMPREHENSIVE MODEL COMPARISON ===\\n\")\n",
    "\n",
    "# Configure TimeSeriesSplit cross-validation with 5 folds\n",
    "print(\"--- Cross-Validation Setup ---\")\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "print(\"Method: TimeSeriesSplit (respects temporal order)\")\n",
    "print(\"Number of folds: 5\")\n",
    "print(\"Strategy: Expanding window (each fold trains on more historical data)\\n\")\n",
    "\n",
    "# Show fold structure for transparency\n",
    "print(\"Fold structure:\")\n",
    "for fold, (train_idx, test_idx) in enumerate(tscv.split(X), 1):\n",
    "    train_start = df_clean.iloc[train_idx[0]]['datetime'].date()\n",
    "    train_end = df_clean.iloc[train_idx[-1]]['datetime'].date()\n",
    "    test_start = df_clean.iloc[test_idx[0]]['datetime'].date()\n",
    "    test_end = df_clean.iloc[test_idx[-1]]['datetime'].date()\n",
    "    \n",
    "    print(f\"Fold {fold}: Train {len(train_idx):,} obs ({train_start} to {train_end}) â†’ \"\n",
    "          f\"Test {len(test_idx):,} obs ({test_start} to {test_end})\")\n",
    "\n",
    "# Perform cross-validation for both models\n",
    "print(\"\\n--- Running Cross-Validation for Both Models ---\\n\")\n",
    "\n",
    "# Linear Regression CV\n",
    "print(\"Linear Regression:\")\n",
    "linear_cv_scores = cross_val_score(LinearRegression(), X, y, cv=tscv, \n",
    "                                   scoring='r2', n_jobs=-1)\n",
    "for fold, score in enumerate(linear_cv_scores, 1):\n",
    "    print(f\"  Fold {fold}: RÂ² = {score:.4f}\")\n",
    "\n",
    "linear_cv_mean = linear_cv_scores.mean()\n",
    "linear_cv_std = linear_cv_scores.std()\n",
    "print(f\"  Mean: {linear_cv_mean:.4f} Â± {linear_cv_std:.4f}\\n\")\n",
    "\n",
    "# Random Forest CV\n",
    "print(\"Random Forest:\")\n",
    "rf_cv_scores = cross_val_score(\n",
    "    RandomForestRegressor(n_estimators=100, max_depth=20, random_state=42, n_jobs=-1),\n",
    "    X, y, cv=tscv, scoring='r2', n_jobs=-1\n",
    ")\n",
    "for fold, score in enumerate(rf_cv_scores, 1):\n",
    "    print(f\"  Fold {fold}: RÂ² = {score:.4f}\")\n",
    "\n",
    "rf_cv_mean = rf_cv_scores.mean()\n",
    "rf_cv_std = rf_cv_scores.std()\n",
    "print(f\"  Mean: {rf_cv_mean:.4f} Â± {rf_cv_std:.4f}\")\n",
    "\n",
    "# Statistical comparison\n",
    "print(f\"\\n--- Cross-Validation Statistical Comparison ---\")\n",
    "print(f\"Linear Regression: {linear_cv_mean:.4f} Â± {linear_cv_std:.4f}\")\n",
    "print(f\"Random Forest:     {rf_cv_mean:.4f} Â± {rf_cv_std:.4f}\")\n",
    "print(f\"Difference:        {(rf_cv_mean - linear_cv_mean):+.4f}\")\n",
    "\n",
    "if rf_cv_mean > linear_cv_mean:\n",
    "    improvement_pct = ((rf_cv_mean - linear_cv_mean) / linear_cv_mean) * 100\n",
    "    print(f\"âœ“ Random Forest superior: {improvement_pct:+.1f}% better mean performance\")\n",
    "    winner = \"Random Forest\"\n",
    "else:\n",
    "    improvement_pct = ((linear_cv_mean - rf_cv_mean) / rf_cv_mean) * 100\n",
    "    print(f\"âœ“ Linear Regression superior: {improvement_pct:+.1f}% better mean performance\")\n",
    "    winner = \"Linear Regression\"\n",
    "\n",
    "# Calculate additional metrics on final test set\n",
    "print(\"\\n--- Test Set Performance Metrics ---\")\n",
    "\n",
    "# Use the test predictions from Step 4 and Step 5\n",
    "linear_mae = mean_absolute_error(y_test, test_predictions_linear)\n",
    "linear_rmse = np.sqrt(mean_squared_error(y_test, test_predictions_linear))\n",
    "linear_r2 = test_r2_linear\n",
    "\n",
    "rf_mae = mean_absolute_error(y_test, test_predictions_rf)\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, test_predictions_rf))\n",
    "rf_r2 = test_r2_rf\n",
    "\n",
    "print(\"\\nLinear Regression Test Set:\")\n",
    "print(f\"  MAE:  {linear_mae:.2f} bikes/hour\")\n",
    "print(f\"  RMSE: {linear_rmse:.2f} bikes/hour\")\n",
    "print(f\"  RÂ²:   {linear_r2:.4f}\")\n",
    "\n",
    "print(\"\\nRandom Forest Test Set:\")\n",
    "print(f\"  MAE:  {rf_mae:.2f} bikes/hour\")\n",
    "print(f\"  RMSE: {rf_rmse:.2f} bikes/hour\")\n",
    "print(f\"  RÂ²:   {rf_r2:.4f}\")\n",
    "\n",
    "# Create comprehensive comparison table\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"COMPREHENSIVE MODEL COMPARISON TABLE\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "comparison_metrics = pd.DataFrame({\n",
    "    'Metric': ['MAE (bikes/hour)', 'RMSE (bikes/hour)', 'RÂ² Score (test)', 'RÂ² Score (CV mean)'],\n",
    "    'Linear Regression': [linear_mae, linear_rmse, linear_r2, linear_cv_mean],\n",
    "    'Random Forest': [rf_mae, rf_rmse, rf_r2, rf_cv_mean],\n",
    "    'Winner': [\n",
    "        'RF' if rf_mae < linear_mae else 'Linear',\n",
    "        'RF' if rf_rmse < linear_rmse else 'Linear',\n",
    "        'RF' if rf_r2 > linear_r2 else 'Linear',\n",
    "        'RF' if rf_cv_mean > linear_cv_mean else 'Linear'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(comparison_metrics.to_string(index=False))\n",
    "\n",
    "# Summary of wins\n",
    "rf_wins = sum([rf_mae < linear_mae, rf_rmse < linear_rmse, rf_r2 > linear_r2, rf_cv_mean > linear_cv_mean])\n",
    "print(f\"\\n{winner} wins {rf_wins}/4 metrics\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Visualize comprehensive comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Comprehensive Model Comparison', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Panel 1: Cross-validation fold-by-fold performance\n",
    "fold_numbers = range(1, 6)\n",
    "axes[0, 0].plot(fold_numbers, linear_cv_scores, 'o-', linewidth=2.5, markersize=9,\n",
    "                color='blue', label='Linear Regression', alpha=0.8)\n",
    "axes[0, 0].plot(fold_numbers, rf_cv_scores, 's-', linewidth=2.5, markersize=9,\n",
    "                color='green', label='Random Forest', alpha=0.8)\n",
    "axes[0, 0].axhline(y=linear_cv_mean, color='blue', linestyle='--', alpha=0.5, linewidth=1.5)\n",
    "axes[0, 0].axhline(y=rf_cv_mean, color='green', linestyle='--', alpha=0.5, linewidth=1.5)\n",
    "axes[0, 0].set_xlabel('Fold Number', fontsize=11)\n",
    "axes[0, 0].set_ylabel('RÂ² Score', fontsize=11)\n",
    "axes[0, 0].set_title('Cross-Validation Performance by Fold', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xticks([1, 2, 3, 4, 5])  # Force integer fold numbers only\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 2: Cross-validation stability (box plot)\n",
    "bp = axes[0, 1].boxplot([linear_cv_scores, rf_cv_scores], \n",
    "                         tick_labels=['Linear', 'Random Forest'],\n",
    "                         patch_artist=True, showmeans=True,\n",
    "                         boxprops=dict(edgecolor='black', linewidth=1.5),\n",
    "                         medianprops=dict(color='red', linewidth=2),\n",
    "                         meanprops=dict(marker='D', markerfacecolor='gold', markersize=8))\n",
    "bp['boxes'][0].set_facecolor('lightblue')\n",
    "bp['boxes'][1].set_facecolor('lightgreen')\n",
    "axes[0, 1].set_ylabel('RÂ² Score', fontsize=11)\n",
    "axes[0, 1].set_title('Performance Distribution (Stability)', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Panel 3: Test set metrics comparison (MAE and RMSE only)\n",
    "metrics_names = ['MAE\\n(lower better)', 'RMSE\\n(lower better)']\n",
    "linear_metrics = [linear_mae, linear_rmse]\n",
    "rf_metrics = [rf_mae, rf_rmse]\n",
    "\n",
    "x = np.arange(len(metrics_names))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = axes[1, 0].bar(x - width/2, linear_metrics, width, label='Linear', \n",
    "                       color='lightblue', edgecolor='black', alpha=0.8)\n",
    "bars2 = axes[1, 0].bar(x + width/2, rf_metrics, width, label='Random Forest', \n",
    "                       color='lightgreen', edgecolor='black', alpha=0.8)\n",
    "\n",
    "axes[1, 0].set_ylabel('Metric Value (bikes/hour)', fontsize=11)\n",
    "axes[1, 0].set_title('Test Set Error Metrics', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xticks(x)\n",
    "axes[1, 0].set_xticklabels(metrics_names)\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        axes[1, 0].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                       f'{height:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Panel 4: RÂ² Score Comparison (Test Set and CV Mean)\n",
    "r2_categories = ['Test Set RÂ²\\n(higher better)', 'CV Mean RÂ²\\n(higher better)']\n",
    "linear_r2_values = [linear_r2, linear_cv_mean]\n",
    "rf_r2_values = [rf_r2, rf_cv_mean]\n",
    "\n",
    "x_r2 = np.arange(len(r2_categories))\n",
    "width_r2 = 0.35\n",
    "\n",
    "bars_lin = axes[1, 1].bar(x_r2 - width_r2/2, linear_r2_values, width_r2, \n",
    "                          label='Linear', color='lightblue', edgecolor='black', alpha=0.8)\n",
    "bars_rf = axes[1, 1].bar(x_r2 + width_r2/2, rf_r2_values, width_r2, \n",
    "                         label='Random Forest', color='lightgreen', edgecolor='black', alpha=0.8)\n",
    "\n",
    "axes[1, 1].set_ylabel('RÂ² Score', fontsize=11)\n",
    "axes[1, 1].set_title('RÂ² Score Comparison', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xticks(x_r2)\n",
    "axes[1, 1].set_xticklabels(r2_categories)\n",
    "axes[1, 1].set_ylim(0, 1.0)\n",
    "axes[1, 1].legend(loc='upper left')\n",
    "axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bars in [bars_lin, bars_rf]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        axes[1, 1].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                       f'{height:.4f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1ae154",
   "metadata": {},
   "source": [
    "**What this does:**\n",
    "- Uses **TimeSeriesSplit cross-validation as the primary evaluation method** (not an afterthought)\n",
    "- Shows fold structure with date ranges for transparency (5 expanding windows)\n",
    "- Prints fold-by-fold RÂ² scores for both Linear Regression AND Random Forest\n",
    "- Calculates CV mean and std for statistical confidence\n",
    "- Computes test set metrics (MAE, RMSE, RÂ²) for both models\n",
    "- **Creates comprehensive comparison table** showing all 4 metrics (MAE, RMSE, test RÂ², CV mean RÂ²) with winner declared for each\n",
    "- Visualizes performance with 4-panel dashboard:\n",
    "  - **Panel 1**: CV fold-by-fold performance (line plot showing RÂ² across 5 folds)\n",
    "  - **Panel 2**: CV stability (box plot showing distribution and outliers)\n",
    "  - **Panel 3**: Test set error metrics (MAE and RMSE in bikes/hour - same scale)\n",
    "  - **Panel 4**: RÂ² score comparison (Test Set RÂ² and CV Mean RÂ² on 0-1 scale)\n",
    "- Shows clear summary: which model wins on how many metrics\n",
    "\n",
    "**Business value:**\n",
    "Cross-validation provides statistical confidence across multiple time periods, not just one arbitrary train-test split. The comprehensive comparison table gives stakeholders a clear, at-a-glance view of model performance across all key metrics. This rigorous approach demonstrates which model will generalize better to future unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724b17b1",
   "metadata": {},
   "source": [
    "### Challenge 6: Enhanced Model with Rolling Window Features\n",
    "\n",
    "Your client asks: \"We engineered those rolling window features in Challenge 2 - do they actually improve our models? I want to see if the extra complexity is worth it.\" Add the rolling features to both models and compare baseline vs enhanced performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb20a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - retrain models with rolling window features and compare\n",
    "\n",
    "print(\"=== ENHANCED MODEL WITH ROLLING WINDOW FEATURES ===\\n\")\n",
    "\n",
    "# First, create rolling window features if not already present\n",
    "if 'demand_3h_avg' not in df_clean.columns:\n",
    "    df_clean['demand_3h_avg'] = df_clean['count'].shift(1).rolling(window=3, min_periods=1).mean()\n",
    "    df_clean['demand_24h_avg'] = df_clean['count'].shift(1).rolling(window=24, min_periods=1).mean()\n",
    "    print(\"âœ“ Rolling window features created\")\n",
    "\n",
    "# Handle NaN values (whether features were just created or from Challenge 2)\n",
    "df_clean['demand_3h_avg'] = df_clean['demand_3h_avg'].fillna(df_clean['count'].mean())\n",
    "df_clean['demand_24h_avg'] = df_clean['demand_24h_avg'].fillna(df_clean['count'].mean())\n",
    "print(\"âœ“ NaN values handled in rolling features\")\n",
    "\n",
    "# Expand feature set to include rolling features\n",
    "enhanced_features = feature_columns + ['demand_3h_avg', 'demand_24h_avg']\n",
    "\n",
    "print(f\"Baseline features: {len(feature_columns)}\")\n",
    "print(f\"Enhanced features: {len(enhanced_features)} (+2 rolling features)\\n\")\n",
    "\n",
    "X_enhanced = df_clean[_____]\n",
    "y_enhanced = df_clean['count']\n",
    "\n",
    "# Cross-validation comparison\n",
    "print(\"\\n--- Cross-Validation: Baseline vs Enhanced ---\")\n",
    "\n",
    "# Linear Regression CV - Enhanced\n",
    "linear_enh_cv_scores = cross_val_score(\n",
    "    LinearRegression(), \n",
    "    _____, y_enhanced, \n",
    "    cv=_____, \n",
    "    scoring='r2', \n",
    "    n_jobs=-1\n",
    ")\n",
    "linear_enh_cv_mean = linear_enh_cv_scores._____()\n",
    "\n",
    "# Random Forest CV - Enhanced  \n",
    "rf_enh_cv_scores = cross_val_score(\n",
    "    RandomForestRegressor(n_estimators=100, max_depth=20, random_state=42, n_jobs=-1),\n",
    "    _____, y_enhanced,\n",
    "    cv=_____,\n",
    "    scoring='r2',\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_enh_cv_mean = rf_enh_cv_scores._____()\n",
    "\n",
    "print(\"\\nLinear Regression CV:\")\n",
    "print(f\"  Baseline (20 features):  {linear_cv_mean:.4f} Â± {linear_cv_std:.4f}\")\n",
    "print(f\"  Enhanced (22 features):  {linear_enh_cv_mean:.4f} Â± {linear_enh_cv_scores.std():.4f}\")\n",
    "print(f\"  Change: {(linear_enh_cv_mean - linear_cv_mean):+.4f}\")\n",
    "\n",
    "print(\"\\nRandom Forest CV:\")\n",
    "print(f\"  Baseline (20 features):  {rf_cv_mean:.4f} Â± {rf_cv_std:.4f}\")\n",
    "print(f\"  Enhanced (22 features):  {rf_enh_cv_mean:.4f} Â± {rf_enh_cv_scores.std():.4f}\")\n",
    "print(f\"  Change: {(rf_enh_cv_mean - rf_cv_mean):+.4f}\")\n",
    "\n",
    "# Test set evaluation (for detailed metrics and visualizations)\n",
    "X_train_enh = X_enhanced.iloc[:split_index]\n",
    "X_test_enh = X_enhanced.iloc[split_index:]\n",
    "y_train_enh = y_enhanced.iloc[:split_index]\n",
    "y_test_enh = y_enhanced.iloc[split_index:]\n",
    "\n",
    "# Train on full training set for test predictions\n",
    "linear_enhanced = LinearRegression()\n",
    "linear_enhanced.fit(_____, _____)\n",
    "linear_enh_pred = linear_enhanced.predict(_____)\n",
    "linear_enh_r2 = r2_score(_____, _____)\n",
    "linear_enh_mae = mean_absolute_error(y_test_enh, linear_enh_pred)\n",
    "\n",
    "rf_enhanced = RandomForestRegressor(n_estimators=100, max_depth=20, random_state=42, n_jobs=-1)\n",
    "rf_enhanced.fit(_____, _____)\n",
    "rf_enh_pred = rf_enhanced.predict(_____)\n",
    "rf_enh_r2 = r2_score(_____, _____)\n",
    "rf_enh_mae = mean_absolute_error(y_test_enh, rf_enh_pred)\n",
    "\n",
    "print(\"\\n--- Test Set Detailed Metrics ---\")\n",
    "print(\"\\nLinear Regression:\")\n",
    "print(f\"  Baseline:  RÂ² = {test_r2_linear:.4f}, MAE = {linear_mae:.2f}\")\n",
    "print(f\"  Enhanced:  RÂ² = {linear_enh_r2:.4f}, MAE = {linear_enh_mae:.2f}\")\n",
    "\n",
    "print(\"\\nRandom Forest:\")\n",
    "print(f\"  Baseline:  RÂ² = {test_r2_rf:.4f}, MAE = {rf_mae:.2f}\")\n",
    "print(f\"  Enhanced:  RÂ² = {rf_enh_r2:.4f}, MAE = {rf_enh_mae:.2f}\")\n",
    "\n",
    "# Feature importance for rolling features\n",
    "print(\"\\n--- ROLLING FEATURE IMPORTANCE (Enhanced RF Model) ---\")\n",
    "rf_enh_importance = pd.DataFrame({\n",
    "    'feature': enhanced_features,\n",
    "    'importance': rf_enhanced.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "rolling_features_imp = rf_enh_importance[rf_enh_importance['feature'].isin(\n",
    "    ['demand_3h_avg', 'demand_24h_avg']\n",
    ")]\n",
    "print(rolling_features_imp.to_string(index=False))\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Panel 1: CV Performance Comparison\n",
    "models = ['Linear\\nBaseline', 'Linear\\nEnhanced', 'RF\\nBaseline', 'RF\\nEnhanced']\n",
    "cv_scores = [linear_cv_mean, linear_enh_cv_mean, rf_cv_mean, rf_enh_cv_mean]\n",
    "colors = ['lightblue', 'blue', 'lightgreen', 'darkgreen']\n",
    "\n",
    "bars = axes[0].bar(models, cv_scores, color=colors, edgecolor='black', alpha=0.8)\n",
    "axes[0].set_ylabel('CV Mean RÂ² Score', fontsize=11)\n",
    "axes[0].set_title('Baseline vs Enhanced (Cross-Validation)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylim(0, 1.0)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, (model, score) in enumerate(zip(models, cv_scores)):\n",
    "    axes[0].text(i, score + 0.02, f'{score:.4f}', ha='center', fontweight='bold', fontsize=10)\n",
    "\n",
    "# Panel 2: Feature importance - Top 12 with rolling features highlighted\n",
    "top_12_enh = rf_enh_importance.head(12)\n",
    "highlight_colors = ['gold' if feat in ['demand_3h_avg', 'demand_24h_avg'] \n",
    "                    else 'steelblue' for feat in top_12_enh['feature']]\n",
    "\n",
    "axes[1].barh(range(len(top_12_enh)), top_12_enh['importance'], \n",
    "             color=highlight_colors, edgecolor='black', alpha=0.8)\n",
    "axes[1].set_yticks(range(len(top_12_enh)))\n",
    "axes[1].set_yticklabels(top_12_enh['feature'])\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].set_xlabel('Importance Score', fontsize=11)\n",
    "axes[1].set_title('Top 12 Features (Rolling Window in Gold)', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Decision recommendation based on CV results\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "max_cv_improvement = max(linear_enh_cv_mean - linear_cv_mean, rf_enh_cv_mean - rf_cv_mean)\n",
    "if max_cv_improvement > 0.02:\n",
    "    print(\"âœ“ RECOMMENDATION: Deploy enhanced models - rolling features provide meaningful improvement\")\n",
    "elif max_cv_improvement > 0.01:\n",
    "    print(\"~ RECOMMENDATION: Rolling features provide marginal benefit - deployment decision depends on complexity tolerance\")\n",
    "else:\n",
    "    print(\"âœ— RECOMMENDATION: Use baseline models - rolling features add complexity without significant value\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1003430d",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ðŸ’¡ <strong>Tip</strong> (click to expand)</summary>\n",
    "\n",
    "Build the enhanced feature set: `enhanced_features = feature_columns + ['demand_3h_avg', 'demand_24h_avg']`. Create X_enhanced using this list. Following Step 6's rigorous methodology, use `cross_val_score()` with the `tscv` TimeSeriesSplit object to evaluate enhanced models: `cross_val_score(LinearRegression(), X_enhanced, y_enhanced, cv=tscv, scoring='r2')`. This gives you 5 fold scores for the enhanced model. Compare the CV means: `linear_enh_cv_scores.mean()` vs `linear_cv_mean` from Step 6. The blanks require: `X_enhanced` for the feature matrix, `tscv` for the cv parameter (reusing the TimeSeriesSplit from Step 6), and `.mean()` to get the average across folds. Also run test set evaluation for detailed metrics (MAE) and feature importance analysis - this requires the train-test split. Train fresh models: `LinearRegression()` and `RandomForestRegressor()` with identical hyperparameters. The test set blanks need: `X_train_enh, y_train_enh` for fitting, `X_test_enh` for prediction, and `y_test_enh, linear_enh_pred` for RÂ² scoring. Fill NaN values in rolling features BEFORE creating X_enhanced to prevent \"Input contains NaN\" errors. Expected realistic results: Linear CV improvement 0.00-0.03, Random Forest improvement 0.00-0.02. The 3-hour rolling average captures short-term trends while the 24-hour rolling average provides daily baseline patterns - both help models understand demand trajectories beyond single lag values. Key insight: Linear models typically benefit MORE from rolling features (capturing sequential patterns they can't model), while Random Forest shows smaller gains (trees already capture patterns via existing lag features). Use CV mean improvement (not single test score) for the deployment decision - this is statistically robust. Rule of thumb: CV improvement >0.02 RÂ² is meaningful, 0.01-0.02 is marginal, <0.01 suggests feature redundancy.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af6f469",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ðŸ¤« <strong>Solution</strong> (click to expand)</summary>\n",
    "\n",
    "```python\n",
    "print(\"=== ENHANCED MODEL WITH ROLLING WINDOW FEATURES ===\\n\")\n",
    "\n",
    "# First, create rolling window features if not already present\n",
    "if 'demand_3h_avg' not in df_clean.columns:\n",
    "    df_clean['demand_3h_avg'] = df_clean['count'].shift(1).rolling(window=3, min_periods=1).mean()\n",
    "    df_clean['demand_24h_avg'] = df_clean['count'].shift(1).rolling(window=24, min_periods=1).mean()\n",
    "    print(\"âœ“ Rolling window features created\")\n",
    "\n",
    "# Handle NaN values (whether features were just created or from Challenge 2)\n",
    "df_clean['demand_3h_avg'] = df_clean['demand_3h_avg'].fillna(df_clean['count'].mean())\n",
    "df_clean['demand_24h_avg'] = df_clean['demand_24h_avg'].fillna(df_clean['count'].mean())\n",
    "print(\"âœ“ NaN values handled in rolling features\")\n",
    "\n",
    "# Expand feature set to include rolling features\n",
    "enhanced_features = feature_columns + ['demand_3h_avg', 'demand_24h_avg']\n",
    "\n",
    "print(f\"Baseline features: {len(feature_columns)}\")\n",
    "print(f\"Enhanced features: {len(enhanced_features)} (+2 rolling features)\\n\")\n",
    "\n",
    "X_enhanced = df_clean[enhanced_features]\n",
    "y_enhanced = df_clean['count']\n",
    "\n",
    "# Cross-validation comparison\n",
    "print(\"\\n--- Cross-Validation: Baseline vs Enhanced ---\")\n",
    "\n",
    "# Linear Regression CV - Enhanced\n",
    "linear_enh_cv_scores = cross_val_score(\n",
    "    LinearRegression(), \n",
    "    X_enhanced, y_enhanced, \n",
    "    cv=tscv, \n",
    "    scoring='r2', \n",
    "    n_jobs=-1\n",
    ")\n",
    "linear_enh_cv_mean = linear_enh_cv_scores.mean()\n",
    "\n",
    "# Random Forest CV - Enhanced  \n",
    "rf_enh_cv_scores = cross_val_score(\n",
    "    RandomForestRegressor(n_estimators=100, max_depth=20, random_state=42, n_jobs=-1),\n",
    "    X_enhanced, y_enhanced,\n",
    "    cv=tscv,\n",
    "    scoring='r2',\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_enh_cv_mean = rf_enh_cv_scores.mean()\n",
    "\n",
    "print(\"\\nLinear Regression CV:\")\n",
    "print(f\"  Baseline (20 features):  {linear_cv_mean:.4f} Â± {linear_cv_std:.4f}\")\n",
    "print(f\"  Enhanced (22 features):  {linear_enh_cv_mean:.4f} Â± {linear_enh_cv_scores.std():.4f}\")\n",
    "lin_cv_change = linear_enh_cv_mean - linear_cv_mean\n",
    "print(f\"  Change: {lin_cv_change:+.4f} ({(lin_cv_change/linear_cv_mean)*100:+.1f}%)\")\n",
    "\n",
    "print(\"\\nRandom Forest CV:\")\n",
    "print(f\"  Baseline (20 features):  {rf_cv_mean:.4f} Â± {rf_cv_std:.4f}\")\n",
    "print(f\"  Enhanced (22 features):  {rf_enh_cv_mean:.4f} Â± {rf_enh_cv_scores.std():.4f}\")\n",
    "rf_cv_change = rf_enh_cv_mean - rf_cv_mean\n",
    "print(f\"  Change: {rf_cv_change:+.4f} ({(rf_cv_change/rf_cv_mean)*100:+.1f}%)\")\n",
    "\n",
    "# Test set evaluation (for detailed metrics and visualizations)\n",
    "X_train_enh = X_enhanced.iloc[:split_index]\n",
    "X_test_enh = X_enhanced.iloc[split_index:]\n",
    "y_train_enh = y_enhanced.iloc[:split_index]\n",
    "y_test_enh = y_enhanced.iloc[split_index:]\n",
    "\n",
    "print(f\"\\n--- Training Final Models for Test Set Evaluation ---\")\n",
    "\n",
    "# Train on full training set for test predictions\n",
    "linear_enhanced = LinearRegression()\n",
    "linear_enhanced.fit(X_train_enh, y_train_enh)\n",
    "linear_enh_pred = linear_enhanced.predict(X_test_enh)\n",
    "linear_enh_r2 = r2_score(y_test_enh, linear_enh_pred)\n",
    "linear_enh_mae = mean_absolute_error(y_test_enh, linear_enh_pred)\n",
    "\n",
    "rf_enhanced = RandomForestRegressor(n_estimators=100, max_depth=20, random_state=42, n_jobs=-1)\n",
    "rf_enhanced.fit(X_train_enh, y_train_enh)\n",
    "rf_enh_pred = rf_enhanced.predict(X_test_enh)\n",
    "rf_enh_r2 = r2_score(y_test_enh, rf_enh_pred)\n",
    "rf_enh_mae = mean_absolute_error(y_test_enh, rf_enh_pred)\n",
    "\n",
    "print(\"\\n--- Test Set Detailed Metrics ---\")\n",
    "print(\"\\nLinear Regression:\")\n",
    "print(f\"  Baseline:  RÂ² = {test_r2_linear:.4f}, MAE = {linear_mae:.2f}\")\n",
    "print(f\"  Enhanced:  RÂ² = {linear_enh_r2:.4f}, MAE = {linear_enh_mae:.2f}\")\n",
    "print(f\"  Change: RÂ² {(linear_enh_r2 - test_r2_linear):+.4f}, MAE {(linear_enh_mae - linear_mae):+.2f}\")\n",
    "\n",
    "print(\"\\nRandom Forest:\")\n",
    "print(f\"  Baseline:  RÂ² = {test_r2_rf:.4f}, MAE = {rf_mae:.2f}\")\n",
    "print(f\"  Enhanced:  RÂ² = {rf_enh_r2:.4f}, MAE = {rf_enh_mae:.2f}\")\n",
    "print(f\"  Change: RÂ² {(rf_enh_r2 - test_r2_rf):+.4f}, MAE {(rf_enh_mae - rf_mae):+.2f}\")\n",
    "\n",
    "# Feature importance analysis\n",
    "print(\"\\n--- ROLLING FEATURE IMPORTANCE (Enhanced RF Model) ---\")\n",
    "rf_enh_importance = pd.DataFrame({\n",
    "    'feature': enhanced_features,\n",
    "    'importance': rf_enhanced.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Show rolling features specifically with their ranks\n",
    "rolling_features_imp = rf_enh_importance[rf_enh_importance['feature'].isin(\n",
    "    ['demand_3h_avg', 'demand_24h_avg']\n",
    ")].copy()\n",
    "rolling_features_imp['rank'] = rolling_features_imp['feature'].apply(\n",
    "    lambda x: rf_enh_importance[rf_enh_importance['feature'] == x].index[0] + 1\n",
    ")\n",
    "print(rolling_features_imp[['feature', 'importance', 'rank']].to_string(index=False))\n",
    "\n",
    "# Visualizations\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Panel 1: CV Performance Comparison (primary evaluation)\n",
    "models = ['Linear\\nBaseline', 'Linear\\nEnhanced', 'RF\\nBaseline', 'RF\\nEnhanced']\n",
    "cv_scores = [linear_cv_mean, linear_enh_cv_mean, rf_cv_mean, rf_enh_cv_mean]\n",
    "colors = ['lightblue', 'blue', 'lightgreen', 'darkgreen']\n",
    "\n",
    "bars = axes[0].bar(models, cv_scores, color=colors, edgecolor='black', alpha=0.8)\n",
    "axes[0].set_ylabel('CV Mean RÂ² Score', fontsize=11)\n",
    "axes[0].set_title('Baseline vs Enhanced (Cross-Validation)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylim(0, 1.0)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, (model, score) in enumerate(zip(models, cv_scores)):\n",
    "    axes[0].text(i, score + 0.02, f'{score:.4f}', ha='center', fontweight='bold', fontsize=10)\n",
    "\n",
    "# Panel 2: Feature importance with rolling features highlighted\n",
    "top_12_enh = rf_enh_importance.head(12)\n",
    "highlight_colors = ['gold' if feat in ['demand_3h_avg', 'demand_24h_avg'] \n",
    "                    else 'steelblue' for feat in top_12_enh['feature']]\n",
    "\n",
    "axes[1].barh(range(len(top_12_enh)), top_12_enh['importance'], \n",
    "             color=highlight_colors, edgecolor='black', alpha=0.8)\n",
    "axes[1].set_yticks(range(len(top_12_enh)))\n",
    "axes[1].set_yticklabels(top_12_enh['feature'])\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].set_xlabel('Importance Score', fontsize=11)\n",
    "axes[1].set_title('Top 12 Features (Rolling Window in Gold)', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add importance values for rolling features\n",
    "for idx, row in top_12_enh.iterrows():\n",
    "    if row['feature'] in ['demand_3h_avg', 'demand_24h_avg']:\n",
    "        rank = list(top_12_enh['feature']).index(row['feature'])\n",
    "        axes[1].text(row['importance'], rank, f\"  {row['importance']:.4f}\", \n",
    "                    va='center', fontweight='bold', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Decision framework based on CV results (rigorous approach)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "max_cv_improvement = max(lin_cv_change, rf_cv_change)\n",
    "if max_cv_improvement > 0.02:\n",
    "    print(\"âœ“ RECOMMENDATION: Deploy enhanced models\")\n",
    "    print(f\"  Rolling features provide meaningful improvement ({max_cv_improvement:+.4f} CV RÂ²)\")\n",
    "    print(f\"  {'Linear benefits most' if lin_cv_change > rf_cv_change else 'Random Forest benefits most'}\")\n",
    "elif max_cv_improvement > 0.01:\n",
    "    print(\"~ RECOMMENDATION: Consider enhanced models\")\n",
    "    print(f\"  Rolling features provide marginal benefit ({max_cv_improvement:+.4f} CV RÂ²)\")\n",
    "    print(f\"  Deploy if operational complexity is acceptable\")\n",
    "else:\n",
    "    print(\"âœ— RECOMMENDATION: Use baseline models\")\n",
    "    print(f\"  Rolling features add minimal value ({max_cv_improvement:+.4f} CV RÂ²)\")\n",
    "    print(f\"  Existing lag features already capture sequential patterns effectively\")\n",
    "\n",
    "# Key insights\n",
    "rolling_in_top_5 = any(feat in list(rf_enh_importance.head(5)['feature']) \n",
    "                       for feat in ['demand_3h_avg', 'demand_24h_avg'])\n",
    "print(f\"\\nâœ“ Rolling window features {'ARE' if rolling_in_top_5 else 'are NOT'} in top 5 importance\")\n",
    "print(f\"âœ“ Linear CV improved by {(lin_cv_change/linear_cv_mean)*100:+.1f}% (linear models benefit from sequential features)\")\n",
    "print(f\"âœ“ Random Forest CV improved by {(rf_cv_change/rf_cv_mean)*100:+.1f}% (trees already capture patterns)\")\n",
    "print(f\"âœ“ Decision based on CV performance (statistically robust across 5 time periods)\")\n",
    "print(\"=\"*70)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b736784",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c15266d",
   "metadata": {},
   "source": [
    "## Summary: Complete End-to-End Machine Learning Pipeline Mastery\n",
    "\n",
    "**What We've Accomplished**:\n",
    "- **Data Quality Pipeline**: Implemented systematic validation workflows, handled missing values, verified timeline integrity, and established clean data foundation for reliable modeling\n",
    "- **Feature Engineering**: Created 17 optimized features including categorical encodings, scaled weather variables, cyclical temporal features, and lag variables - transforming raw data into ML-ready inputs\n",
    "- **Statistical Validation**: Applied descriptive statistics, correlation analysis, and professional visualizations (line plots, bar charts, scatter plots, box plots, heatmaps) confirming features capture real demand patterns\n",
    "- **Linear Regression Baseline**: Trained interpretable baseline model achieving RÂ² â‰ˆ 0.80, established performance benchmark, and validated temporal train-test splitting methodology\n",
    "- **Random Forest Excellence**: Deployed ensemble model with 100 trees achieving RÂ² â‰ˆ 0.90, analyzed feature importance revealing key demand drivers, and demonstrated non-linear pattern capture\n",
    "- **Evaluation Framework**: Compared models across MAE, RMSE, and RÂ² metrics; applied 5-fold TimeSeriesSplit cross-validation for robust estimates; translated performance to business impact; made evidence-based deployment recommendation\n",
    "\n",
    "**Key Technical Skills Mastered**:\n",
    "- **Data preparation**: Quality assessment workflows, missing data handling, timeline standardization, outlier detection (IQR method)\n",
    "- **Feature engineering**: One-hot encoding, binary indicators, StandardScaler normalization, cyclical sin/cos encoding for temporal continuity, lag features with `.shift()`\n",
    "- **Exploratory analysis**: `.describe()` for statistics, `.corr()` for relationships, `.groupby()` for segmentation, professional matplotlib visualizations\n",
    "- **Model development**: LinearRegression and RandomForestRegressor with scikit-learn, chronological train-test splitting, proper evaluation on unseen future data\n",
    "- **Performance evaluation**: MAE/RMSE/RÂ² metric calculation, TimeSeriesSplit cross-validation, statistical confidence intervals, feature importance interpretation\n",
    "\n",
    "Congratulations! ðŸ¥³ You've completed the full professional ML workflow from raw data to deployment-ready system. Your Capital City Bikes forecasting system demonstrates production-grade rigor across data preparation, feature engineering, model development, and evaluation - the complete skillset that distinguishes professional ML engineers from basic model builders. You're now ready to tackle real-world transportation forecasting challenges with confidence, systematic methodology, and stakeholder-ready communication!"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
